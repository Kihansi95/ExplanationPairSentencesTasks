{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42291469-df9d-43bc-8e04-550994f2f37b",
   "metadata": {},
   "source": [
    "# Study on HateXplain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb5ea3c8670a44",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5a77f3-37ef-489d-bbb7-73be05cfc3ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:20:39.605359Z",
     "start_time": "2024-04-12T09:20:39.555993Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3326b3297a8386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:20:46.465904Z",
     "start_time": "2024-04-12T09:20:41.657139Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from modules.logger import init_logging\n",
    "from modules.logger import log\n",
    "\n",
    "init_logging(color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d017a76b82832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:20:46.527056Z",
     "start_time": "2024-04-12T09:20:46.473014Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cache_path = path.join(os.getcwd(), '..', '.cache')\n",
    "dataset_path = path.join(cache_path, 'dataset')\n",
    "tmp_path = path.join('.cache', '2022-07-27')\n",
    "os.makedirs(tmp_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978372aee3dae18b",
   "metadata": {},
   "source": [
    "## Download dataset from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d048668-dfda-4895-b3a7-0305ecfb6b6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:12:13.973840Z",
     "start_time": "2024-04-12T08:12:11.199006Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hatexplain (/Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/plain_text/1.0.0/df474d8d8667d89ef30649bf66e9c856ad8305bef4bc147e8e31cbdf1b8e0249)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b2c999414e48dabf1fe1c61fe545d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import shutil\n",
    "\n",
    "dataset = load_dataset(\"hatexplain\", cache_dir=path.join(cache_path, 'dataset'))\n",
    "\n",
    "shutil.rmtree(path.join(dataset_path, 'downloads'), ignore_errors=True)\n",
    "for fname in os.listdir(dataset_path):\n",
    "    if fname.endswith('.lock'): os.remove(os.path.join( dataset_path, fname ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f08c876-628f-4d93-a7b2-e2f079aa53c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:12:14.000409Z",
     "start_time": "2024-04-12T08:12:13.976701Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e824499-d464-4789-83fd-b88319078e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:12:16.011755Z",
     "start_time": "2024-04-12T08:12:14.003615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de vocab: 24991\n",
      "exemple de vocab: ['the', 'a', 'to', 'and', 'i', '<user>', 'you', 'of', 'is', 'not', 'in', 'are', 'that', 'it', 'white', 'they', 'for', '<number>', 'be', 'have', 'this', 'with', 'on', 'all', 'do', 'nigger', 'like', 'but', 'so', 'my', 'if', 'was', 'as', 'he', 'just', 'will', 'people', 'we', 'who', 'can', 'your', 'or', 'by', 'their', 'about', 'no', 'what', 'women', 'me', 'from', 'am', 'them', 'up', 'out', 'at', 'get', 'jews', 'one', 'how', 'there', 'when', 'bitch', 'muslim', 'kike', 'would', 'fucking', 'an', 'ghetto', 'his', 'she', 'retarded', 'black', 'more', 'why', 'shit', 'because', 'fuck', 'hate', 'only', 'has', 'some', '’', 'being', 'now', 'know', 'niggers', 'gay', 'these', 'raped', 'her', 'should', 'us', 'did', 'our', 'were', 'want', 'immigrants', 'than', 'think', 'too']\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "vocab = build_vocab_from_iterator(iter(doc for doc in train_set['post_tokens']))\n",
    "print('Taille de vocab:', len(vocab))\n",
    "print('exemple de vocab:', vocab.get_itos()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f14cb6-81ab-4c35-9d01-5a9205bff0c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:12:16.211635Z",
     "start_time": "2024-04-12T08:12:16.014636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>count_rationales</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>{'label': [0, 2, 2], 'annotator_id': [203, 204...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [27, 6, 4...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [209, 203...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [235, 222...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...</td>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [51, 25, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>1125944647509917699_twitter</td>\n",
       "      <td>{'label': [2, 2, 1], 'annotator_id': [217, 206...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...</td>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>1191705189587341312_twitter</td>\n",
       "      <td>{'label': [1, 1, 2], 'annotator_id': [209, 200...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>1178822728511606786_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [127, 17,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>1179009825432358913_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [49, 18, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>24503772_gab</td>\n",
       "      <td>{'label': [0, 0, 0], 'annotator_id': [9, 1, 64...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0                     23107796_gab   \n",
       "1                      9995600_gab   \n",
       "2      1227920812235051008_twitter   \n",
       "3      1204931715778543624_twitter   \n",
       "4      1179102559241244672_twitter   \n",
       "...                            ...   \n",
       "15378  1125944647509917699_twitter   \n",
       "15379  1191705189587341312_twitter   \n",
       "15380  1178822728511606786_twitter   \n",
       "15381  1179009825432358913_twitter   \n",
       "15382                 24503772_gab   \n",
       "\n",
       "                                              annotators  \\\n",
       "0      {'label': [0, 2, 2], 'annotator_id': [203, 204...   \n",
       "1      {'label': [2, 2, 0], 'annotator_id': [27, 6, 4...   \n",
       "2      {'label': [2, 2, 2], 'annotator_id': [209, 203...   \n",
       "3      {'label': [2, 2, 2], 'annotator_id': [235, 222...   \n",
       "4      {'label': [2, 2, 2], 'annotator_id': [51, 25, ...   \n",
       "...                                                  ...   \n",
       "15378  {'label': [2, 2, 1], 'annotator_id': [217, 206...   \n",
       "15379  {'label': [1, 1, 2], 'annotator_id': [209, 200...   \n",
       "15380  {'label': [1, 1, 1], 'annotator_id': [127, 17,...   \n",
       "15381  {'label': [1, 1, 1], 'annotator_id': [49, 18, ...   \n",
       "15382  {'label': [0, 0, 0], 'annotator_id': [9, 1, 64...   \n",
       "\n",
       "                                              rationales  \\\n",
       "0      [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...   \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...   \n",
       "4      [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                  ...   \n",
       "15378  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...   \n",
       "15379                                                 []   \n",
       "15380                                                 []   \n",
       "15381                                                 []   \n",
       "15382  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                             post_tokens  count_rationales  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...                 2   \n",
       "1      [the, uk, has, threatened, to, return, radioac...                 3   \n",
       "2      [if, english, is, not, imposition, then, hindi...                 2   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...                 2   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...                 3   \n",
       "...                                                  ...               ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...                 2   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...                 0   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...                 0   \n",
       "15381          [good, morning, ados, black, women, only]                 0   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...                 3   \n",
       "\n",
       "          labels  \n",
       "0      [0, 2, 2]  \n",
       "1      [2, 2, 0]  \n",
       "2      [2, 2, 2]  \n",
       "3      [2, 2, 2]  \n",
       "4      [2, 2, 2]  \n",
       "...          ...  \n",
       "15378  [2, 2, 1]  \n",
       "15379  [1, 1, 2]  \n",
       "15380  [1, 1, 1]  \n",
       "15381  [1, 1, 1]  \n",
       "15382  [0, 0, 0]  \n",
       "\n",
       "[15383 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_set.to_pandas()\n",
    "df['count_rationales'] = df['rationales'].apply(lambda x: len(x))\n",
    "df['labels'] = df['annotators'].apply(lambda x: x['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca3f411-a62b-4250-aefe-e179d6b063d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T10:36:27.936251Z",
     "start_time": "2023-05-02T10:36:27.884195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.465253851654424"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_tokens'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aaaef9a-dbe6-4f2b-b0f6-a9ab0c25ef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.804274752488313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_tokens'].str.len().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50714c43-f4ed-43a7-b625-1df91e9921ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_tokens'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb112a99-b268-4f1e-9a82-0f66784d0b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_tokens'].str.len().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f38c5-247a-472b-acee-7ee4f5cd2665",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Les raisonnements ne sont pas donnés systématiques par les 3 annotateurs\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1f69f0-9cc1-42d9-a3f5-e43d3a9d00fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>count_rationales</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_harmful</th>\n",
       "      <th>harmful_has_explaination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>{'label': [0, 2, 2], 'annotator_id': [203, 204...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [27, 6, 4...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [209, 203...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [235, 222...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...</td>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [51, 25, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>1125944647509917699_twitter</td>\n",
       "      <td>{'label': [2, 2, 1], 'annotator_id': [217, 206...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...</td>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>1191705189587341312_twitter</td>\n",
       "      <td>{'label': [1, 1, 2], 'annotator_id': [209, 200...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>1178822728511606786_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [127, 17,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>1179009825432358913_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [49, 18, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>24503772_gab</td>\n",
       "      <td>{'label': [0, 0, 0], 'annotator_id': [9, 1, 64...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0                     23107796_gab   \n",
       "1                      9995600_gab   \n",
       "2      1227920812235051008_twitter   \n",
       "3      1204931715778543624_twitter   \n",
       "4      1179102559241244672_twitter   \n",
       "...                            ...   \n",
       "15378  1125944647509917699_twitter   \n",
       "15379  1191705189587341312_twitter   \n",
       "15380  1178822728511606786_twitter   \n",
       "15381  1179009825432358913_twitter   \n",
       "15382                 24503772_gab   \n",
       "\n",
       "                                              annotators  \\\n",
       "0      {'label': [0, 2, 2], 'annotator_id': [203, 204...   \n",
       "1      {'label': [2, 2, 0], 'annotator_id': [27, 6, 4...   \n",
       "2      {'label': [2, 2, 2], 'annotator_id': [209, 203...   \n",
       "3      {'label': [2, 2, 2], 'annotator_id': [235, 222...   \n",
       "4      {'label': [2, 2, 2], 'annotator_id': [51, 25, ...   \n",
       "...                                                  ...   \n",
       "15378  {'label': [2, 2, 1], 'annotator_id': [217, 206...   \n",
       "15379  {'label': [1, 1, 2], 'annotator_id': [209, 200...   \n",
       "15380  {'label': [1, 1, 1], 'annotator_id': [127, 17,...   \n",
       "15381  {'label': [1, 1, 1], 'annotator_id': [49, 18, ...   \n",
       "15382  {'label': [0, 0, 0], 'annotator_id': [9, 1, 64...   \n",
       "\n",
       "                                              rationales  \\\n",
       "0      [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...   \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...   \n",
       "4      [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                  ...   \n",
       "15378  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...   \n",
       "15379                                                 []   \n",
       "15380                                                 []   \n",
       "15381                                                 []   \n",
       "15382  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                             post_tokens  count_rationales  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...                 2   \n",
       "1      [the, uk, has, threatened, to, return, radioac...                 3   \n",
       "2      [if, english, is, not, imposition, then, hindi...                 2   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...                 2   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...                 3   \n",
       "...                                                  ...               ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...                 2   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...                 0   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...                 0   \n",
       "15381          [good, morning, ados, black, women, only]                 0   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...                 3   \n",
       "\n",
       "          labels  is_harmful  harmful_has_explaination  \n",
       "0      [0, 2, 2]        True                      True  \n",
       "1      [2, 2, 0]        True                      True  \n",
       "2      [2, 2, 2]        True                      True  \n",
       "3      [2, 2, 2]        True                      True  \n",
       "4      [2, 2, 2]        True                      True  \n",
       "...          ...         ...                       ...  \n",
       "15378  [2, 2, 1]       False                      True  \n",
       "15379  [1, 1, 2]       False                      True  \n",
       "15380  [1, 1, 1]       False                      True  \n",
       "15381  [1, 1, 1]       False                      True  \n",
       "15382  [0, 0, 0]        True                      True  \n",
       "\n",
       "[15383 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistent:  True\n"
     ]
    }
   ],
   "source": [
    "df['is_harmful'] = df['labels'].apply(lambda x: 1 not in x)\n",
    "df['harmful_has_explaination'] = (df['count_rationales'] > 0 & df['is_harmful']) | (df['count_rationales'] == 0 & ~df['is_harmful'])\n",
    "display(df)\n",
    "print('Consistent: ',df['harmful_has_explaination'].all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93c520-284b-47a1-bb88-4ef2dd8cf556",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Dans les cas où personne ne trouve le commentaire nuisible, aucun raisonnement est fourni.\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c5746c-8a5e-4a67-9b40-e92138e79b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>count_rationales</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_harmful</th>\n",
       "      <th>harmful_has_explaination</th>\n",
       "      <th>count_harmful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>{'label': [0, 2, 2], 'annotator_id': [203, 204...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [27, 6, 4...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [209, 203...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [235, 222...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...</td>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [51, 25, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>1125944647509917699_twitter</td>\n",
       "      <td>{'label': [2, 2, 1], 'annotator_id': [217, 206...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...</td>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>1191705189587341312_twitter</td>\n",
       "      <td>{'label': [1, 1, 2], 'annotator_id': [209, 200...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>1178822728511606786_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [127, 17,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>1179009825432358913_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [49, 18, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>24503772_gab</td>\n",
       "      <td>{'label': [0, 0, 0], 'annotator_id': [9, 1, 64...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0                     23107796_gab   \n",
       "1                      9995600_gab   \n",
       "2      1227920812235051008_twitter   \n",
       "3      1204931715778543624_twitter   \n",
       "4      1179102559241244672_twitter   \n",
       "...                            ...   \n",
       "15378  1125944647509917699_twitter   \n",
       "15379  1191705189587341312_twitter   \n",
       "15380  1178822728511606786_twitter   \n",
       "15381  1179009825432358913_twitter   \n",
       "15382                 24503772_gab   \n",
       "\n",
       "                                              annotators  \\\n",
       "0      {'label': [0, 2, 2], 'annotator_id': [203, 204...   \n",
       "1      {'label': [2, 2, 0], 'annotator_id': [27, 6, 4...   \n",
       "2      {'label': [2, 2, 2], 'annotator_id': [209, 203...   \n",
       "3      {'label': [2, 2, 2], 'annotator_id': [235, 222...   \n",
       "4      {'label': [2, 2, 2], 'annotator_id': [51, 25, ...   \n",
       "...                                                  ...   \n",
       "15378  {'label': [2, 2, 1], 'annotator_id': [217, 206...   \n",
       "15379  {'label': [1, 1, 2], 'annotator_id': [209, 200...   \n",
       "15380  {'label': [1, 1, 1], 'annotator_id': [127, 17,...   \n",
       "15381  {'label': [1, 1, 1], 'annotator_id': [49, 18, ...   \n",
       "15382  {'label': [0, 0, 0], 'annotator_id': [9, 1, 64...   \n",
       "\n",
       "                                              rationales  \\\n",
       "0      [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...   \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...   \n",
       "4      [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                  ...   \n",
       "15378  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...   \n",
       "15379                                                 []   \n",
       "15380                                                 []   \n",
       "15381                                                 []   \n",
       "15382  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                             post_tokens  count_rationales  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...                 2   \n",
       "1      [the, uk, has, threatened, to, return, radioac...                 3   \n",
       "2      [if, english, is, not, imposition, then, hindi...                 2   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...                 2   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...                 3   \n",
       "...                                                  ...               ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...                 2   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...                 0   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...                 0   \n",
       "15381          [good, morning, ados, black, women, only]                 0   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...                 3   \n",
       "\n",
       "          labels  is_harmful  harmful_has_explaination  count_harmful  \n",
       "0      [0, 2, 2]        True                      True              3  \n",
       "1      [2, 2, 0]        True                      True              3  \n",
       "2      [2, 2, 2]        True                      True              3  \n",
       "3      [2, 2, 2]        True                      True              3  \n",
       "4      [2, 2, 2]        True                      True              3  \n",
       "...          ...         ...                       ...            ...  \n",
       "15378  [2, 2, 1]       False                      True              2  \n",
       "15379  [1, 1, 2]       False                      True              1  \n",
       "15380  [1, 1, 1]       False                      True              0  \n",
       "15381  [1, 1, 1]       False                      True              0  \n",
       "15382  [0, 0, 0]        True                      True              3  \n",
       "\n",
       "[15383 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotators fournissent automatiquement l'explication?  False\n"
     ]
    }
   ],
   "source": [
    "df['count_harmful'] = df['labels'].apply(lambda x: sum(x != 1))\n",
    "display(df)\n",
    "print('Annotators fournissent automatiquement l\\'explication? ', (df['count_rationales'] == df['count_harmful']).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03d254-edee-4f7c-b9ad-cea27752b083",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Là où les annotateurs donnes son label comme <i>hatespeech</i> ou <i>offensive</i> ne donne pas systématiquement son raisonnement\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b514282-ab14-4a8b-b2c7-549cb62fdd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>count_rationales</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_harmful</th>\n",
       "      <th>harmful_has_explaination</th>\n",
       "      <th>count_harmful</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>{'label': [0, 2, 2], 'annotator_id': [203, 204...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [27, 6, 4...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [209, 203...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [235, 222...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...</td>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [51, 25, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>1125944647509917699_twitter</td>\n",
       "      <td>{'label': [2, 2, 1], 'annotator_id': [217, 206...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...</td>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>1191705189587341312_twitter</td>\n",
       "      <td>{'label': [1, 1, 2], 'annotator_id': [209, 200...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 2]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>1178822728511606786_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [127, 17,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>1179009825432358913_twitter</td>\n",
       "      <td>{'label': [1, 1, 1], 'annotator_id': [49, 18, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>24503772_gab</td>\n",
       "      <td>{'label': [0, 0, 0], 'annotator_id': [9, 1, 64...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "0                     23107796_gab   \n",
       "1                      9995600_gab   \n",
       "2      1227920812235051008_twitter   \n",
       "3      1204931715778543624_twitter   \n",
       "4      1179102559241244672_twitter   \n",
       "...                            ...   \n",
       "15378  1125944647509917699_twitter   \n",
       "15379  1191705189587341312_twitter   \n",
       "15380  1178822728511606786_twitter   \n",
       "15381  1179009825432358913_twitter   \n",
       "15382                 24503772_gab   \n",
       "\n",
       "                                              annotators  \\\n",
       "0      {'label': [0, 2, 2], 'annotator_id': [203, 204...   \n",
       "1      {'label': [2, 2, 0], 'annotator_id': [27, 6, 4...   \n",
       "2      {'label': [2, 2, 2], 'annotator_id': [209, 203...   \n",
       "3      {'label': [2, 2, 2], 'annotator_id': [235, 222...   \n",
       "4      {'label': [2, 2, 2], 'annotator_id': [51, 25, ...   \n",
       "...                                                  ...   \n",
       "15378  {'label': [2, 2, 1], 'annotator_id': [217, 206...   \n",
       "15379  {'label': [1, 1, 2], 'annotator_id': [209, 200...   \n",
       "15380  {'label': [1, 1, 1], 'annotator_id': [127, 17,...   \n",
       "15381  {'label': [1, 1, 1], 'annotator_id': [49, 18, ...   \n",
       "15382  {'label': [0, 0, 0], 'annotator_id': [9, 1, 64...   \n",
       "\n",
       "                                              rationales  \\\n",
       "0      [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "1      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...   \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...   \n",
       "4      [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                  ...   \n",
       "15378  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,...   \n",
       "15379                                                 []   \n",
       "15380                                                 []   \n",
       "15381                                                 []   \n",
       "15382  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                             post_tokens  count_rationales  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...                 2   \n",
       "1      [the, uk, has, threatened, to, return, radioac...                 3   \n",
       "2      [if, english, is, not, imposition, then, hindi...                 2   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...                 2   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...                 3   \n",
       "...                                                  ...               ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...                 2   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...                 0   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...                 0   \n",
       "15381          [good, morning, ados, black, women, only]                 0   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...                 3   \n",
       "\n",
       "          labels  is_harmful  harmful_has_explaination  count_harmful  label  \n",
       "0      [0, 2, 2]        True                      True              3      2  \n",
       "1      [2, 2, 0]        True                      True              3      2  \n",
       "2      [2, 2, 2]        True                      True              3      2  \n",
       "3      [2, 2, 2]        True                      True              3      2  \n",
       "4      [2, 2, 2]        True                      True              3      2  \n",
       "...          ...         ...                       ...            ...    ...  \n",
       "15378  [2, 2, 1]       False                      True              2      2  \n",
       "15379  [1, 1, 2]       False                      True              1      1  \n",
       "15380  [1, 1, 1]       False                      True              0      1  \n",
       "15381  [1, 1, 1]       False                      True              0      1  \n",
       "15382  [0, 0, 0]        True                      True              3      0  \n",
       "\n",
       "[15383 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a-t'il des commentaires négatifs sans raisonnement?  False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['label'] = df['annotators'].apply(lambda x: np.bincount(x['label']).argmax())\n",
    "display(df)\n",
    "print('Il y a-t\\'il des commentaires négatifs sans raisonnement? ', ((df['label'] != 1) & (df['count_rationales'] == 0)).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bed02a-818c-4238-9c5b-2d9504aa5311",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Si la vote donne un négatif (0 ou 2), on a au moins une explication (<i>rationales</i>)\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceecbb04-373a-4744-9ee5-c9daa2bd9e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does all rationale has equal length? False\n",
      "How many comments that have this problem? 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>count_rationales</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_harmful</th>\n",
       "      <th>harmful_has_explaination</th>\n",
       "      <th>count_harmful</th>\n",
       "      <th>label</th>\n",
       "      <th>length_rationale_consistent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>24439295_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [222, 209...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[my, rhymes, pass, any, bar, exam, they, call,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                         annotators  \\\n",
       "1997  24439295_gab  {'label': [2, 2, 0], 'annotator_id': [222, 209...   \n",
       "\n",
       "                                             rationales  \\\n",
       "1997  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                            post_tokens  count_rationales  \\\n",
       "1997  [my, rhymes, pass, any, bar, exam, they, call,...                 2   \n",
       "\n",
       "         labels  is_harmful  harmful_has_explaination  count_harmful  label  \\\n",
       "1997  [2, 2, 0]        True                      True              3      2   \n",
       "\n",
       "      length_rationale_consistent  \n",
       "1997                        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale length:  [47, 48] // Token length: 47\n"
     ]
    }
   ],
   "source": [
    "df['length_rationale_consistent'] = df['rationales'].apply(lambda x: len(set([_x.shape[0] for _x in x])) == 1 or len(x) == 0)\n",
    "print('Does all rationale has equal length?', df['length_rationale_consistent'].all())\n",
    "print('How many comments that have this problem?', (~df['length_rationale_consistent']).sum())\n",
    "insconsistent = df[~df['length_rationale_consistent']]\n",
    "display(insconsistent)\n",
    "for idx in insconsistent.index:\n",
    "    rationales = df.loc[idx, 'rationales']\n",
    "    print('Rationale length: ', [len(l) for l in rationales], '// Token length:', len(df.loc[idx, 'post_tokens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b06b5-d17d-43ff-b4f4-30fba650552c",
   "metadata": {},
   "source": [
    "Is this the case for test and val?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e87bf2-00b4-47fe-98f1-061054a33b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train :\n",
      "Does all rationale has equal length? False\n",
      "How many comments that have this problem? 1\n",
      "In validation :\n",
      "Does all rationale has equal length? True\n",
      "How many comments that have this problem? 0\n",
      "In test :\n",
      "Does all rationale has equal length? True\n",
      "How many comments that have this problem? 0\n"
     ]
    }
   ],
   "source": [
    "for split, splitset in dataset.items():\n",
    "    print('In',split,':')\n",
    "    df = splitset.to_pandas()\n",
    "    df['length_rationale_consistent'] = df['rationales'].apply(lambda x: len(set([_x.shape[0] for _x in x])) == 1 or len(x) == 0)\n",
    "    print('Does all rationale has equal length?', df['length_rationale_consistent'].all())\n",
    "    print('How many comments that have this problem?', (~df['length_rationale_consistent']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a88b2-f98a-422b-9b76-cccfc09eeb43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Juste un cas particulier dans l'explication du train set\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8ad1bc-51a7-4b9d-ba10-f1d43be65b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>rationale</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_tokens  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...   \n",
       "1      [the, uk, has, threatened, to, return, radioac...   \n",
       "2      [if, english, is, not, imposition, then, hindi...   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...   \n",
       "...                                                  ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...   \n",
       "15381          [good, morning, ados, black, women, only]   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...   \n",
       "\n",
       "                                               rationale       label  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...   offensive  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   offensive  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]   offensive  \n",
       "3                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   offensive  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   offensive  \n",
       "...                                                  ...         ...  \n",
       "15378  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   offensive  \n",
       "15379                                                 []      normal  \n",
       "15380                                                 []      normal  \n",
       "15381                                                 []      normal  \n",
       "15382  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  hatespeech  \n",
       "\n",
       "[15383 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct the example\n",
    "df = train_set.to_pandas()\n",
    "rationales = df.loc[1997, 'rationales']\n",
    "L = len(df.loc[1997, 'post_tokens'])\n",
    "rationales = [r[:L] for r in rationales]\n",
    "df.loc[1997, 'rationales'] = rationales\n",
    "\n",
    "df['rationale']  = df['rationales'].apply(lambda x: (np.mean([r.astype(float) for r in x], axis=0) >= 0.5).astype(int) if len(x) > 0 else x)\n",
    "df['label'] = df['annotators'].apply(lambda x: np.bincount(x['label']).argmax())\n",
    "df = df.drop(columns=['annotators', 'rationales', 'id'])\n",
    "\n",
    "int2str = ['hatespeech', 'normal', 'offensive'] # label from huggingface\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: int2str[x]).astype('category')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "523b9de2-3b66-4887-8519-54d68861ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'annotators', 'rationales', 'post_tokens'],\n",
       "    num_rows: 15383\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411934f1-7079-408b-a832-74daedccd487",
   "metadata": {},
   "source": [
    "## Checking problem with dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf7357-6cdb-4038-a028-6b83e5251020",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Check if #tokens != #rationale\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8c9c6a-d986-4dc8-995e-88522f431f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train > False\n",
      "val > False\n",
      "test > False\n"
     ]
    }
   ],
   "source": [
    "from data.hatexplain.dataset import HateXPlain\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    dataset = HateXPlain(root=dataset_path, split=split)\n",
    "    dataset.data['count_tokens'] = dataset.data['post_tokens'].str.len()\n",
    "    dataset.data['count_rationale'] = dataset.data['rationale'].str.len()\n",
    "    print(split,'>', ((dataset.data['count_tokens'] != dataset.data['count_rationale']) & (dataset.data['count_rationale'] > 0)).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce9d5740-1322-40d5-bf5e-ca26698bb484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>count_tokens</th>\n",
       "      <th>count_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_tokens, label, rationale, heuristic, count_tokens, count_rationale]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[(dataset.data['count_tokens'] != dataset.data['count_rationale']) & (dataset.data['count_rationale'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d62b8-210b-42c8-87be-0b0dbf6759e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Checking if there are hateful/offensive contents having no rationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6441b4b-f0cc-450d-a94b-370f303ebc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data['sum_rationale'] = dataset.data['rationale'].map(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc955d1-3617-4ec9-988e-fc0e4d85d87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.data['sum_rationale'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ab1327f-8531-413a-9a60-df19049fe4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split : train\n",
      "Number of post that has 0 rationale :  3 / 9132 ( 0.03 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>sum_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>[muslims, have, been, enslaving, and, raping, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0102198993099...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>[&lt;user&gt;, not, good, good, vs, bad, more, like,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0009191050386161296, 0.0009191050...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>[boo, sorry, did, i, scare, you, wassup, gurl,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 5.487194260394804e-05, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            post_tokens       label  \\\n",
       "626   [muslims, have, been, enslaving, and, raping, ...   offensive   \n",
       "2594  [<user>, not, good, good, vs, bad, more, like,...  hatespeech   \n",
       "5947  [boo, sorry, did, i, scare, you, wassup, gurl,...   offensive   \n",
       "\n",
       "                                              rationale  \\\n",
       "626   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2594  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5947  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              heuristic  sum_rationale  \n",
       "626   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0102198993099...              0  \n",
       "2594  [0.0, 0.0, 0.0009191050386161296, 0.0009191050...              0  \n",
       "5947  [0.0, 5.487194260394804e-05, 0.0, 0.0, 0.0, 0....              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Split : val\n",
      "Number of post that has 0 rationale :  0 / 1141 ( 0.0 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>sum_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_tokens, label, rationale, heuristic, sum_rationale]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Split : test\n",
      "Number of post that has 0 rationale :  1 / 1142 ( 0.09 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>sum_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>[i, think, ancestry, com, only, exists, to, tr...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_tokens       label  \\\n",
       "513  [i, think, ancestry, com, only, exists, to, tr...  hatespeech   \n",
       "\n",
       "                                             rationale  \\\n",
       "513  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             heuristic  sum_rationale  \n",
       "513  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010...              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'val', 'test']:\n",
    "    print('Split :', split)\n",
    "    dataset = HateXPlain(root=dataset_path, split=split)\n",
    "    data = dataset.data.copy()\n",
    "    data = data[data['label'] != 'normal']\n",
    "    data['sum_rationale'] = data['rationale'].apply(sum)\n",
    "    nb_0_rationale = (data['sum_rationale'] == 0).sum()\n",
    "    print('Number of post that has 0 rationale : ', nb_0_rationale,'/', len(data), '(', round(nb_0_rationale*100/len(data), 2),'%)')\n",
    "    display(data[data['sum_rationale'] == 0])\n",
    "    \n",
    "    print('='*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0eea7-ffff-4f64-a3cc-f94d4ae257ec",
   "metadata": {},
   "source": [
    "## Correct existing datasets for thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b0a70718dc1097dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:10:52.837928Z",
     "start_time": "2024-04-12T09:10:52.807638Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cache_path = path.join(os.getcwd(), '..', '.cache')\n",
    "dataset_path = path.join(cache_path, 'dataset')\n",
    "tmp_path = path.join('.cache', '2022-07-27')\n",
    "os.makedirs(tmp_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b798c184-35d1-4eea-98cd-e4c77411f9e2",
   "metadata": {},
   "source": [
    "### Add columns: POS, stopwors, morpho-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "438c93df-3287-440c-8d4e-3f1046586aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:13:35.158763Z",
     "start_time": "2024-04-12T09:13:33.368413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18-04-2024 16:14:08 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1758651355.py:<cell line: 9>:12 \u001b[0m \u001b[34mLoad parquet /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.parquet\u001b[0m\n",
      "18-04-2024 16:14:09 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1758651355.py:<cell line: 9>:24 \u001b[0m \u001b[34mColumn {column} in data,\u001b[0m\n",
      "18-04-2024 16:14:09 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1758651355.py:<cell line: 9>:24 \u001b[0m \u001b[34mColumn {column} in data,\u001b[0m\n",
      "18-04-2024 16:14:09 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1758651355.py:<cell line: 9>:24 \u001b[0m \u001b[34mColumn {column} in data,\u001b[0m\n",
      "18-04-2024 16:14:09 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1758651355.py:<cell line: 9>:26 \u001b[0m \u001b[34mNo need to preprocess\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "sm = spacy.load('en_core_web_sm')\n",
    "from spacy.tokens import Doc\n",
    "import pandas as pd\n",
    "\n",
    "# Correct the example\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "for split in splits:\n",
    "    \n",
    "    parquet_path = path.join(dataset_path, 'hatexplain', split+'.parquet')\n",
    "    log.info(f'Load parquet {parquet_path}')\n",
    "    data = pd.read_parquet(parquet_path)\n",
    "    data['tokens.form'] = data['post_tokens'].copy()\n",
    "    \n",
    "    # Check if we need to preprocess\n",
    "    need_preprocess = False\n",
    "    for column in ['tokens.pos', 'tokens.norm', 'tokens.is_stop']:\n",
    "        if column not in data:\n",
    "            need_preprocess = True\n",
    "            log.info(f'Column {column} not in data, preprocess')\n",
    "            break \n",
    "        else:\n",
    "            log.info('Column {column} in data,')\n",
    "    if not need_preprocess: \n",
    "        log.info('No need to preprocess')\n",
    "        break\n",
    "    \n",
    "    # Preprocess tokens\n",
    "    docs = [Doc(sm.vocab, words=tok_sentence) for tok_sentence in data['post_tokens']]\n",
    "    docs = list(sm.pipe(docs))\n",
    "    \n",
    "    tokens_pos = []\n",
    "    tokens_norm = []\n",
    "    tokens_is_stop = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        tokens_pos.append([tk.pos_ for tk in doc])\n",
    "        tokens_norm.append([tk.lemma_.lower() for tk in doc])\n",
    "        tokens_is_stop.append([tk.is_stop for tk in doc])\n",
    "    \n",
    "    data['tokens.pos'] = tokens_pos\n",
    "    data['tokens.norm'] = tokens_norm\n",
    "    data['tokens.is_stop'] = tokens_is_stop\n",
    "    \n",
    "    morpho_filter = data[['tokens.is_stop', 'tokens.pos']].apply(\n",
    "        lambda x: [(pos in ['NOUN', 'VERB', 'ADJ']) and (not is_stop) for pos, is_stop in zip(x['tokens.pos'], x['tokens.is_stop'])], axis=1\n",
    "        )\n",
    "    \n",
    "    data['morpho_filter'] = morpho_filter\n",
    "    # Check length between tokens vs morpho_filter\n",
    "    assert data['morpho_filter'].str.len().equals(data['post_tokens'].str.len()), f'Incompatible length'\n",
    "    \n",
    "    data.to_parquet(parquet_path)\n",
    "    log.info(f'Saved in {parquet_path}')\n",
    "    \n",
    "    json_path = path.join(dataset_path, 'hatexplain', split+'.json')\n",
    "    data.to_json(json_path)\n",
    "    log.info(f'Saved in {json_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310278a-beb5-4d09-a5ea-1ccc9093dad0",
   "metadata": {},
   "source": [
    "### From `parquet` to `json`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22fec071-562e-41c5-aa75-f44c1ca51760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-04-2024 14:44:14 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:7 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.parquet\u001b[0m\n",
      "12-04-2024 14:44:14 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:19 \u001b[0m \u001b[34mSave /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.json\u001b[0m\n",
      "12-04-2024 14:44:14 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:7 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/val.parquet\u001b[0m\n",
      "12-04-2024 14:44:15 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:19 \u001b[0m \u001b[34mSave /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/val.json\u001b[0m\n",
      "12-04-2024 14:44:15 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:7 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/test.parquet\u001b[0m\n",
      "12-04-2024 14:44:15 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 230696762.py:<cell line: 4>:19 \u001b[0m \u001b[34mSave /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/test.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Correct the example\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "for split in splits:\n",
    "    parquet_path = path.join(dataset_path, 'hatexplain', split+'.parquet')\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    log.debug(f'Load {parquet_path}')\n",
    "\n",
    "    # Drop useless columns\n",
    "    df = df.drop(columns=['annotators.annotator_id'])\n",
    "\n",
    "    # Convert into list\n",
    "    columns_np2list = ['post_tokens', 'tokens.form', 'tokens.norm', 'tokens.pos', 'tokens.is_stop', 'morpho_filter']\n",
    "    df[columns_np2list] = df[columns_np2list].apply(lambda x: [_x.tolist() for _x in x])\n",
    "\n",
    "    # Save to json\n",
    "    json_path = path.join(dataset_path, 'hatexplain', split+'.json')\n",
    "    df.to_json(json_path)\n",
    "    log.info(f'Save {json_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cfdcf0-c60d-4627-b0e8-206b6482a04c",
   "metadata": {},
   "source": [
    "### Correct heuristic columns. `heuristic` -> `heuristics`. Add column `tokens.frequency`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08063bce-0a5d-4878-a763-6f5296f2fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-04-2024 16:34:04 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 2543924955.py:<cell line: 25>:27 \u001b[0m \u001b[34mSave annotation frequency in /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/annotation_lexical_frequency.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Count token frequency only in train split.\n",
    "df_train = pd.read_json(path.join(dataset_path, 'hatexplain', 'train.json'))\n",
    "\n",
    "## 1. Count annotation frequency and token frequency\n",
    "\n",
    "# Flatten tokens and annotations\n",
    "tokens_norm = [item for row in df_train['tokens.norm'].tolist() for item in row]\n",
    "tokens_annot = [item for row in df_train['rationale'].tolist() for item in row]\n",
    "\n",
    "cnt = {'exist': dict(), 'annot' : dict()}\n",
    "for token, annot in zip(tokens_norm, tokens_annot):\n",
    "    cnt['exist'][token] = cnt['exist'].get(token, 0) + 1\n",
    "    if annot > 0:\n",
    "        cnt['annot'][token] = cnt['annot'].get(token, 0) + 1\n",
    "        \n",
    "## In this new version, use the normalized tokens to count!\n",
    "## 2. For each tokens, find the P(token w_i annotated|w_i)\n",
    "token_frequency = dict()\n",
    "for token in cnt['annot']:\n",
    "    token_frequency[token] = cnt['annot'][token] / cnt['exist'][token]\n",
    "token_frequency = dict(sorted(token_frequency.items(), key=lambda item: -item[1]))\n",
    "\n",
    "## 3. Save in new `annotation_lexical_frequency`\n",
    "freq_path = path.join(dataset_path, 'hatexplain', 'annotation_lexical_frequency.json')\n",
    "with open(freq_path, 'w') as f:\n",
    "    json.dump(token_frequency, f, indent='\\t')\n",
    "    log.info(f'Save annotation frequency in {freq_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "272e293f-f4ac-4730-8fdd-bffe8dae724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-04-2024 03:42:50 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:15 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.json\u001b[0m\n",
      "14-04-2024 03:42:50 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:18 \u001b[0m \u001b[34mheuristics column exists\u001b[0m\n",
      "14-04-2024 03:42:50 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:15 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/val.json\u001b[0m\n",
      "14-04-2024 03:42:50 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:18 \u001b[0m \u001b[34mheuristics column exists\u001b[0m\n",
      "14-04-2024 03:42:50 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:15 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/test.json\u001b[0m\n",
      "14-04-2024 03:42:50 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 1827972420.py:<cell line: 12>:18 \u001b[0m \u001b[34mheuristics column exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "freq_path = path.join(dataset_path, 'hatexplain', 'annotation_lexical_frequency.json')\n",
    "with open(freq_path, 'r') as f:\n",
    "    token_frequency = json.load(f)\n",
    "\n",
    "# Now remake the heursitic for all splits:\n",
    "def heuristics(x):\n",
    "    morpho_filter = [float(_x) for _x in x['morpho_filter']]\n",
    "    heuris_score = [token_frequency.get(tok, 0) for tok in x['tokens.norm']]\n",
    "    heuristics = [h*f for h, f in zip(heuris_score, morpho_filter)]\n",
    "    return heuristics\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    json_path = path.join(dataset_path, 'hatexplain', split+'.json')\n",
    "    data = pd.read_json(json_path)\n",
    "    log.debug(f'Load {json_path}')\n",
    "    \n",
    "    if 'heuristics' in data:\n",
    "        log.info('heuristics column exists')\n",
    "        continue\n",
    "    \n",
    "    data['heuristics'] = data.apply(heuristics, axis=1)\n",
    "    \n",
    "    data.to_json(json_path)\n",
    "    log.info(f'Save {json_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fe8c6748-499e-4ad3-a4df-0146e65c8913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-04-2024 03:43:18 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:9 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.json\u001b[0m\n",
      "14-04-2024 03:43:19 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:18 \u001b[0m \u001b[34mSave /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/train.json\u001b[0m\n",
      "14-04-2024 03:43:19 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:9 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/val.json\u001b[0m\n",
      "14-04-2024 03:43:19 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:18 \u001b[0m \u001b[34mSave /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/val.json\u001b[0m\n",
      "14-04-2024 03:43:19 | \u001b[32;1m   DEBUG\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:9 \u001b[0m \u001b[32;1mLoad /Users/dunguyen/Developer/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/hatexplain/test.json\u001b[0m\n",
      "14-04-2024 03:43:19 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 3930555517.py:<cell line: 6>:12 \u001b[0m \u001b[34mtokens.frequency column exists\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "freq_path = path.join(dataset_path, 'hatexplain', 'annotation_lexical_frequency.json')\n",
    "\n",
    "with open(freq_path, 'r') as f:\n",
    "    token_frequency = json.load(f)\n",
    "    \n",
    "for split in ['train', 'val', 'test']:\n",
    "    json_path = path.join(dataset_path, 'hatexplain', split+'.json')\n",
    "    data = pd.read_json(json_path)\n",
    "    log.debug(f'Load {json_path}')\n",
    "    \n",
    "    if 'tokens.frequency' in data:\n",
    "        log.info('tokens.frequency column exists')\n",
    "        continue      \n",
    "    \n",
    "    data['tokens.frequency'] = data['tokens.norm'].apply(lambda x: [ token_frequency.get(tk, 0) for tk in x])\n",
    "    \n",
    "    data.to_json(json_path)\n",
    "    log.info(f'Save {json_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77af319-ea17-4a6c-a5be-bb90d43bba1b",
   "metadata": {},
   "source": [
    "### Evaluate plausibility of heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bb6f9-847d-4797-bdf4-ed618fd2def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as m\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from modules import rescale\n",
    "\n",
    "# setup metrics\n",
    "auprc = m.AveragePrecision(average='micro')\n",
    "auroc = m.AUROC(average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b170a9-bae7-4a43-a89a-c8ed2de07fc5",
   "metadata": {},
   "source": [
    "Evaluate the `heuristics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4248b10d-433b-4578-8aa4-92395c6c6532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dd16f0d37847e0b4ae22c3287335aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC: tensor(0.5136)\n",
      "AUROC: tensor(0.6149)\n"
     ]
    }
   ],
   "source": [
    "# Load datatet\n",
    "df = pd.read_json(path.join(dataset_path, 'hatexplain', 'test.json'))\n",
    "\n",
    "# filter neutral labels\n",
    "df = df[df['label'] != 'normal'].reset_index(drop=True)\n",
    "heuristics = df['heuristics'].tolist()\n",
    "annotations = df['rationale'].tolist()\n",
    "\n",
    "# stacking heuristics\n",
    "for a_heuris, a_true in tqdm(zip(heuristics, annotations), total=len(heuristics), desc=split):\n",
    "    a_heuris = torch.tensor(a_heuris)\n",
    "    a_true = torch.tensor(a_true)\n",
    "\n",
    "    # normalize heuristics\n",
    "    a_heuris = a_heuris/a_heuris.sum()\n",
    "    a_heuris = rescale(a_heuris)\n",
    "\n",
    "    auprc.update(a_heuris, a_true)\n",
    "    auroc.update(a_heuris, a_true)\n",
    "\n",
    "# report\n",
    "print('AUPRC:', auprc.compute())\n",
    "print('AUROC:', auroc.compute())\n",
    "auprc.reset()\n",
    "auroc.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a55a1ca-0d9c-41bb-b7bb-2f64e9eb6922",
   "metadata": {},
   "source": [
    "Evaluate the `heuristic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fc7b8eff-074a-40b0-97ee-a207f0867687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebfa7b1a734403492f450a12f53d99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/1142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC: tensor(0.3521)\n",
      "AUROC: tensor(0.5213)\n"
     ]
    }
   ],
   "source": [
    "# Load datatet\n",
    "df = pd.read_json(path.join(dataset_path, 'hatexplain', 'test.json'))\n",
    "\n",
    "# filter neutral labels\n",
    "df = df[df['label'] != 'normal']\n",
    "heuristics = df['heuristic'].tolist()\n",
    "annotations = df['rationale'].tolist()\n",
    "\n",
    "# stacking heuristics\n",
    "for a_heuris, a_true in tqdm(zip(heuristics, annotations), total=len(heuristics), desc=split):\n",
    "    a_heuris = torch.tensor(a_heuris)\n",
    "    a_true = torch.tensor(a_true)\n",
    "\n",
    "    # normalize heuristics\n",
    "    #a_heuris = a_heuris/a_heuris.sum()\n",
    "    a_heuris = rescale(a_heuris)\n",
    "\n",
    "    auprc.update(a_heuris, a_true)\n",
    "    auroc.update(a_heuris, a_true)\n",
    "\n",
    "# report\n",
    "print('AUPRC:', auprc.compute())\n",
    "print('AUROC:', auroc.compute())\n",
    "auprc.reset()\n",
    "auroc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7df799-4715-4841-8470-734d6916dbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e04d0ce2-642c-4c98-9c5f-4834fbb732b5",
   "metadata": {},
   "source": [
    "## Find words statistics for class prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53eb771-dacc-4d74-948c-9d6bd23d90cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T13:28:41.540794Z",
     "start_time": "2023-08-31T13:28:24.465950Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.hatexplain.dataset import HateXPlain\n",
    "\n",
    "# Load dataset\n",
    "dataset = HateXPlain(root=dataset_path, split='test')\n",
    "tokens = dataset.data['post_tokens']\n",
    "rationale = dataset.data['rationale']\n",
    "\n",
    "# Add punctuation to separate sentences\n",
    "for i in range(len(tokens)):\n",
    "    tokens[i].append('.')\n",
    "    rationale[i].append(0)\n",
    "\n",
    "\n",
    "# Find postag\n",
    "from spacy.tokens import Doc\n",
    "import spacy\n",
    "\n",
    "flatten_token = [tk for sent in tokens for tk in sent]\n",
    "flatten_rationale = [r for sent in rationale for r in sent]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = Doc(nlp.vocab, words=flatten_token)\n",
    "pos = [tk.pos_ for tk in nlp(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a2f63dd-3948-4f9f-8bb5-cb454fd71dfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T13:28:41.632900Z",
     "start_time": "2023-08-31T13:28:41.542826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc225c2815e45f7a5bee17eb58b209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "cnt_pos = dict()\n",
    "cnt_tok = dict()\n",
    "cnt_pos_total = dict()\n",
    "cnt_tok_total = dict()\n",
    "\n",
    "for p, r, t in tqdm(zip(pos, flatten_rationale, flatten_token), total=len(flatten_rationale)):\n",
    "    \n",
    "    cnt_pos_total[p] = cnt_pos_total.get(p, 0) +1\n",
    "    cnt_tok_total[t] = cnt_tok_total.get(t, 0) +1\n",
    "    \n",
    "    if r > 0:\n",
    "        cnt_pos[p] = cnt_pos.get(p, 0) + 1\n",
    "        cnt_tok[t] = cnt_tok.get(t, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af3233b6-eafa-47da-9346-3c8a7250c712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T13:28:41.683305Z",
     "start_time": "2023-08-31T13:28:41.635973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS of annotations\n",
      "{'NOUN': 2519, 'VERB': 1192, 'ADJ': 1018, 'PRON': 756, 'PROPN': 707, 'ADP': 637, 'DET': 574, 'AUX': 484, 'ADV': 340, 'CCONJ': 236, 'PART': 185, 'SCONJ': 173, 'INTJ': 36, 'NUM': 26, 'X': 13, 'PUNCT': 12, 'SPACE': 2}\n",
      "POS in total\n",
      "{'NOUN': 9360, 'VERB': 6116, 'PRON': 4826, 'ADJ': 4109, 'ADP': 3922, 'DET': 3438, 'PROPN': 3022, 'AUX': 2885, 'ADV': 2145, 'PUNCT': 2052, 'CCONJ': 1258, 'PART': 1152, 'SCONJ': 1098, 'INTJ': 638, 'NUM': 197, 'X': 184, 'SPACE': 34, 'SYM': 7}\n"
     ]
    }
   ],
   "source": [
    "cnt_pos = {k: v for k, v in sorted(cnt_pos.items(), key=lambda item: -item[1])}\n",
    "\n",
    "print('POS of annotations')\n",
    "print(cnt_pos)\n",
    "\n",
    "cnt_pos_total = {k: v for k, v in sorted(cnt_pos_total.items(), key=lambda item: -item[1])}\n",
    "\n",
    "print('POS in total')\n",
    "print(cnt_pos_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8693426d-cfbc-4347-9f6f-daacea8c00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in .cache/2022-07-27/posfreq_hatexplain_test\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.barh(width=cnt_pos_total.values(), y=list(cnt_pos_total.keys()))\n",
    "ax.barh(width=cnt_pos.values(), y=list(cnt_pos.keys()))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_title('POS tag in annotation - HateXPlain')\n",
    "\n",
    "save_path = path.join(tmp_path, 'posfreq_hatexplain_test')\n",
    "plt.savefig(save_path, dpi=600)\n",
    "print('Saved in',save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b22059-7b1e-423a-81f7-d11a97821db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T13:30:24.274579Z",
     "start_time": "2023-08-31T13:29:06.575859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e71397b589e4b15b9ace5e376c51284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/15316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72056c3471d4a90a5fe5341718ae748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/12611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563c9fb44f3f409bbfc3dd0a753c7a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/15133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c4c03355bf462bbd9fef05b8e044f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/12719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe288ea9e8fa47d6a834f7a9576fccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/121254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e23878c23643ed816549c70e466acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/102664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.hatexplain.dataset import HateXPlain\n",
    "\n",
    "cnt = dict()\n",
    "\n",
    "for split in ['test', 'val', 'train']:\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = HateXPlain(root=dataset_path, split=split)\n",
    "        \n",
    "    cnt[split] = {}\n",
    "    \n",
    "    for label in ['hatespeech', 'offensive']:\n",
    "        data = dataset.data.copy()\n",
    "        data = data[data['label'] == label].reset_index()\n",
    "        tokens = data['post_tokens']\n",
    "        rationale = data['rationale']\n",
    "\n",
    "        # Add punctuation to separate sentences\n",
    "        for i in range(len(tokens)):\n",
    "            tokens[i].append('.')\n",
    "            rationale[i].append(0)\n",
    "\n",
    "        flatten_token = [tk for sent in tokens for tk in sent]\n",
    "        flatten_rationale = [r for sent in rationale for r in sent]\n",
    "\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        doc = Doc(nlp.vocab, words=flatten_token)\n",
    "        pos = [tk.pos_ for tk in nlp(doc)]\n",
    "\n",
    "        # Start counting\n",
    "        cnt_pos = dict()\n",
    "        cnt_tok = dict()\n",
    "        cnt_pos_total = dict()\n",
    "        cnt_tok_total = dict()\n",
    "\n",
    "        for p, r, t in tqdm(zip(pos, flatten_rationale, flatten_token), total=len(flatten_rationale), desc=split):\n",
    "\n",
    "            cnt_pos_total[p] = cnt_pos_total.get(p, 0) +1\n",
    "            cnt_tok_total[t] = cnt_tok_total.get(t, 0) +1\n",
    "\n",
    "            if r > 0:\n",
    "                cnt_pos[p] = cnt_pos.get(p, 0) + 1\n",
    "                cnt_tok[t] = cnt_tok.get(t, 0) + 1\n",
    "\n",
    "        cnt[split][label] = {\n",
    "            'pos' : cnt_pos,\n",
    "            'tok' : cnt_tok,\n",
    "            'pos_total': cnt_pos_total,\n",
    "            'tok_total': cnt_tok_total\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d25b8f-aec6-4a93-9a01-8fbb69236a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test hatespeech\n",
      "Annotated POS : 4397 / 15316 ( 28.71 %)\n",
      "Annotated token : 4397 / 15316 ( 28.71 %)\n",
      "===============\n",
      "test offensive\n",
      "Annotated POS : 4513 / 12611 ( 35.79 %)\n",
      "Annotated token : 4513 / 12611 ( 35.79 %)\n",
      "===============\n",
      "val hatespeech\n",
      "Annotated POS : 4474 / 15133 ( 29.56 %)\n",
      "Annotated token : 4474 / 15133 ( 29.56 %)\n",
      "===============\n",
      "val offensive\n",
      "Annotated POS : 4772 / 12719 ( 37.52 %)\n",
      "Annotated token : 4772 / 12719 ( 37.52 %)\n",
      "===============\n",
      "train hatespeech\n",
      "Annotated POS : 34053 / 121254 ( 28.08 %)\n",
      "Annotated token : 34053 / 121254 ( 28.08 %)\n",
      "===============\n",
      "train offensive\n",
      "Annotated POS : 38846 / 102664 ( 37.84 %)\n",
      "Annotated token : 38846 / 102664 ( 37.84 %)\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "# report annotated proportion\n",
    "for split, cnt_split in cnt.items():\n",
    "    for label in cnt_split:\n",
    "        print(split, label)\n",
    "        print('Annotated POS :', sum(cnt[split][label]['pos'].values()), '/', sum(cnt[split][label]['pos_total'].values()), '(', round(sum(cnt[split][label]['pos'].values())*100/sum(cnt[split][label]['pos_total'].values()), 2), '%)')\n",
    "        print('Annotated token :', sum(cnt[split][label]['tok'].values()), '/', sum(cnt[split][label]['tok_total'].values()), '(', round(sum(cnt[split][label]['tok'].values())*100/sum(cnt[split][label]['tok_total'].values()), 2), '%)')\n",
    "        print('='*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eaf2d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'val', 'train'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58af8d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hatespeech', 'offensive'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt['test'].keys(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25e375e-069b-4aaa-ab65-880da4462fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-arrange the dictionary of cnt: first label, then for each label, splits\n",
    "cnt_arranged = dict()\n",
    "for label in cnt['test']:\n",
    "    cnt_arranged[label] = {split: cnt[split][label] for split in cnt.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10d7456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pos', 'tok', 'pos_total', 'tok_total'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt['train']['offensive'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447fb490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hatespeech', 'offensive'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_arranged.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "913b52c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'val', 'train'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_per_label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd6d2e08-7657-403c-bf58-509d3ac32ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pos_total'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, pos_freq_label \u001b[38;5;129;01min\u001b[39;00m pos_freq\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label)\n\u001b[0;32m---> 17\u001b[0m     cnt_pos_total \u001b[38;5;241m=\u001b[39m \u001b[43mpos_freq_label\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos_total\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     18\u001b[0m     cnt_pos \u001b[38;5;241m=\u001b[39m pos_freq_label[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m     ax\u001b[38;5;241m.\u001b[39mbarh(width\u001b[38;5;241m=\u001b[39mcnt_pos_total\u001b[38;5;241m.\u001b[39mvalues(), y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(cnt_pos_total\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pos_total'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, sharey=True)\n",
    "\n",
    "fig.suptitle('POS tag in annotation - HateXPlain', fontsize=20, fontweight='black')\n",
    "\n",
    "for ax_row, label in zip(axes, cnt_arranged):\n",
    "\n",
    "    cnt_per_label = cnt_arranged[label]\n",
    "\n",
    "    for ax, pos_freq, split in zip(ax_row, cnt_per_label.values(), cnt_per_label.keys()):\n",
    "        for label, pos_freq_label in pos_freq.items():\n",
    "            print(label)\n",
    "\n",
    "            cnt_pos_total = pos_freq_label['pos_total']\n",
    "            cnt_pos = pos_freq_label['pos']\n",
    "\n",
    "            ax.barh(width=cnt_pos_total.values(), y=list(cnt_pos_total.keys()))\n",
    "            ax.barh(width=cnt_pos.values(), y=list(cnt_pos.keys()))\n",
    "\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "            ax.set_xlabel('Frequency', fontsize=18)\n",
    "            ax.set_title(split, fontsize=18)\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "#plt.savefig(path.join(tmp_path, 'posfreq_hatexplain'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0b400-56a6-4d6b-9fae-a58b51bb1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total annotated token amont NVA:')\n",
    "(cnt_pos['VERB'] + cnt_pos['NOUN'] + cnt_pos['ADJ']) / sum(cnt_pos.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad84b02-1316-4b5f-bc89-73a2d3ed9979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c0c277e-a12d-4765-afb5-3ae567517320",
   "metadata": {},
   "source": [
    "## Visualize heuristics for thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "34427aeb-9555-4f66-bd01-7e3c832dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/Users/dunguyen/Developer/server_backup/historic/2023-06-05/experiments/illustration_heuristics_hatexplain'\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "html_path = out_path + '/html'\n",
    "os.makedirs(html_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "69405432-ca12-4fce-835f-3d8bdfe1ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(path.join(dataset_path, 'hatexplain', 'train.json'))\n",
    "df = df[df['label'] != 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "abbec7a6-cb23-4457-a140-6d79e356dc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995b07b561fb4d159eef572c8ecc1bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.const import Color\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    \n",
    "    tokens = row['tokens.form']\n",
    "    \n",
    "    html_str = '''<html>\n",
    "    <head>\n",
    "    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css\" integrity=\"sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N\" crossorigin=\"anonymous\">\n",
    "    <style>\n",
    "    table, th, td {\n",
    "      border:solid black;\n",
    "      border-collapse: collapse;\n",
    "      padding: 0px 5px 0px 5px;\n",
    "    }\n",
    "    </style>\n",
    "    </head>\n",
    "    <body>\n",
    "    <table style=\"font-size:120%;\" cellspacing=0>\n",
    "        <caption style=\"text-align: center;\">Dataset: e-SNLI - Instance ID: 726414.jpg#1r1c</caption>\n",
    "        <tr><th style=\"width:200px;\">Explainer</th> <th style=\"width:500px;\">Explanation</th> <th style=\"width:100px;\">Label</th></tr>\n",
    "        <tr>\n",
    "    '''\n",
    "    \n",
    "    html_str += '''<tr><td style=\"text-align:right;\">Anntation map</td><td>''' + highlight(tokens, row['rationale'], color=Color.HIGHLIGHT) +\\\n",
    "                     '''</td><td rowspan=\"4\" style=\"text-align:center\">'''+ row['label'] +'''</td></tr>'''\n",
    "    html_str += '''<tr><td style=\"text-align:right;\">Annotation frequency</td><td>''' + highlight(tokens, row['tokens.frequency'], Color.HEURISTICS) + '''</td></tr>'''\n",
    "    html_str += '''<tr><td style=\"text-align:right;\">Morphosyntactic filter</td><td>''' + highlight(tokens, row['morpho_filter'], Color.HEURISTICS) + '''</td></tr>'''\n",
    "    html_str += '''<tr><td style=\"text-align:right;\">Heuristic map</td><td>''' + highlight(tokens, row['heuristics'], Color.HEURISTICS) + '''</td></tr>'''\n",
    "    \n",
    "    html_str += '''\n",
    "        </tr>\n",
    "    </table></body></html>'''\n",
    "    \n",
    "    #display(HTML(html_str))\n",
    "    with open(html_path + '/' + row['id'] + '.html', 'w') as f:\n",
    "        f.write(html_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a931813-c704-4527-8c23-774d86776e8c",
   "metadata": {},
   "source": [
    "## Check the salient word but irrevent for explanation in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f5c0bb-6eeb-473f-9ff1-905987fc789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HateXPlain(root=dataset_path, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb33039-f1fe-4cff-b97e-7a70743b3146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators.annotator_id</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178610029273976833_twitter</td>\n",
       "      <td>[9, 17, 64]</td>\n",
       "      <td>[&lt;user&gt;, men, can, not, be, raped, can, not, b...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1165785686903009283_twitter</td>\n",
       "      <td>[200, 199, 211]</td>\n",
       "      <td>[&lt;user&gt;, you, are, missing, an, essential, pre...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1252707503441313794_twitter</td>\n",
       "      <td>[233, 215, 202]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, why, are, you, repeating, you...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1103385226921762816_twitter</td>\n",
       "      <td>[206, 199, 203]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, well, she, ’, muslim, so, of,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1169443635869487105_twitter</td>\n",
       "      <td>[205, 223, 208]</td>\n",
       "      <td>[&lt;user&gt;, lol, not, me, i, don, ’, t, deal, wit...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>7645213_gab</td>\n",
       "      <td>[225, 207, 204]</td>\n",
       "      <td>[we, hate, islam, and, we, will, mock, your, p...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>7672117_gab</td>\n",
       "      <td>[13, 4, 46]</td>\n",
       "      <td>[he, sounds, like, a, clothing, line, i, will,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1231804803614830592_twitter</td>\n",
       "      <td>[203, 209, 223]</td>\n",
       "      <td>[4, chan, is, retarded, and, so, are, you]</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00846376493504712, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>26732378_gab</td>\n",
       "      <td>[9, 6, 110]</td>\n",
       "      <td>[plenty, of, e, celebs, have, covered, israid,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>14030104_gab</td>\n",
       "      <td>[9, 43, 4]</td>\n",
       "      <td>[yeah, i, got, to, about, just, over, &lt;number&gt;...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422502...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id annotators.annotator_id  \\\n",
       "0     1178610029273976833_twitter             [9, 17, 64]   \n",
       "1     1165785686903009283_twitter         [200, 199, 211]   \n",
       "2     1252707503441313794_twitter         [233, 215, 202]   \n",
       "3     1103385226921762816_twitter         [206, 199, 203]   \n",
       "4     1169443635869487105_twitter         [205, 223, 208]   \n",
       "...                           ...                     ...   \n",
       "1919                  7645213_gab         [225, 207, 204]   \n",
       "1920                  7672117_gab             [13, 4, 46]   \n",
       "1921  1231804803614830592_twitter         [203, 209, 223]   \n",
       "1922                 26732378_gab             [9, 6, 110]   \n",
       "1923                 14030104_gab              [9, 43, 4]   \n",
       "\n",
       "                                            post_tokens       label  \\\n",
       "0     [<user>, men, can, not, be, raped, can, not, b...      normal   \n",
       "1     [<user>, you, are, missing, an, essential, pre...      normal   \n",
       "2     [<user>, <user>, why, are, you, repeating, you...   offensive   \n",
       "3     [<user>, <user>, well, she, ’, muslim, so, of,...  hatespeech   \n",
       "4     [<user>, lol, not, me, i, don, ’, t, deal, wit...   offensive   \n",
       "...                                                 ...         ...   \n",
       "1919  [we, hate, islam, and, we, will, mock, your, p...  hatespeech   \n",
       "1920  [he, sounds, like, a, clothing, line, i, will,...   offensive   \n",
       "1921         [4, chan, is, retarded, and, so, are, you]   offensive   \n",
       "1922  [plenty, of, e, celebs, have, covered, israid,...  hatespeech   \n",
       "1923  [yeah, i, got, to, about, just, over, <number>...  hatespeech   \n",
       "\n",
       "                                              rationale  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3     [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1919  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1920   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1921                           [0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1922  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1923  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                              heuristic  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "1919  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...  \n",
       "1920  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1921  [0.0, 0.0, 0.0, 0.00846376493504712, 0.0, 0.0,...  \n",
       "1922  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1923  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422502...  \n",
       "\n",
       "[1924 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e983e0-964d-48ae-a4ac-de912e028313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d37ba2d6-f1e2-469c-b062-eacd86918055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'or', 'marxist', 'indoctrination', 'since', 'it', 'is', 'well', 'established', 'blacks', 'are', 'incapable', 'of', 'learning', 'anything', 'past', 'the', 'age', 'of', 'ten', 'unless', 'they', 'are', 'half', 'white', 'should', 'not', 'blacks', 'go', 'to', 'a', 'trade', 'school', 'upon', 'age', '<number>', 'say', 'learning', 'how', 'to', 'pick', 'cotton', 'fruits', 'and', 'vegetables']\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "upon_examples = df[df['post_tokens'].apply(lambda x: 'upon' in x)]\n",
    "upon_examples = upon_examples[upon_examples['label']=='hatespeech']\n",
    "\n",
    "html = '<table>'\n",
    "html = ''\n",
    "for idx, row in upon_examples.iterrows():\n",
    "    print(row['post_tokens'])\n",
    "    print(row['rationale'])\n",
    "    print()\n",
    "    #display(HTML(highlight(row['post_tokens'], row['rationale'])))\n",
    "    \n",
    "html += '</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a04f8b3d-138f-4964-83f9-a7c7a756ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135, 206, 250, 0.0);\">education </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">marxist </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">indoctrination </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">since </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">it </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">is </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">well </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">established </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">blacks </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">are </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">incapable </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">of </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">learning </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">anything </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">past </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">the </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">age </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">of </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">ten </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">unless </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">they </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">are </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">half </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">white </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">should </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">not </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">blacks </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">go </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">to </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">a </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">trade </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">school </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">upon </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">age </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\"><number> </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">say </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">learning </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">how </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">to </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">pick </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">cotton </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">fruits </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">and </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">vegetables </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(highlight(row['post_tokens'], row['rationale'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2124e4f1-3466-4af9-aa69-680b5063b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24305062_gab'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a76b7-00e5-4245-ae22-5bec9a486ec1",
   "metadata": {},
   "source": [
    "## Making of heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea577d1a-1bb3-43df-972d-142706c33335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m pos \u001b[38;5;241m=\u001b[39m [tk\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;28;01mfor\u001b[39;00m tk \u001b[38;5;129;01min\u001b[39;00m nlp(doc)]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# build mask\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m pos_filter \u001b[38;5;241m=\u001b[39m [[tk\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m tk \u001b[38;5;129;01min\u001b[39;00m d] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenized_docs\u001b[49m]\n\u001b[1;32m     22\u001b[0m stop_filter \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;129;01mnot\u001b[39;00m tk\u001b[38;5;241m.\u001b[39mis_stop \u001b[38;5;28;01mfor\u001b[39;00m tk \u001b[38;5;129;01min\u001b[39;00m d] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tokenized_docs]\n\u001b[1;32m     23\u001b[0m mask \u001b[38;5;241m=\u001b[39m [pos_ \u001b[38;5;129;01mand\u001b[39;00m stop_ \u001b[38;5;28;01mfor\u001b[39;00m pos_, stop_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pos_filter, stop_filter)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_docs' is not defined"
     ]
    }
   ],
   "source": [
    "from data.hatexplain.dataset import HateXPlain\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from modules.utils import highlight\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "dataset = HateXPlain(root=dataset_path, split='test')\n",
    "tokens = dataset.data['post_tokens'].tolist()\n",
    "rationale = dataset.data['rationale'].tolist()\n",
    "\n",
    "flatten_token = [tk for sent in tokens for tk in sent]\n",
    "flatten_rationale = [r for sent in rationale for r in sent]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = Doc(nlp.vocab, words=flatten_token)\n",
    "pos = [tk.pos_ for tk in nlp(doc)]\n",
    "\n",
    "# build mask\n",
    "pos_filter = [[tk.pos_ in ['ADJ'] for tk in d] for d in tokenized_docs]\n",
    "stop_filter = [[not tk.is_stop for tk in d] for d in tokenized_docs]\n",
    "mask = [pos_ and stop_ for pos_, stop_ in zip(pos_filter, stop_filter)]\n",
    "\n",
    "# Count frequence\n",
    "token_freq = dict()\n",
    "flatten_token = [tk for sent in tokens for tk in sent]\n",
    "flatten_rationale = [r for sent in rationale for r in sent]\n",
    "\n",
    "for t, r in zip(flatten_token, flatten_rationale):\n",
    "    if r: token_freq[t] = token_freq.get(t, 0) + 1\n",
    "\n",
    "total_freq = sum(token_freq.values())\n",
    "token_freq = {k: v/total_freq for k, v in token_freq.items()}\n",
    "\n",
    "# Making of heuristic\n",
    "heuristics = []\n",
    "for sent_tokens, sent_mask in zip(tokens, mask):\n",
    "    heuris_map = [token_freq.get(tk, 0) for tk in sent_tokens]\n",
    "    heuris_map = [h * float(m) for h, m in zip(heuris_map, sent_mask)]\n",
    "    heuristics.append(heuris_map)\n",
    "\n",
    "tensor_heuristics = [torch.tensor(h) for h in heuristics]\n",
    "for i in range(20):\n",
    "    display(HTML(hightlight(tokens[i], tensor_heuristics[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6cb89-d26f-40ad-9af1-4bc64a192d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic = dataset.data['heuristic']\n",
    "rationale = dataset.data['rationale']\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score = roc_auc_score(rationale, heuristic)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c82d58-ec66-4e76-989a-16065afcbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HateXPlain(root=path.join(cache_path, 'dataset'), split='val')\n",
    "dataset.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffeabd1-f2d2-4b62-b37d-2f1636c45863",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    display(HTML(hightlight(dataset.data.loc[i, 'post_tokens'], torch.tensor(dataset.data.loc[i, 'heuristic']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91017aa2-ac82-4c3a-88d3-0d19c25b1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic = dataset.data['heuristic']\n",
    "rationale = dataset.data['rationale']\n",
    "\n",
    "heuristic = [h_value for h_vector in heuristic for h_value in h_vector]\n",
    "rationale = [r_value for r_vector in rationale for r_value in r_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fb7ba-ce16-4810-81cf-7a907ec1a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_score = roc_auc_score(rationale, heuristic)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf51a01-7ae3-4418-b78b-d36f84602da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val', 'test']:\n",
    "    dataset = HateXPlain(root=path.join(cache_path, 'dataset'), split=split)\n",
    "    heuristic = dataset.data['heuristic']\n",
    "    rationale = dataset.data['rationale']\n",
    "\n",
    "    heuristic = [h_value for h_vector in heuristic for h_value in h_vector]\n",
    "    rationale = [r_value for r_vector in rationale for r_value in r_vector]\n",
    "    roc_score = roc_auc_score(rationale, heuristic)\n",
    "    print(split, ':', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e3c15-ce20-4b98-849e-2eaa2d8f6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HateXPlain(root=path.join(cache_path, 'dataset'), split='test')\n",
    "heuristic = dataset.data['heuristic']\n",
    "rationale = dataset.data['rationale']\n",
    "\n",
    "for i in range(10):\n",
    "    display(HTML(hightlight(dataset.data.loc[i, 'post_tokens'], torch.tensor(dataset.data.loc[i, 'heuristic']))))\n",
    "    \n",
    "roc_score = roc_auc_score(rationale, heuristic)\n",
    "print('AUROC = ', roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6722f373-579b-47a1-9083-ebf9fbe16c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0.0007682071964552725, 0.0, 0.000905387052965...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.00032923165562368824, 0.0, 1.371798565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.0001508978421608571, 0.0, 0.0, 1.37179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[0.0, 0.0005624374116904674, 0.0, 9.6025899556...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0004252575551805973, 1.371798565098701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[5.487194260394804e-05, 0.0, 0.000205769784764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0004938474834355323, 0.0004938474834355323,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0003703856125766492, 0.0, 0.0, 0.0, 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0009191050386161296, 4.115395695296103e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 5.487194260394804e-05, 0.000233205756066...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_tokens       label  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...   offensive   \n",
       "1      [the, uk, has, threatened, to, return, radioac...   offensive   \n",
       "2      [if, english, is, not, imposition, then, hindi...   offensive   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...   offensive   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...   offensive   \n",
       "...                                                  ...         ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...   offensive   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...      normal   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...      normal   \n",
       "15381          [good, morning, ados, black, women, only]      normal   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...  hatespeech   \n",
       "\n",
       "                                               rationale  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
       "3                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "15378  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "15379  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15380  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15381                                 [0, 0, 0, 0, 0, 0]   \n",
       "15382  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                               heuristic  \n",
       "0      [0.0007682071964552725, 0.0, 0.000905387052965...  \n",
       "1      [0.0, 0.00032923165562368824, 0.0, 1.371798565...  \n",
       "2      [0.0, 0.0001508978421608571, 0.0, 0.0, 1.37179...  \n",
       "3      [0.0, 0.0005624374116904674, 0.0, 9.6025899556...  \n",
       "4      [0.0, 0.0004252575551805973, 1.371798565098701...  \n",
       "...                                                  ...  \n",
       "15378  [5.487194260394804e-05, 0.0, 0.000205769784764...  \n",
       "15379  [0.0004938474834355323, 0.0004938474834355323,...  \n",
       "15380  [0.0, 0.0003703856125766492, 0.0, 0.0, 0.0, 5....  \n",
       "15381  [0.0009191050386161296, 4.115395695296103e-05,...  \n",
       "15382  [0.0, 5.487194260394804e-05, 0.000233205756066...  \n",
       "\n",
       "[15383 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2196d577-9c12-45a6-a2d1-16bb45d4ec61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isnan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mheuristic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isnan'"
     ]
    }
   ],
   "source": [
    "heuristic.isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b316e6c6-5e6a-41a6-983c-e932a8406391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : 0.5044194852915073\n",
      "val : 0.5280741352217981\n",
      "test : 0.522427389102623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from data.hatexplain.dataset import HateXPlain\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    dataset = HateXPlain(root=path.join(cache_path, 'dataset'), split=split)\n",
    "    dataset.data = dataset.data[dataset.data['label'] != 'normal'].reset_index()\n",
    "    \n",
    "    h_vectors = [np.array(h_vector)/sum(h_vector) for h_vector in dataset.data['heuristic']]\n",
    "    h_vectors = [(h-h.min())/(h.max()-h.min() + (h.max()==h.min())) for h in h_vectors]\n",
    "    heuristic = np.concatenate(h_vectors)\n",
    "    \n",
    "    rationale = np.array([r_value for r_vector in dataset.data['rationale'] for r_value in r_vector])\n",
    "    auprc = average_precision_score(rationale, heuristic)\n",
    "    \n",
    "    print(split, ':', auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367b3a2-0026-4ff2-b05d-e824621514ab",
   "metadata": {},
   "source": [
    "## Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2d178a-ef97-4c5c-afd1-60487ae6d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_module.hatexplain_module import HateXPlainDM\n",
    "from data.hatexplain.dataset import HateXPlain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce8b77e-fffa-4546-ae60-e2778942b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatexplain = HateXPlain(root=dataset_path, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8213f0c9-3f25-4930-a70b-0d72f620a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotators.annotator_id</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[9, 17, 64]</td>\n",
       "      <td>[&lt;user&gt;, men, can, not, be, raped, can, not, b...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[200, 199, 211]</td>\n",
       "      <td>[&lt;user&gt;, you, are, missing, an, essential, pre...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[233, 215, 202]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, why, are, you, repeating, you...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[206, 199, 203]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, well, she, ’, muslim, so, of,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[205, 223, 208]</td>\n",
       "      <td>[&lt;user&gt;, lol, not, me, i, don, ’, t, deal, wit...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>[225, 207, 204]</td>\n",
       "      <td>[we, hate, islam, and, we, will, mock, your, p...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>[13, 4, 46]</td>\n",
       "      <td>[he, sounds, like, a, clothing, line, i, will,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>[203, 209, 223]</td>\n",
       "      <td>[4, chan, is, retarded, and, so, are, you]</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.008463997146658984, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>[9, 6, 110]</td>\n",
       "      <td>[plenty, of, e, celebs, have, covered, israid,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>[9, 43, 4]</td>\n",
       "      <td>[yeah, i, got, to, about, just, over, &lt;number&gt;...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422513...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotators.annotator_id  \\\n",
       "0                [9, 17, 64]   \n",
       "1            [200, 199, 211]   \n",
       "2            [233, 215, 202]   \n",
       "3            [206, 199, 203]   \n",
       "4            [205, 223, 208]   \n",
       "...                      ...   \n",
       "1919         [225, 207, 204]   \n",
       "1920             [13, 4, 46]   \n",
       "1921         [203, 209, 223]   \n",
       "1922             [9, 6, 110]   \n",
       "1923              [9, 43, 4]   \n",
       "\n",
       "                                            post_tokens       label  \\\n",
       "0     [<user>, men, can, not, be, raped, can, not, b...      normal   \n",
       "1     [<user>, you, are, missing, an, essential, pre...      normal   \n",
       "2     [<user>, <user>, why, are, you, repeating, you...   offensive   \n",
       "3     [<user>, <user>, well, she, ’, muslim, so, of,...  hatespeech   \n",
       "4     [<user>, lol, not, me, i, don, ’, t, deal, wit...   offensive   \n",
       "...                                                 ...         ...   \n",
       "1919  [we, hate, islam, and, we, will, mock, your, p...  hatespeech   \n",
       "1920  [he, sounds, like, a, clothing, line, i, will,...   offensive   \n",
       "1921         [4, chan, is, retarded, and, so, are, you]   offensive   \n",
       "1922  [plenty, of, e, celebs, have, covered, israid,...  hatespeech   \n",
       "1923  [yeah, i, got, to, about, just, over, <number>...  hatespeech   \n",
       "\n",
       "                                              rationale  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3     [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1919  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1920   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1921                           [0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1922  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1923  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                              heuristic  \n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                 ...  \n",
       "1919  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...  \n",
       "1920  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1921  [0.0, 0.0, 0.0, 0.008463997146658984, 0.0, 0.0...  \n",
       "1922  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1923  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422513...  \n",
       "\n",
       "[1924 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatexplain.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4177f",
   "metadata": {},
   "source": [
    "## Example where the highlighted words in hate speech is the unhatefule case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0cb47d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T10:39:57.321573Z",
     "start_time": "2023-05-02T10:39:40.991370Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from data.hatexplain.dataset import HateXPlain\n",
    "\n",
    "hatexplain = HateXPlain(root=dataset_path, split='train')\n",
    "df_train = hatexplain.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fd7d027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T10:39:57.382163Z",
     "start_time": "2023-05-02T10:39:57.321518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators.annotator_id</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>[203, 204, 233]</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>[27, 6, 4]</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>[209, 203, 222]</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>[235, 222, 209]</td>\n",
       "      <td>[no, liberal, congratulated, hindu, refugees, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>[0.0, 0.0005624219810971344, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>[51, 25, 4]</td>\n",
       "      <td>[he, said, bro, even, your, texts, sound, redn...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15378</th>\n",
       "      <td>1125944647509917699_twitter</td>\n",
       "      <td>[217, 206, 223]</td>\n",
       "      <td>[thanks, for, coming, to, my, ted, talk, p.s.,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.3717609295052059e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15379</th>\n",
       "      <td>1191705189587341312_twitter</td>\n",
       "      <td>[209, 200, 199]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, iran, has, the, 2, n, biggest...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00013717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>1178822728511606786_twitter</td>\n",
       "      <td>[127, 17, 37]</td>\n",
       "      <td>[or, maybe, those, were, not, meant, to, be, h...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15381</th>\n",
       "      <td>1179009825432358913_twitter</td>\n",
       "      <td>[49, 18, 4]</td>\n",
       "      <td>[good, morning, ados, black, women, only]</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0009190798227684879, 0.0, 0.0, 0.0030041564...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15382</th>\n",
       "      <td>24503772_gab</td>\n",
       "      <td>[9, 1, 64]</td>\n",
       "      <td>[the, main, reason, you, do, not, come, here, ...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 5.4870437180208235e-05, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15383 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id annotators.annotator_id  \\\n",
       "0                     23107796_gab         [203, 204, 233]   \n",
       "1                      9995600_gab              [27, 6, 4]   \n",
       "2      1227920812235051008_twitter         [209, 203, 222]   \n",
       "3      1204931715778543624_twitter         [235, 222, 209]   \n",
       "4      1179102559241244672_twitter             [51, 25, 4]   \n",
       "...                            ...                     ...   \n",
       "15378  1125944647509917699_twitter         [217, 206, 223]   \n",
       "15379  1191705189587341312_twitter         [209, 200, 199]   \n",
       "15380  1178822728511606786_twitter           [127, 17, 37]   \n",
       "15381  1179009825432358913_twitter             [49, 18, 4]   \n",
       "15382                 24503772_gab              [9, 1, 64]   \n",
       "\n",
       "                                             post_tokens       label  \\\n",
       "0      [u, really, think, i, would, not, have, been, ...   offensive   \n",
       "1      [the, uk, has, threatened, to, return, radioac...   offensive   \n",
       "2      [if, english, is, not, imposition, then, hindi...   offensive   \n",
       "3      [no, liberal, congratulated, hindu, refugees, ...   offensive   \n",
       "4      [he, said, bro, even, your, texts, sound, redn...   offensive   \n",
       "...                                                  ...         ...   \n",
       "15378  [thanks, for, coming, to, my, ted, talk, p.s.,...   offensive   \n",
       "15379  [<user>, <user>, iran, has, the, 2, n, biggest...      normal   \n",
       "15380  [or, maybe, those, were, not, meant, to, be, h...      normal   \n",
       "15381          [good, morning, ados, black, women, only]      normal   \n",
       "15382  [the, main, reason, you, do, not, come, here, ...  hatespeech   \n",
       "\n",
       "                                               rationale  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
       "3                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "15378  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "15379  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15380  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "15381                                 [0, 0, 0, 0, 0, 0]   \n",
       "15382  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                               heuristic  \n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3      [0.0, 0.0005624219810971344, 0.0, 0.0, 0.0, 0....  \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                  ...  \n",
       "15378  [0.0, 0.0, 0.0, 0.0, 0.0, 1.3717609295052059e-...  \n",
       "15379  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00013717...  \n",
       "15380  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "15381  [0.0009190798227684879, 0.0, 0.0, 0.0030041564...  \n",
       "15382  [0.0, 5.4870437180208235e-05, 0.0, 0.0, 0.0, 0...  \n",
       "\n",
       "[15383 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29504baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-02T10:44:56.526611Z",
     "start_time": "2023-05-02T10:44:56.059706Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> <user> i witnessed my black teammates defend and agree with my overtly racist white friend for calling a black dude a nigger i tried to defend dude being called nigger and they all hated on me\n",
      "id                                               1178226486081286144_twitter\n",
      "annotators.annotator_id                                          [10, 4, 39]\n",
      "post_tokens                [<user>, <user>, i, witnessed, my, black, team...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.003004156435616400...\n",
      "Name: 149, dtype: object\n",
      "again why are you so defensive about it is some nazi gonna come in and call you a name so what i have been called nigger more times than i can count\n",
      "id                                                              13501213_gab\n",
      "annotators.annotator_id                                          [37, 4, 48]\n",
      "post_tokens                [again, why, are, you, so, defensive, about, i...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 269, dtype: object\n",
      "<user> idubbz says nigger faggot all the time but no one actually gives him shit for it lol people are stupid as fuck\n",
      "id                                               1178154068545593345_twitter\n",
      "annotators.annotator_id                                           [9, 4, 17]\n",
      "post_tokens                [<user>, idubbz, says, nigger, faggot, all, th...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0, 0.0...\n",
      "Name: 348, dtype: object\n",
      "get a load of that nigger\n",
      "id                              1117879411951357952_twitter\n",
      "annotators.annotator_id                          [25, 7, 4]\n",
      "post_tokens                [get, a, load, of, that, nigger]\n",
      "label                                                normal\n",
      "rationale                                [0, 0, 0, 0, 0, 0]\n",
      "heuristic                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 684, dtype: object\n",
      "<user> loving the new season of your show when you said go be a nigger somewhere else i laughed so hard people at work wanted to know what was funny keep it up and god speed\n",
      "id                                                              18605730_gab\n",
      "annotators.annotator_id                                           [67, 7, 4]\n",
      "post_tokens                [<user>, loving, the, new, season, of, your, s...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0003017874044911453, 0.0, 0....\n",
      "Name: 835, dtype: object\n",
      "it would really break my heart to see that nigger come out of the hospital with a vicious staph infection\n",
      "id                                                              17428728_gab\n",
      "annotators.annotator_id                                          [60, 17, 4]\n",
      "post_tokens                [it, would, really, break, my, heart, to, see,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 930, dtype: object\n",
      "some white ppl called me a stupid nigger last night\n",
      "id                                               1178382939085778944_twitter\n",
      "annotators.annotator_id                                          [18, 4, 17]\n",
      "post_tokens                [some, white, ppl, called, me, a, stupid, nigg...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012071496179...\n",
      "Name: 1006, dtype: object\n",
      "if you are a white lady who ready to call me a nigger but in a loving way hit me up ❤️\n",
      "id                                               1178374131898818561_twitter\n",
      "annotators.annotator_id                                          [42, 52, 4]\n",
      "post_tokens                [if, you, are, a, white, lady, who, ready, to,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.010219618924813783, 0.0...\n",
      "Name: 1382, dtype: object\n",
      "did not a nigger just shoot up a white church just wondering because i have not seen any politicians or media people screaming for any all to disavow black supremacy\n",
      "id                                                              12646112_gab\n",
      "annotators.annotator_id                                           [9, 4, 17]\n",
      "post_tokens                [did, not, a, nigger, just, shoot, up, a, whit...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0, 0.0...\n",
      "Name: 1399, dtype: object\n",
      "looks homey niggers like to call us cavebeasts we were smart enough to get out of the rain keep a fire going to put our backs to walls and store stuff as opposed to capering tree to tree eating rotten fruit like feckless nigger monkeys storing surplus gave rise to agriculture\n",
      "id                                                              15089070_gab\n",
      "annotators.annotator_id                                           [9, 67, 4]\n",
      "post_tokens                [looks, homey, niggers, like, to, call, us, ca...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 1530, dtype: object\n",
      "gangsta poppin margiela can not hustlin this nigger\n",
      "id                                               1178783421058994176_twitter\n",
      "annotators.annotator_id                                           [4, 60, 9]\n",
      "post_tokens                [gangsta, poppin, margiela, can, not, hustlin,...\n",
      "label                                                                 normal\n",
      "rationale                                           [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02069987...\n",
      "Name: 1616, dtype: object\n",
      "i would not laugh too hard you are a nigger too <happy>\n",
      "id                                                              17335154_gab\n",
      "annotators.annotator_id                                           [4, 9, 60]\n",
      "post_tokens                [i, would, not, laugh, too, hard, you, are, a,...\n",
      "label                                                                 normal\n",
      "rationale                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 1703, dtype: object\n",
      "i am not saying nigger because i am racist i am saying it to take a stand against pc and fight for freedom of speech white dude comedians\n",
      "id                                               1179104530706960384_twitter\n",
      "annotators.annotator_id                                          [16, 89, 4]\n",
      "post_tokens                [i, am, not, saying, nigger, because, i, am, r...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.020699872426233556, 0.0...\n",
      "Name: 2077, dtype: object\n",
      "<user> <user> drag this nigger for filth honey\n",
      "id                                               1178831186296094723_twitter\n",
      "annotators.annotator_id                                           [4, 20, 9]\n",
      "post_tokens                [<user>, <user>, drag, this, nigger, for, filt...\n",
      "label                                                                 normal\n",
      "rationale                                           [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 2087, dtype: object\n",
      "want to know the real bubble the usd under the fed we will remove the nigger fed\n",
      "id                                                              16407424_gab\n",
      "annotators.annotator_id                                           [67, 9, 4]\n",
      "post_tokens                [want, to, know, the, real, bubble, the, usd, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0006858804647526029, 0....\n",
      "Name: 2099, dtype: object\n",
      "this is wrong it included nigger on the end it read white lives matter nigger that why this particular incident was a bigger deal\n",
      "id                                                              14987108_gab\n",
      "annotators.annotator_id                                           [89, 9, 3]\n",
      "post_tokens                [this, is, wrong, it, included, nigger, on, th...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0001920465301307288, 0.0, 0.0, 0....\n",
      "Name: 2119, dtype: object\n",
      "winner winner chicken dinner and do not forget that cia nigger malcolm nance on msnbc\n",
      "id                                                              23950465_gab\n",
      "annotators.annotator_id                                           [4, 9, 12]\n",
      "post_tokens                [winner, winner, chicken, dinner, and, do, not...\n",
      "label                                                                 normal\n",
      "rationale                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 2141, dtype: object\n",
      "so i got called a nappy headed nigger jew 🤣 🤣 🤣\n",
      "id                                                              22005487_gab\n",
      "annotators.annotator_id                                          [19, 46, 4]\n",
      "post_tokens                [so, i, got, called, a, nappy, headed, nigger,...\n",
      "label                                                                 normal\n",
      "rationale                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 2.7435218590104118e-...\n",
      "Name: 2182, dtype: object\n",
      "sheeit nigguh you fuckin trippin why boi dat nigger turnin him life aroun gnomesayin on his way ta mufuggin churchskoo an shit an outta nowheres dem dam raysis crackas jump out da bush and try ta rape em self dafunce all da dam way where dafaq muh lawsuit moneys\n",
      "id                                                              10767251_gab\n",
      "annotators.annotator_id                                            [7, 6, 9]\n",
      "post_tokens                [sheeit, nigguh, you, fuckin, trippin, why, bo...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 2227, dtype: object\n",
      "my homie medicine hoe no versace this nigger\n",
      "id                                               1178815750687076352_twitter\n",
      "annotators.annotator_id                                        [114, 58, 18]\n",
      "post_tokens                [my, homie, medicine, hoe, no, versace, this, ...\n",
      "label                                                                 normal\n",
      "rationale                                           [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 2516, dtype: object\n",
      "i am a sand nigger and that shit made me fucking laugh\n",
      "id                                                              20470697_gab\n",
      "annotators.annotator_id                                          [4, 18, 17]\n",
      "post_tokens                [i, am, a, sand, nigger, and, that, shit, made...\n",
      "label                                                                 normal\n",
      "rationale                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.020699872426233556, 0.0...\n",
      "Name: 2552, dtype: object\n",
      "if that was the case then people would not call me a nigger just because i made a joke\n",
      "id                                                              17497830_gab\n",
      "annotators.annotator_id                                            [9, 3, 4]\n",
      "post_tokens                [if, that, was, the, case, then, people, would...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 3082, dtype: object\n",
      "unironic you are dead kiddo spec ops beret pic extensively educated over compensatory bio obsessed with some nigger called chyna classical liberal peaked during reagan loves kikes viagra blogger has access to computer vlogger owns cell phone will you be my hero\n",
      "id                                                              14494551_gab\n",
      "annotators.annotator_id                                           [46, 9, 3]\n",
      "post_tokens                [unironic, you, are, dead, kiddo, spec, ops, b...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0005487043718020823, 1.37176...\n",
      "Name: 3248, dtype: object\n",
      "yesterday in burleson tx someone called me a nigger the old me would have shot em but the new me is to focused to let some white man make me mad or take away my freedom\n",
      "id                                               1178863636791615488_twitter\n",
      "annotators.annotator_id                                        [133, 14, 18]\n",
      "post_tokens                [yesterday, in, burleson, tx, someone, called,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 3342, dtype: object\n",
      "wait just figured out the white dude called him a nigger fuck him\n",
      "id                                               1178759437550522370_twitter\n",
      "annotators.annotator_id                                           [18, 4, 3]\n",
      "post_tokens                [wait, just, figured, out, the, white, dude, c...\n",
      "label                                                                 normal\n",
      "rationale                            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.010219618924813783...\n",
      "Name: 3344, dtype: object\n",
      "cash money makin fuck with smoke this nigger fucking it\n",
      "id                                               1177399021125734400_twitter\n",
      "annotators.annotator_id                                           [9, 17, 4]\n",
      "post_tokens                [cash, money, makin, fuck, with, smoke, this, ...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 3802, dtype: object\n",
      "brown pops stripper pole weed on it this nigger\n",
      "id                                               1177291179647471619_twitter\n",
      "annotators.annotator_id                                          [17, 18, 4]\n",
      "post_tokens                [brown, pops, stripper, pole, weed, on, it, th...\n",
      "label                                                                 normal\n",
      "rationale                                        [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0003840930602614576, 0.0, 2.743521859010411...\n",
      "Name: 3821, dtype: object\n",
      "at my job yesterday these <number> white boys were running around saying nigger nigger and the mom was like that very in appropriate where did you learn that and he said another boy at school taught it to him saying it was okay to say it 🥴\n",
      "id                                               1178783140879327234_twitter\n",
      "annotators.annotator_id                                           [2, 18, 9]\n",
      "post_tokens                [at, my, job, yesterday, these, <number>, whit...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.004225023662876034...\n",
      "Name: 3844, dtype: object\n",
      "this quarterback is shitting his pants who is this nigger du kvs vt\n",
      "id                                               1177730111719854080_twitter\n",
      "annotators.annotator_id                                           [17, 4, 9]\n",
      "post_tokens                [this, quarterback, is, shitting, his, pants, ...\n",
      "label                                                                 normal\n",
      "rationale                            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 3860, dtype: object\n",
      "charles is angry that one of his nigger bros got caught raping again\n",
      "id                                                              21751669_gab\n",
      "annotators.annotator_id                                           [4, 9, 34]\n",
      "post_tokens                [charles, is, angry, that, one, of, his, nigge...\n",
      "label                                                                 normal\n",
      "rationale                            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 8.230565577031235e-05, 0.0, 0.0, 0....\n",
      "Name: 4211, dtype: object\n",
      "<user> should not vr called zayn a sand nigger 🤷 🏻 ‍ ♀️ 🤷 🏻 ‍ ♀️\n",
      "id                                               1178773239566405633_twitter\n",
      "annotators.annotator_id                                           [9, 4, 18]\n",
      "post_tokens                [<user>, should, not, vr, called, zayn, a, san...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020...\n",
      "Name: 4238, dtype: object\n",
      "boy those evil confederates sure were wrong about need to control hyper violent nigger apes huh\n",
      "id                                                              10474856_gab\n",
      "annotators.annotator_id                                           [9, 67, 4]\n",
      "post_tokens                [boy, those, evil, confederates, sure, were, w...\n",
      "label                                                                 normal\n",
      "rationale                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0004252458881466138, 0.0, 0.00026...\n",
      "Name: 4588, dtype: object\n",
      "gold poppin bugatti brown gangsta shit this nigger\n",
      "id                                               1177892324472479744_twitter\n",
      "annotators.annotator_id                                            [4, 9, 1]\n",
      "post_tokens                [gold, poppin, bugatti, brown, gangsta, shit, ...\n",
      "label                                                                 normal\n",
      "rationale                                           [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 4636, dtype: object\n",
      "is ur girlfriend acting funny you are suspecting there a nigger on the side talk to degea because de gea saves\n",
      "id                                               1084543381546696704_twitter\n",
      "annotators.annotator_id                                            [7, 4, 8]\n",
      "post_tokens                [is, ur, girlfriend, acting, funny, you, are, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.00021948174872083294, 0...\n",
      "Name: 4802, dtype: object\n",
      "if the lefts feelings about blacks and slavery are promoting censorship then why are hip hop rap songs that used the word nigger in them not censored\n",
      "id                                                              11253654_gab\n",
      "annotators.annotator_id                                         [15, 108, 9]\n",
      "post_tokens                [if, the, lefts, feelings, about, blacks, and,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 4851, dtype: object\n",
      "ebt cards are nigger crypto\n",
      "id                                3Z8UJEJOCZEG603II1EL4BE4QZH93Z_nf_2\n",
      "annotators.annotator_id                                   [9, 4, 187]\n",
      "post_tokens                         [ebt, cards, are, nigger, crypto]\n",
      "label                                                          normal\n",
      "rationale                                             [0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0]\n",
      "Name: 4886, dtype: object\n",
      "i do not know why the word nigger still bothers people i think the word is funny asf 😭 white people feel so powerful saying it 🤣 🤣\n",
      "id                                               1178702446039830528_twitter\n",
      "annotators.annotator_id                                           [9, 17, 4]\n",
      "post_tokens                [i, do, not, know, why, the, word, nigger, sti...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02069987...\n",
      "Name: 5060, dtype: object\n",
      "<user> why the hell did this mentally challenged individual parents allow him to go to a sleepover with a retarded ghetto nigger maybe the we are all one race the human race crap had filled their heads maybe they are tired of caring for him not wise\n",
      "id                                                               3694770_gab\n",
      "annotators.annotator_id                                      [199, 216, 205]\n",
      "post_tokens                [<user>, why, the, hell, did, this, mentally, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.115...\n",
      "Name: 5141, dtype: object\n",
      "hey john what guchhi mah nigger\n",
      "id                                    1109106538579296256_twitter\n",
      "annotators.annotator_id                                 [8, 6, 4]\n",
      "post_tokens                [hey, john, what, guchhi, mah, nigger]\n",
      "label                                                      normal\n",
      "rationale                                      [0, 0, 0, 0, 0, 0]\n",
      "heuristic                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 5540, dtype: object\n",
      "a white man callin me brotha is way more offensive than them just callin me a nigger\n",
      "id                                               1178723913016184833_twitter\n",
      "annotators.annotator_id                                          [17, 4, 64]\n",
      "post_tokens                [a, white, man, callin, me, brotha, is, way, m...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.010219618924813783, 0.0, 0.0, 0.0, 0.0...\n",
      "Name: 5624, dtype: object\n",
      "this whole album is <number> <number> very underrated not joking he even says nigger hard r in one of the songs hee hee\n",
      "id                                                              20872466_gab\n",
      "annotators.annotator_id                                           [4, 9, 81]\n",
      "post_tokens                [this, whole, album, is, <number>, <number>, v...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.004225023662876034...\n",
      "Name: 5754, dtype: object\n",
      "<user> why eat hot pockets when you can eat ass preferably nigger ass 👍\n",
      "id                                               1178681126476496896_twitter\n",
      "annotators.annotator_id                                           [18, 9, 4]\n",
      "post_tokens                [<user>, why, eat, hot, pockets, when, you, ca...\n",
      "label                                                                 normal\n",
      "rationale                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.00015089370224557265, 0.0, 0...\n",
      "Name: 5939, dtype: object\n",
      "i am white and i get called nigger on xbox and that shit still pisses me off lmfao\n",
      "id                                               1178825670849388546_twitter\n",
      "annotators.annotator_id                                       [155, 132, 30]\n",
      "post_tokens                [i, am, white, and, i, get, called, nigger, on...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.010219618924813783, 0.0, 0.0, 0.0...\n",
      "Name: 5990, dtype: object\n",
      "i am truly amazed that twitter allows little racist bitches to go on and scream nigger but they throw somebody in jail because they tell them to eat poo and stop existing but kill kill all the niggers is ok with twitter shame on twitter\n",
      "id                                               1178812941405171713_twitter\n",
      "annotators.annotator_id                                          [4, 48, 10]\n",
      "post_tokens                [i, am, truly, amazed, that, twitter, allows, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00083677...\n",
      "Name: 6189, dtype: object\n",
      "why is it that every time we catch a white person shouting nigger with hate they all of a sudden want to cry and act like they did not know better you weren t crying when you were shouting it now were you blanche\n",
      "id                                               1179099015855652865_twitter\n",
      "annotators.annotator_id                                           [4, 9, 25]\n",
      "post_tokens                [why, is, it, that, every, time, we, catch, a,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 6406, dtype: object\n",
      "nigger please you do not have the first clue about anyting other than what white people tell you the same people that think you are a joke and uneducated house negro have you taken a moment to listen to yourself you are a shitass on top of that\n",
      "id                                               1179053960268779520_twitter\n",
      "annotators.annotator_id                                           [9, 4, 89]\n",
      "post_tokens                [nigger, please, you, do, not, have, the, firs...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.020699872426233556, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
      "Name: 7067, dtype: object\n",
      "anyone who shouts nigger is a fkn wanker with little vocabulary or wit to have an adult conversation and or insult someone with any intelligence\n",
      "id                                                              20027579_gab\n",
      "annotators.annotator_id                                          [9, 39, 17]\n",
      "post_tokens                [anyone, who, shouts, nigger, is, a, fkn, wank...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0, 0.0...\n",
      "Name: 7153, dtype: object\n",
      "now i say my prayers i got too many people in my head right now so many that in jail or they are dead right now one time for my nigger crag right now he in the feds damn the times change and these stupid niggers talking bout crime pays\n",
      "id                                               1179035123942952964_twitter\n",
      "annotators.annotator_id                                           [5, 4, 99]\n",
      "post_tokens                [now, i, say, my, prayers, i, got, too, many, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 7357, dtype: object\n",
      "<user> young boy ain t nigger music it nigga music\n",
      "id                                               1178428981592375297_twitter\n",
      "annotators.annotator_id                                           [4, 70, 5]\n",
      "post_tokens                [<user>, young, boy, ain, t, nigger, music, it...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.000233199358015885, 0.0, 0.0, 0.0, 0.0...\n",
      "Name: 7479, dtype: object\n",
      "fucking clowns the modern clown evolved from blackface and minstrel shows where theyd put on blackface and act like a dumb nigger and sing racist songs and make racist jokes the only difference clowns got is they paint the face white and made the hair brightly colored\n",
      "id                                               1178841151580905473_twitter\n",
      "annotators.annotator_id                                           [5, 19, 4]\n",
      "post_tokens                [fucking, clowns, the, modern, clown, evolved,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 2.7435218590104118e-05, 0.0, 0...\n",
      "Name: 7561, dtype: object\n",
      "looks at avi you think white people not going to call you a nigger\n",
      "id                                               1178717722416467969_twitter\n",
      "annotators.annotator_id                                          [90, 67, 4]\n",
      "post_tokens                [looks, at, avi, you, think, white, people, no...\n",
      "label                                                                 normal\n",
      "rationale                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.010219618924813783...\n",
      "Name: 7662, dtype: object\n",
      "<user> like someone will say nigga to be cool bc it in song but they do not fuck w black ppl you piss them off and they are calling you a nigger it not the same\n",
      "id                                               1178796675210592256_twitter\n",
      "annotators.annotator_id                                          [18, 4, 32]\n",
      "post_tokens                [<user>, like, someone, will, say, nigga, to, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.743...\n",
      "Name: 7840, dtype: object\n",
      "another one in the news black man sitting on the couch eatting ice cream police woman come his apartment shoot him dead you can live like you white but in there eyes u still a nigger\n",
      "id                                               1179036289313587201_twitter\n",
      "annotators.annotator_id                                          [60, 1, 17]\n",
      "post_tokens                [another, one, in, the, news, black, man, sitt...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.003004156435616400...\n",
      "Name: 7877, dtype: object\n",
      "shouts to all the limp bizkit and korn fans who made fun of me for listening to nigger music when i would play wu tang one of those <number> is forever and one of those <number> is for the children\n",
      "id                                               1178459220938768385_twitter\n",
      "annotators.annotator_id                                          [4, 49, 17]\n",
      "post_tokens                [shouts, to, all, the, limp, bizkit, and, korn...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 2.7435218590104118e-05, 0...\n",
      "Name: 8124, dtype: object\n",
      "i just asked a <number> year old about pewdiepie using the nigger word in a video his reply was who cares i agreed with the sentiment and congratulated him on his common sense\n",
      "id                                                              11949427_gab\n",
      "annotators.annotator_id                                           [4, 9, 79]\n",
      "post_tokens                [i, just, asked, a, <number>, year, old, about...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.004225023662876034, 0.0...\n",
      "Name: 8178, dtype: object\n",
      "winter olympics white mans code for a nigger section in public\n",
      "id                                                              19132473_gab\n",
      "annotators.annotator_id                                            [4, 7, 9]\n",
      "post_tokens                [winter, olympics, white, mans, code, for, a, ...\n",
      "label                                                                 normal\n",
      "rationale                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02069987...\n",
      "Name: 8239, dtype: object\n",
      "mpc is the hangout for black teens who are not allowed to say nigger at home mpc status updates\n",
      "id                                                               6556400_gab\n",
      "annotators.annotator_id                                           [4, 54, 9]\n",
      "post_tokens                [mpc, is, the, hangout, for, black, teens, who...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.003004156435616400...\n",
      "Name: 8249, dtype: object\n",
      "<user> <user> no fr like how tf do i block ppl on twitter cause this nigger always commenting on my shit and is aggravating\n",
      "id                                               1179073691814125568_twitter\n",
      "annotators.annotator_id                                          [67, 18, 4]\n",
      "post_tokens                [<user>, <user>, no, fr, like, how, tf, do, i,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 8349, dtype: object\n",
      "this iz fur the niguhs in the suburbs and the white kids wit nigger friends that say the n werrd 🤓\n",
      "id                                               1178294845783199745_twitter\n",
      "annotators.annotator_id                                          [64, 9, 17]\n",
      "post_tokens                [this, iz, fur, the, niguhs, in, the, suburbs,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 8658, dtype: object\n",
      "<user> you can not say the n word just like i would not call a gay person a faggot weird point to make cause he still seems perfectly fine saying faggot not like anyone is advocating to let white people go arround calling random black people nigger kinda defeats itself\n",
      "id                                               1178943122996256773_twitter\n",
      "annotators.annotator_id                                          [25, 1, 18]\n",
      "post_tokens                [<user>, you, can, not, say, the, n, word, jus...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 8814, dtype: object\n",
      "<user> nigger dyke\n",
      "id                                                               1820844_gab\n",
      "annotators.annotator_id                                           [9, 5, 66]\n",
      "post_tokens                                           [<user>, nigger, dyke]\n",
      "label                                                                 normal\n",
      "rationale                                                          [0, 0, 0]\n",
      "heuristic                  [0.0004938339346218741, 0.020699872426233556, ...\n",
      "Name: 9058, dtype: object\n",
      "canadians say the word nigger too much thier just dishing out from rap music and throwing it away your full of bird shit\n",
      "id                                               1089369393866387456_twitter\n",
      "annotators.annotator_id                                            [8, 7, 4]\n",
      "post_tokens                [canadians, say, the, word, nigger, too, much,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.020699872426233556, 0.0...\n",
      "Name: 9254, dtype: object\n",
      "<user> would ya get a load of this nigger lmao\n",
      "id                                               1178676586285015040_twitter\n",
      "annotators.annotator_id                                           [18, 4, 1]\n",
      "post_tokens                [<user>, would, ya, get, a, load, of, this, ni...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020...\n",
      "Name: 9388, dtype: object\n",
      "if i could work remotely full time woo a career a lifestyle the poor mentally unstable queer nigger agenda\n",
      "id                                               1179030196160208896_twitter\n",
      "annotators.annotator_id                                           [17, 9, 2]\n",
      "post_tokens                [if, i, could, work, remotely, full, time, woo...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 9537, dtype: object\n",
      "<user> take ya nigger ass to bed\n",
      "id                                               1178911850806693888_twitter\n",
      "annotators.annotator_id                                          [19, 4, 25]\n",
      "post_tokens                         [<user>, take, ya, nigger, ass, to, bed]\n",
      "label                                                                 normal\n",
      "rationale                                              [0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0, 0.0...\n",
      "Name: 9634, dtype: object\n",
      "unconfirmed backstory white girl refers to black girl as nigger on facebook black girl responds to prove her wrong\n",
      "id                                                              18099370_gab\n",
      "annotators.annotator_id                                           [9, 4, 15]\n",
      "post_tokens                [unconfirmed, backstory, white, girl, refers, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.010219618924813783, 0.0, 0.0, 0.0...\n",
      "Name: 10054, dtype: object\n",
      "you are a be rollin margiela fuckin this nigger slammin\n",
      "id                                               1178692538850582530_twitter\n",
      "annotators.annotator_id                                           [4, 9, 41]\n",
      "post_tokens                [you, are, a, be, rollin, margiela, fuckin, th...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020...\n",
      "Name: 10096, dtype: object\n",
      "bring it nigger were you coming here on some welfare ticket ar <number> i am a great shot\n",
      "id                                                              27431724_gab\n",
      "annotators.annotator_id                                           [9, 4, 19]\n",
      "post_tokens                [bring, it, nigger, were, you, coming, here, o...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.020699872426233556, 0.0, 0.0, 0.0...\n",
      "Name: 10125, dtype: object\n",
      "back to the old you can not say nigger in a rap unless you are black thing not even if you call yourself ninja and have blue hair\n",
      "id                                                              22968939_gab\n",
      "annotators.annotator_id                                            [9, 7, 4]\n",
      "post_tokens                [back, to, the, old, you, can, not, say, nigge...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0004938339346218741, 0.0, 0....\n",
      "Name: 10609, dtype: object\n",
      "mayweather wins gab calls him a nigger mayweather loses gab calls him a nigger\n",
      "id                                                              11239767_gab\n",
      "annotators.annotator_id                                         [34, 39, 25]\n",
      "post_tokens                [mayweather, wins, gab, calls, him, a, nigger,...\n",
      "label                                                                 normal\n",
      "rationale                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0206998724262...\n",
      "Name: 10750, dtype: object\n",
      "i would invest in gab but contrary to popular belief i do not really like being called a nigger online\n",
      "id                                                               9692978_gab\n",
      "annotators.annotator_id                                        [110, 72, 76]\n",
      "post_tokens                [i, would, invest, in, gab, but, contrary, to,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.115...\n",
      "Name: 10849, dtype: object\n",
      "<user> please excuse the language i think the word nigger does not pertain to every black person if i have to hear it be used in this shit crap they call music nowadays it open for use\n",
      "id                                                              27706338_gab\n",
      "annotators.annotator_id                                          [4, 24, 71]\n",
      "post_tokens                [<user>, please, excuse, the, language, i, thi...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 10945, dtype: object\n",
      "the daily mail thinks that its incriminating to say nigger\n",
      "id                                                               5115411_gab\n",
      "annotators.annotator_id                                          [30, 18, 9]\n",
      "post_tokens                [the, daily, mail, thinks, that, its, incrimin...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.00010974087436041647, 0.0, 0.0, 0.0, 0...\n",
      "Name: 11091, dtype: object\n",
      "twitter black guys get mad when they see a white girl tweet nigger but they letting these white girls treat them like coons smarten up king\n",
      "id                                               1179037520597663745_twitter\n",
      "annotators.annotator_id                                          [18, 4, 46]\n",
      "post_tokens                [twitter, black, guys, get, mad, when, they, s...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0030041564356164006, 0.0, 0.0, 8.23056...\n",
      "Name: 11315, dtype: object\n",
      "call me a nigger lover shitskin apologist and misogynist but general powell was duped by white people hillary did it for power and blood sport only nimrata randhawa rabbi knows her motivations\n",
      "id                                                              23617885_gab\n",
      "annotators.annotator_id                                           [54, 9, 4]\n",
      "post_tokens                [call, me, a, nigger, lover, shitskin, apologi...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.020699872426233556, 0.0, 0.0...\n",
      "Name: 11338, dtype: object\n",
      "my gramma always says if u can not say something nice about someone do not say anything at all just call them a nigger and move on 😇\n",
      "id                                                              26725075_gab\n",
      "annotators.annotator_id                                           [4, 92, 9]\n",
      "post_tokens                [my, gramma, always, says, if, u, can, not, sa...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 11454, dtype: object\n",
      "i really hate explaining my nigger hair details to old white ladies 😒 leave me and my puffs tf alone katherine 🙄 🤬\n",
      "id                                               1178699138642391043_twitter\n",
      "annotators.annotator_id                                           [1, 4, 42]\n",
      "post_tokens                [i, really, hate, explaining, my, nigger, hair...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.020699872426233556...\n",
      "Name: 11464, dtype: object\n",
      "<user> it still does not negate the fact that it violence inciting speech her losing whatever job she had and havin trouble finding a new one cause who knowingly hiring openly racists was adequate punishment i guarantee you gone have sum to say if somebody call you a nigger\n",
      "id                                               1177428537311158272_twitter\n",
      "annotators.annotator_id                                          [135, 4, 9]\n",
      "post_tokens                [<user>, it, still, does, not, negate, the, fa...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 11475, dtype: object\n",
      "<user> one of my black classmates had the gall to teach a teacher the difference between nigga and nigger and basically made it okay for the white kids to say it i wanted no part of that\n",
      "id                                               1178911310068760576_twitter\n",
      "annotators.annotator_id                                           [10, 1, 9]\n",
      "post_tokens                [<user>, one, of, my, black, classmates, had, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0030041564356164006, 0....\n",
      "Name: 11599, dtype: object\n",
      "<user> bro you was telling me that you want a white women to tie you up and call you nigger 🤕\n",
      "id                                               1178423738213289984_twitter\n",
      "annotators.annotator_id                                           [12, 9, 4]\n",
      "post_tokens                [<user>, bro, you, was, telling, me, that, you...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 11799, dtype: object\n",
      "white people say they have dark humour and then just call you a nigger and laugh it off bc they have black friends\n",
      "id                                               1178345903821905926_twitter\n",
      "annotators.annotator_id                                           [5, 39, 4]\n",
      "post_tokens                [white, people, say, they, have, dark, humour,...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.010219618924813783, 0.0, 0.0, 0.0, 0.0, 8.2...\n",
      "Name: 11915, dtype: object\n",
      "why my mama just tell me the white men i like look like they say nigger 😭\n",
      "id                                               1178925512233586689_twitter\n",
      "annotators.annotator_id                                           [2, 42, 4]\n",
      "post_tokens                [why, my, mama, just, tell, me, the, white, me...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01021961...\n",
      "Name: 11958, dtype: object\n",
      "lmao i go to retweet greg photo and this nigger got me damn socks on how 😂 😂 😂 🥴 😂 😂 😂 😂\n",
      "id                                               1177725810914013185_twitter\n",
      "annotators.annotator_id                                           [1, 4, 60]\n",
      "post_tokens                [lmao, i, go, to, retweet, greg, photo, and, t...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 11975, dtype: object\n",
      "richard pryors album bicentennial nigger\n",
      "id                                                           12981088_gab\n",
      "annotators.annotator_id                                   [235, 215, 217]\n",
      "post_tokens                [richard, pryors, album, bicentennial, nigger]\n",
      "label                                                              normal\n",
      "rationale                                                 [0, 0, 0, 0, 0]\n",
      "heuristic                                       [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Name: 12031, dtype: object\n",
      "not tame just do not use words like nigger and kike etc disqus lets websites blacklist particular words\n",
      "id                                                              11366872_gab\n",
      "annotators.annotator_id                                          [30, 17, 9]\n",
      "post_tokens                [not, tame, just, do, not, use, words, like, n...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020...\n",
      "Name: 12123, dtype: object\n",
      "white professors love using literature with the word nigger\n",
      "id                                               1178715987119656962_twitter\n",
      "annotators.annotator_id                                           [1, 18, 4]\n",
      "post_tokens                [white, professors, love, using, literature, w...\n",
      "label                                                                 normal\n",
      "rationale                                        [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020...\n",
      "Name: 12436, dtype: object\n",
      "<user> jason shitlock ain t seen a nigger he do not like that agrees with him\n",
      "id                                               1176837132649934848_twitter\n",
      "annotators.annotator_id                                            [4, 7, 6]\n",
      "post_tokens                [<user>, jason, shitlock, ain, t, seen, a, nig...\n",
      "label                                                                 normal\n",
      "rationale                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 12727, dtype: object\n",
      "if black people do not want non blacks saying nigga or nigger or negro maybe they should stop saying it\n",
      "id                                                              12477646_gab\n",
      "annotators.annotator_id                                          [7, 4, 120]\n",
      "post_tokens                [if, black, people, do, not, want, non, blacks...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0030041564356164006, 0.0, 0.0, 0.0, 0....\n",
      "Name: 12733, dtype: object\n",
      "being ignored by a white man is basically him calling you a nigger\n",
      "id                                               1178660548466085890_twitter\n",
      "annotators.annotator_id                                           [4, 5, 99]\n",
      "post_tokens                [being, ignored, by, a, white, man, is, basica...\n",
      "label                                                                 normal\n",
      "rationale                            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.010219618924813783, 0.0...\n",
      "Name: 12878, dtype: object\n",
      "law society investigator curtis smith an old white man wrote in his notes that i tweeted squaw and nigger about <number> times\n",
      "id                                               1179103212663693319_twitter\n",
      "annotators.annotator_id                                          [4, 17, 18]\n",
      "post_tokens                [law, society, investigator, curtis, smith, an...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004938339346...\n",
      "Name: 12938, dtype: object\n",
      "should not that be a sales pitch for trumpers i had no idea who he is never heard of him but from the name i d hazard a guess that he likely yellow on the outside and nigger on the inside\n",
      "id                                                              15086972_gab\n",
      "annotators.annotator_id                                          [6, 2, 193]\n",
      "post_tokens                [should, not, that, be, a, sales, pitch, for, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13031, dtype: object\n",
      "all i did was wake up and love myself and some group of uneducated white girls are yelling nigger at me through the internet before lunch\n",
      "id                                               1178691072303812608_twitter\n",
      "annotators.annotator_id                                            [4, 1, 3]\n",
      "post_tokens                [all, i, did, was, wake, up, and, love, myself...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13049, dtype: object\n",
      "people asking me how im doing and i just start screaming nigger\n",
      "id                                                              23412595_gab\n",
      "annotators.annotator_id                                           [9, 67, 4]\n",
      "post_tokens                [people, asking, me, how, im, doing, and, i, j...\n",
      "label                                                                 normal\n",
      "rationale                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13088, dtype: object\n",
      "i have to side with the nigger here he seems like he d be easy to pitch segregation to and all tucker kept saying was that race hatred i am not a bigot\n",
      "id                                                              14608176_gab\n",
      "annotators.annotator_id                                           [19, 4, 9]\n",
      "post_tokens                [i, have, to, side, with, the, nigger, here, h...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13138, dtype: object\n",
      "the conversion to metric would make that <number> jigaboo watts i can do it on the fly because i am always having to convert nigger watt hours to jigaboo watts\n",
      "id                                                              15293224_gab\n",
      "annotators.annotator_id                                           [9, 4, 18]\n",
      "post_tokens                [the, conversion, to, metric, would, make, tha...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422502...\n",
      "Name: 13229, dtype: object\n",
      "<user> <user> ay this nigger here is givin out free money\n",
      "id                                               1179075216066125824_twitter\n",
      "annotators.annotator_id                                         [111, 18, 4]\n",
      "post_tokens                [<user>, <user>, ay, this, nigger, here, is, g...\n",
      "label                                                                 normal\n",
      "rationale                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13285, dtype: object\n",
      "the nigger part was funny\n",
      "id                                                              25979396_gab\n",
      "annotators.annotator_id                                           [67, 9, 4]\n",
      "post_tokens                                  [the, nigger, part, was, funny]\n",
      "label                                                                 normal\n",
      "rationale                                                    [0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.020699872426233556, 0.0, 0.0, 0.000219...\n",
      "Name: 13463, dtype: object\n",
      "<user> <user> cuz ppl r not taught the full history usage it lessens understanding of why it so offensive a history literature teacher sayin nigger coon spick wetback towelhead chink when examining racial disparity events is different then self proclaimed racist saying same words\n",
      "id                                               1178730678512476161_twitter\n",
      "annotators.annotator_id                                           [18, 9, 4]\n",
      "post_tokens                [<user>, <user>, cuz, ppl, r, not, taught, the...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 13964, dtype: object\n",
      "my grandma was legit the best role model my daddy could ask for she had a degree and a career and raised him in a christian household and the stupid nigger still chose the streets 😭\n",
      "id                                               1178843246837092353_twitter\n",
      "annotators.annotator_id                                          [25, 4, 18]\n",
      "post_tokens                [my, grandma, was, legit, the, best, role, mod...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.000233199358015885...\n",
      "Name: 14047, dtype: object\n",
      "i remember when white ppl were scared of nigger music let us go back to those days\n",
      "id                                               1178448977534078982_twitter\n",
      "annotators.annotator_id                                           [18, 4, 5]\n",
      "post_tokens                [i, remember, when, white, ppl, were, scared, ...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001234584836...\n",
      "Name: 14454, dtype: object\n",
      "<user> damn you now whenever i can not figure out what to say the first thing that pops into my head is wait for it lol nigger\n",
      "id                                                              10622597_gab\n",
      "annotators.annotator_id                                           [17, 9, 1]\n",
      "post_tokens                [<user>, damn, you, now, whenever, i, can, not...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 14474, dtype: object\n",
      "<user> when roy rosales killed he called himself a dumb nigger which in court you have to say roy rosales dumb nigger killed\n",
      "id                                               1178430921156042753_twitter\n",
      "annotators.annotator_id                                           [19, 4, 5]\n",
      "post_tokens                [<user>, when, roy, rosales, killed, he, calle...\n",
      "label                                                                 normal\n",
      "rationale                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "Name: 14476, dtype: object\n",
      "haha they call me sand nigger and i am white\n",
      "id                                                               9980949_gab\n",
      "annotators.annotator_id                                          [18, 50, 4]\n",
      "post_tokens                [haha, they, call, me, sand, nigger, and, i, a...\n",
      "label                                                                 normal\n",
      "rationale                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [0.0, 0.0, 0.0, 0.0, 0.0, 0.020699872426233556...\n",
      "Name: 14742, dtype: object\n",
      "cold poppin stripper pole fuck this nigger together\n",
      "id                                               1178649697554194432_twitter\n",
      "annotators.annotator_id                                          [67, 18, 4]\n",
      "post_tokens                [cold, poppin, stripper, pole, fuck, this, nig...\n",
      "label                                                                 normal\n",
      "rationale                                           [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "heuristic                  [5.4870437180208235e-05, 0.0, 2.74352185901041...\n",
      "Name: 14842, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = df_train[df_train['label'] == 'normal']\n",
    "for idx, row in df.iterrows():\n",
    "    if 'nigger' in row['post_tokens']:\n",
    "        print(' '.join(row['post_tokens']))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d393b",
   "metadata": {},
   "source": [
    "## Example of heuristics\n",
    "\n",
    "Get and generate example of heuristics highlighting on texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2430cbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:27.045531Z",
     "start_time": "2024-04-12T09:21:26.372903Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_json(path.join(dataset_path, 'hatexplain', 'train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dd767a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:28.630977Z",
     "start_time": "2024-04-12T09:21:28.500848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>tokens.form</th>\n",
       "      <th>tokens.pos</th>\n",
       "      <th>tokens.norm</th>\n",
       "      <th>tokens.is_stop</th>\n",
       "      <th>morpho_filter</th>\n",
       "      <th>heuristics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[u, really, think, i, would, not, have, been, ...</td>\n",
       "      <td>[PRON, ADV, VERB, PRON, AUX, PART, AUX, AUX, V...</td>\n",
       "      <td>[u, really, think, i, would, not, have, be, ra...</td>\n",
       "      <td>[False, True, False, True, True, True, True, T...</td>\n",
       "      <td>[False, False, True, False, False, False, Fals...</td>\n",
       "      <td>[0.0, 0.0, 0.1208053691, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[the, uk, has, threatened, to, return, radioac...</td>\n",
       "      <td>[DET, PROPN, AUX, VERB, PART, VERB, ADJ, NOUN,...</td>\n",
       "      <td>[the, uk, have, threaten, to, return, radioact...</td>\n",
       "      <td>[True, False, True, False, True, False, False,...</td>\n",
       "      <td>[False, False, False, True, False, True, True,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.1063829787, 0.0, 0.161290322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[if, english, is, not, imposition, then, hindi...</td>\n",
       "      <td>[SCONJ, PROPN, AUX, PART, NOUN, ADV, NOUN, AUX...</td>\n",
       "      <td>[if, english, be, not, imposition, then, hindi...</td>\n",
       "      <td>[True, False, True, True, False, True, False, ...</td>\n",
       "      <td>[False, False, False, False, True, False, True...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.33333333330000003, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0                 23107796_gab   \n",
       "1                  9995600_gab   \n",
       "2  1227920812235051008_twitter   \n",
       "\n",
       "                                         post_tokens      label  \\\n",
       "0  [u, really, think, i, would, not, have, been, ...  offensive   \n",
       "1  [the, uk, has, threatened, to, return, radioac...  offensive   \n",
       "2  [if, english, is, not, imposition, then, hindi...  offensive   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]   \n",
       "\n",
       "                                           heuristic  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         tokens.form  \\\n",
       "0  [u, really, think, i, would, not, have, been, ...   \n",
       "1  [the, uk, has, threatened, to, return, radioac...   \n",
       "2  [if, english, is, not, imposition, then, hindi...   \n",
       "\n",
       "                                          tokens.pos  \\\n",
       "0  [PRON, ADV, VERB, PRON, AUX, PART, AUX, AUX, V...   \n",
       "1  [DET, PROPN, AUX, VERB, PART, VERB, ADJ, NOUN,...   \n",
       "2  [SCONJ, PROPN, AUX, PART, NOUN, ADV, NOUN, AUX...   \n",
       "\n",
       "                                         tokens.norm  \\\n",
       "0  [u, really, think, i, would, not, have, be, ra...   \n",
       "1  [the, uk, have, threaten, to, return, radioact...   \n",
       "2  [if, english, be, not, imposition, then, hindi...   \n",
       "\n",
       "                                      tokens.is_stop  \\\n",
       "0  [False, True, False, True, True, True, True, T...   \n",
       "1  [True, False, True, False, True, False, False,...   \n",
       "2  [True, False, True, True, False, True, False, ...   \n",
       "\n",
       "                                       morpho_filter  \\\n",
       "0  [False, False, True, False, False, False, Fals...   \n",
       "1  [False, False, False, True, False, True, True,...   \n",
       "2  [False, False, False, False, True, False, True...   \n",
       "\n",
       "                                          heuristics  \n",
       "0  [0.0, 0.0, 0.1208053691, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "1  [0.0, 0.0, 0.0, 0.1063829787, 0.0, 0.161290322...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.33333333330000003, 0.0,...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train['label'] != 'normal']\n",
    "df_train = df_train[:3]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886234b-91ff-4492-9ca4-56461d8ec630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f1c27f-e73f-4028-9ef6-589681f7bb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240d66a4-e952-429c-9258-176604d197bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcd089503ef32204",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check annotation frequency\n",
    "import json\n",
    "\n",
    "with open(path.join(dataset_path, 'hatexplain', 'annotation_lexical_frequency.json'), 'r') as f:\n",
    "    annot_frequency = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "807c36b88ecc7fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:51.465001Z",
     "start_time": "2024-04-12T09:21:51.346002Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 0 instance_id 23107796_gab\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135, 206, 250, 0.0);\">u </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">really </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">think </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">i </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">not </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">have </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">been </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">raped </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">by </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">feral </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">hindu </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">muslim </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">back </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">in </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">india </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">bangladesh </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">and </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">a </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">neo </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">nazi </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">rape </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">as </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">well </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">just </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">to </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">see </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">cry </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135, 206, 250, 0.0);\">PRON </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">VERB </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PRON </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">AUX </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PART </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">AUX </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">AUX </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">VERB </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADP </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">ADJ </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">NOUN </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">CCONJ </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PROPN </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADP </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PROPN </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">CCONJ </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">NOUN </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">CCONJ </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">DET </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">NOUN </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">AUX </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">VERB </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PRON </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">ADV </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PART </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">VERB </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">PRON </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">VERB </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135, 206, 250, 0.0);\">u </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">really </span><span style=\"background-color:rgba(135, 206, 250, 0.16107381880283356);\">think </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">i </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">not </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">have </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">been </span><span style=\"background-color:rgba(135, 206, 250, 0.5095828771591187);\">raped </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">by </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">feral </span><span style=\"background-color:rgba(135, 206, 250, 0.1530054658651352);\">hindu </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">muslim </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">back </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">in </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">india </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.06060606241226196);\">bangladesh </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">and </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">a </span><span style=\"background-color:rgba(135, 206, 250, 0.42105260491371155);\">neo </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">nazi </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.5095828771591187);\">rape </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">as </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">well </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">just </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">to </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">see </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.2145593911409378);\">cry </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135, 206, 250, 0.0);\">u </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">really </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">think </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">i </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">not </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">have </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">been </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">raped </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">by </span><span style=\"background-color:rgba(135, 206, 250, 0.800000011920929);\">feral </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">hindu </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">muslim </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">back </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">in </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">india </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">or </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">bangladesh </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">and </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">a </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">neo </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">nazi </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">would </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">rape </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">as </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">well </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">just </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">to </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">see </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">me </span><span style=\"background-color:rgba(135, 206, 250, 0.0);\">cry </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0007681861205229152, 0.0006584452461624988, 0.0009053622134734358, 0.007448661847213268, 0.002139947050028121, 0.008491200153637224, 0.0048560336904484285, 0.0009739502599486962, 0.0027023690311252556, 0.0038546482119096283, 8.230565577031235e-05, 9.60232650653644e-05, 0.0033196614494025983, 0.004760010425383064, 0.0010974087436041646, 0.009588608897241389, 2.7435218590104118e-05, 0.0033196614494025983, 1.3717609295052059e-05, 0.019821945431350223, 0.01860107820409059, 0.0001646113115406247, 0.002139947050028121, 0.002139947050028121, 0.0013443257109151017, 0.001165996790079425, 0.0033196614494025983, 0.0005075515439169261, 0.002510322500994527, 0.01846390211114007, 0.000727033292637759, 0.001165996790079425, 8.230565577031235e-05]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules import highlight\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    print('idx', idx, 'instance_id', row['id'])\n",
    "    raw_heuristics = [annot_frequency.get(tk, 0) for tk in row['tokens.form']]\n",
    "    new_heuristics = [0 if not f else h for h, f in zip(raw_heuristics, row['morpho_filter'])]\n",
    "    \n",
    "    display(HTML(''+ highlight(row['tokens.form'], row['rationale'])))\n",
    "    display(HTML(highlight(row['tokens.pos'], row['morpho_filter'])))\n",
    "    display(HTML(highlight(row['tokens.form'], row['heuristics'])))\n",
    "    display(HTML(highlight(row['tokens.form'], row['heuristic'])))\n",
    "    print(raw_heuristics)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21bb55b6-aa3b-4412-afb9-c8ecff2fcc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004760010425383064"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_frequency['muslim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db632305db250f3a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574940f91a022446",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7867131e240e1e59",
   "metadata": {},
   "source": [
    "# Cached parquet file: Visualization and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44dea0b7c4a76a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:54:28.160587Z",
     "start_time": "2023-10-05T08:54:27.352973Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators.annotator_id</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>label</th>\n",
       "      <th>rationale</th>\n",
       "      <th>heuristic</th>\n",
       "      <th>tokens.norm</th>\n",
       "      <th>tokens.form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1178610029273976833_twitter</td>\n",
       "      <td>[9, 17, 64]</td>\n",
       "      <td>[&lt;user&gt;, men, can, not, be, raped, can, not, b...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[&lt;user&gt;, men, can, not, be, raped, can, not, b...</td>\n",
       "      <td>[&lt;user&gt;, men, can, not, be, raped, can, not, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1165785686903009283_twitter</td>\n",
       "      <td>[200, 199, 211]</td>\n",
       "      <td>[&lt;user&gt;, you, are, missing, an, essential, pre...</td>\n",
       "      <td>normal</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[&lt;user&gt;, you, are, missing, an, essential, pre...</td>\n",
       "      <td>[&lt;user&gt;, you, are, missing, an, essential, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1252707503441313794_twitter</td>\n",
       "      <td>[233, 215, 202]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, why, are, you, repeating, you...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, why, are, you, repeating, you...</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, why, are, you, repeating, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1103385226921762816_twitter</td>\n",
       "      <td>[206, 199, 203]</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, well, she, ’, muslim, so, of,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, well, she, ’, muslim, so, of,...</td>\n",
       "      <td>[&lt;user&gt;, &lt;user&gt;, well, she, ’, muslim, so, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1169443635869487105_twitter</td>\n",
       "      <td>[205, 223, 208]</td>\n",
       "      <td>[&lt;user&gt;, lol, not, me, i, don, ’, t, deal, wit...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[&lt;user&gt;, lol, not, me, i, don, ’, t, deal, wit...</td>\n",
       "      <td>[&lt;user&gt;, lol, not, me, i, don, ’, t, deal, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>7645213_gab</td>\n",
       "      <td>[225, 207, 204]</td>\n",
       "      <td>[we, hate, islam, and, we, will, mock, your, p...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...</td>\n",
       "      <td>[we, hate, islam, and, we, will, mock, your, p...</td>\n",
       "      <td>[we, hate, islam, and, we, will, mock, your, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>7672117_gab</td>\n",
       "      <td>[13, 4, 46]</td>\n",
       "      <td>[he, sounds, like, a, clothing, line, i, will,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[he, sounds, like, a, clothing, line, i, will,...</td>\n",
       "      <td>[he, sounds, like, a, clothing, line, i, will,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1231804803614830592_twitter</td>\n",
       "      <td>[203, 209, 223]</td>\n",
       "      <td>[4, chan, is, retarded, and, so, are, you]</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.00846376493504712, 0.0, 0.0,...</td>\n",
       "      <td>[4, chan, is, retarded, and, so, are, you]</td>\n",
       "      <td>[4, chan, is, retarded, and, so, are, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>26732378_gab</td>\n",
       "      <td>[9, 6, 110]</td>\n",
       "      <td>[plenty, of, e, celebs, have, covered, israid,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[plenty, of, e, celebs, have, covered, israid,...</td>\n",
       "      <td>[plenty, of, e, celebs, have, covered, israid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>14030104_gab</td>\n",
       "      <td>[9, 43, 4]</td>\n",
       "      <td>[yeah, i, got, to, about, just, over, &lt;number&gt;...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422502...</td>\n",
       "      <td>[yeah, i, got, to, about, just, over, &lt;number&gt;...</td>\n",
       "      <td>[yeah, i, got, to, about, just, over, &lt;number&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id annotators.annotator_id  \\\n",
       "0     1178610029273976833_twitter             [9, 17, 64]   \n",
       "1     1165785686903009283_twitter         [200, 199, 211]   \n",
       "2     1252707503441313794_twitter         [233, 215, 202]   \n",
       "3     1103385226921762816_twitter         [206, 199, 203]   \n",
       "4     1169443635869487105_twitter         [205, 223, 208]   \n",
       "...                           ...                     ...   \n",
       "1919                  7645213_gab         [225, 207, 204]   \n",
       "1920                  7672117_gab             [13, 4, 46]   \n",
       "1921  1231804803614830592_twitter         [203, 209, 223]   \n",
       "1922                 26732378_gab             [9, 6, 110]   \n",
       "1923                 14030104_gab              [9, 43, 4]   \n",
       "\n",
       "                                            post_tokens       label  \\\n",
       "0     [<user>, men, can, not, be, raped, can, not, b...      normal   \n",
       "1     [<user>, you, are, missing, an, essential, pre...      normal   \n",
       "2     [<user>, <user>, why, are, you, repeating, you...   offensive   \n",
       "3     [<user>, <user>, well, she, ’, muslim, so, of,...  hatespeech   \n",
       "4     [<user>, lol, not, me, i, don, ’, t, deal, wit...   offensive   \n",
       "...                                                 ...         ...   \n",
       "1919  [we, hate, islam, and, we, will, mock, your, p...  hatespeech   \n",
       "1920  [he, sounds, like, a, clothing, line, i, will,...   offensive   \n",
       "1921         [4, chan, is, retarded, and, so, are, you]   offensive   \n",
       "1922  [plenty, of, e, celebs, have, covered, israid,...  hatespeech   \n",
       "1923  [yeah, i, got, to, about, just, over, <number>...  hatespeech   \n",
       "\n",
       "                                              rationale  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "3     [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "1919  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1920   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "1921                           [0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1922  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1923  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                              heuristic  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "1919  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.858...   \n",
       "1920  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1921  [0.0, 0.0, 0.0, 0.00846376493504712, 0.0, 0.0,...   \n",
       "1922  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1923  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00422502...   \n",
       "\n",
       "                                            tokens.norm  \\\n",
       "0     [<user>, men, can, not, be, raped, can, not, b...   \n",
       "1     [<user>, you, are, missing, an, essential, pre...   \n",
       "2     [<user>, <user>, why, are, you, repeating, you...   \n",
       "3     [<user>, <user>, well, she, ’, muslim, so, of,...   \n",
       "4     [<user>, lol, not, me, i, don, ’, t, deal, wit...   \n",
       "...                                                 ...   \n",
       "1919  [we, hate, islam, and, we, will, mock, your, p...   \n",
       "1920  [he, sounds, like, a, clothing, line, i, will,...   \n",
       "1921         [4, chan, is, retarded, and, so, are, you]   \n",
       "1922  [plenty, of, e, celebs, have, covered, israid,...   \n",
       "1923  [yeah, i, got, to, about, just, over, <number>...   \n",
       "\n",
       "                                            tokens.form  \n",
       "0     [<user>, men, can, not, be, raped, can, not, b...  \n",
       "1     [<user>, you, are, missing, an, essential, pre...  \n",
       "2     [<user>, <user>, why, are, you, repeating, you...  \n",
       "3     [<user>, <user>, well, she, ’, muslim, so, of,...  \n",
       "4     [<user>, lol, not, me, i, don, ’, t, deal, wit...  \n",
       "...                                                 ...  \n",
       "1919  [we, hate, islam, and, we, will, mock, your, p...  \n",
       "1920  [he, sounds, like, a, clothing, line, i, will,...  \n",
       "1921         [4, chan, is, retarded, and, so, are, you]  \n",
       "1922  [plenty, of, e, celebs, have, covered, israid,...  \n",
       "1923  [yeah, i, got, to, about, just, over, <number>...  \n",
       "\n",
       "[1924 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# fname = './../.cache/dataset/esnli/test.pretransformed.parquet'\n",
    "\n",
    "fname = '/home/dunguyen/RUNS/dataset/hatexplain/test.parquet'\n",
    "df = pd.read_parquet(fname)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8ec940cc8d9753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:57:43.068418Z",
     "start_time": "2023-10-05T08:57:42.928944Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95ef6beb8cf9943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:57:43.068658Z",
     "start_time": "2023-10-05T08:57:43.033125Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "id_instance = '1242188730099793920_twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "775afa74dd6a0e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T08:57:43.069529Z",
     "start_time": "2023-10-05T08:57:43.039923Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mid_instance\u001b[49m]\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'id_instance' is not defined"
     ]
    }
   ],
   "source": [
    "df.loc[id_instance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67992ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
