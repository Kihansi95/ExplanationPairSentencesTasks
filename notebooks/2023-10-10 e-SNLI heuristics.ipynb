{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# e-SNLI Heuristic Qualitative Result\n",
    "\n",
    "In this notebook, we show the qualitative of heuristic attention maps on e-SNLI dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e16826685c6df3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea506cc1c1867fe6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8135f73-f3f9-4d54-b888-ad08edf3cb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:27.021909Z",
     "start_time": "2023-10-10T13:17:26.905022Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "sys.path.append(\"./../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from modules.logger import init_logging\n",
    "from modules.logger import log\n",
    "\n",
    "init_logging(color=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:33.999371Z",
     "start_time": "2023-10-10T13:17:29.037444Z"
    }
   },
   "id": "7be72d7a281b26a1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f350fd13-a37b-41e2-9514-9a0c0e84e0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:34.263435Z",
     "start_time": "2023-10-10T13:17:34.014736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 10 15:17:34 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 23%   18C    P8     8W / 250W |      1MiB / 11178MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9c1ab664bf18052"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10-2023 15:17:34 | \u001B[34m    INFO\u001B[0m \u001B[1m \u001B[4m 2147724394.py:<cell line: 5>:5 \u001B[0m \u001B[34mCurrent node: grele-5.nancy.grid5000.fr\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# Define root folder based on current node (local or server)\n",
    "node = platform.node()\n",
    "log.info(f'Current node: {node}')\n",
    "if node == 'MAC-C02D80HRMD6':\n",
    "    ROOT = '/Users/dunguyen/Developer/server_backup/historic/2023-06-05'\n",
    "else:\n",
    "    ROOT = '/home/dunguyen/RUNS'\n",
    "    \n",
    "# model path\n",
    "LOG_PATH = path.join(ROOT, 'logs')\n",
    "DATA_CACHE = path.join(ROOT, 'dataset')\n",
    "MODEL_CACHE = path.join(ROOT, 'models')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:34.288922Z",
     "start_time": "2023-10-10T13:17:34.271055Z"
    }
   },
   "id": "2f8d5563976b6d72"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10-2023 15:17:53 | \u001B[34m    INFO\u001B[0m \u001B[1m \u001B[4m esnli_module.py:prepare_data:103 \u001B[0m \u001B[34mLoaded vocab at /home/dunguyen/RUNS/dataset/esnli/vocab.pt\u001B[0m\n",
      "10-10-2023 15:17:53 | \u001B[34m    INFO\u001B[0m \u001B[1m \u001B[4m esnli_module.py:prepare_data:105 \u001B[0m \u001B[34mVocab size: 26578\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from data_module.esnli_module import ESNLIDM\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "###############\n",
    "# PREPARE DATA\n",
    "###############\n",
    "dm = ESNLIDM(cache_path=DATA_CACHE, batch_size=16, num_workers=16, shuffle=False)\n",
    "dm.prepare_data()\n",
    "dm.setup('test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:54.800341Z",
     "start_time": "2023-10-10T13:17:34.293405Z"
    }
   },
   "id": "5518758e75af1d2c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tokens.form.premise  \\\nid                                                                       \n2677109430.jpg#1r1n  [This, church, choir, sings, to, the, masses, ...   \n2677109430.jpg#1r1e  [This, church, choir, sings, to, the, masses, ...   \n2677109430.jpg#1r1c  [This, church, choir, sings, to, the, masses, ...   \n6160193920.jpg#4r1n  [A, woman, with, a, green, headscarf, ,, blue,...   \n6160193920.jpg#4r1e  [A, woman, with, a, green, headscarf, ,, blue,...   \n\n                                              tokens.form.hypothesis  \\\nid                                                                     \n2677109430.jpg#1r1n  [The, church, has, cracks, in, the, ceiling, .]   \n2677109430.jpg#1r1e         [The, church, is, filled, with, song, .]   \n2677109430.jpg#1r1c    [A, choir, singing, at, a, baseball, game, .]   \n6160193920.jpg#4r1n                       [The, woman, is, young, .]   \n6160193920.jpg#4r1e                 [The, woman, is, very, happy, .]   \n\n                                                   tokens.norm.premise  \\\nid                                                                       \n2677109430.jpg#1r1n  [this, church, choir, sing, to, the, masse, as...   \n2677109430.jpg#1r1e  [this, church, choir, sing, to, the, masse, as...   \n2677109430.jpg#1r1c  [this, church, choir, sing, to, the, masse, as...   \n6160193920.jpg#4r1n  [a, woman, with, a, green, headscarf, ,, blue,...   \n6160193920.jpg#4r1e  [a, woman, with, a, green, headscarf, ,, blue,...   \n\n                                              tokens.norm.hypothesis  \\\nid                                                                     \n2677109430.jpg#1r1n  [the, church, have, crack, in, the, ceiling, .]   \n2677109430.jpg#1r1e           [the, church, be, fill, with, song, .]   \n2677109430.jpg#1r1c    [a, choir, singing, at, a, baseball, game, .]   \n6160193920.jpg#4r1n                       [the, woman, be, young, .]   \n6160193920.jpg#4r1e                 [the, woman, be, very, happy, .]   \n\n                             label  \\\nid                                   \n2677109430.jpg#1r1n        neutral   \n2677109430.jpg#1r1e     entailment   \n2677109430.jpg#1r1c  contradiction   \n6160193920.jpg#4r1n        neutral   \n6160193920.jpg#4r1e     entailment   \n\n                                                     heuristic.premise  \\\nid                                                                       \n2677109430.jpg#1r1n  [-1.0000000150474662e+30, 3.064525842666626, 1...   \n2677109430.jpg#1r1e  [-1.0000000150474662e+30, 2.79181170463562, 2....   \n2677109430.jpg#1r1c  [-1.0000000150474662e+30, 2.5598974227905273, ...   \n6160193920.jpg#4r1n  [-1.0000000150474662e+30, 2.597653388977051, -...   \n6160193920.jpg#4r1e  [-1.0000000150474662e+30, 2.784580707550049, -...   \n\n                                                  heuristic.hypothesis  \\\nid                                                                       \n2677109430.jpg#1r1n  [-1.0000000150474662e+30, 7.628961086273193, -...   \n2677109430.jpg#1r1e  [-1.0000000150474662e+30, 7.628961086273193, -...   \n2677109430.jpg#1r1c  [-1.0000000150474662e+30, 6.388305187225342, 6...   \n6160193920.jpg#4r1n  [-1.0000000150474662e+30, 5.648240089416504, -...   \n6160193920.jpg#4r1e  [-1.0000000150474662e+30, 5.648240089416504, -...   \n\n                                                     rationale.premise  \\\nid                                                                       \n2677109430.jpg#1r1n  [False, False, False, False, False, False, Fal...   \n2677109430.jpg#1r1e  [False, False, True, True, True, True, True, F...   \n2677109430.jpg#1r1c  [False, False, False, False, False, False, Tru...   \n6160193920.jpg#4r1n  [False, False, False, False, False, False, Fal...   \n6160193920.jpg#4r1e  [False, False, False, False, False, False, Fal...   \n\n                                                  rationale.hypothesis  \nid                                                                      \n2677109430.jpg#1r1n  [False, False, False, True, True, True, True, ...  \n2677109430.jpg#1r1e     [False, False, False, True, True, True, False]  \n2677109430.jpg#1r1c  [False, False, True, False, False, True, True,...  \n6160193920.jpg#4r1n                 [False, False, False, True, False]  \n6160193920.jpg#4r1e          [False, False, False, False, True, False]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens.form.premise</th>\n      <th>tokens.form.hypothesis</th>\n      <th>tokens.norm.premise</th>\n      <th>tokens.norm.hypothesis</th>\n      <th>label</th>\n      <th>heuristic.premise</th>\n      <th>heuristic.hypothesis</th>\n      <th>rationale.premise</th>\n      <th>rationale.hypothesis</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2677109430.jpg#1r1n</th>\n      <td>[This, church, choir, sings, to, the, masses, ...</td>\n      <td>[The, church, has, cracks, in, the, ceiling, .]</td>\n      <td>[this, church, choir, sing, to, the, masse, as...</td>\n      <td>[the, church, have, crack, in, the, ceiling, .]</td>\n      <td>neutral</td>\n      <td>[-1.0000000150474662e+30, 3.064525842666626, 1...</td>\n      <td>[-1.0000000150474662e+30, 7.628961086273193, -...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n      <td>[False, False, False, True, True, True, True, ...</td>\n    </tr>\n    <tr>\n      <th>2677109430.jpg#1r1e</th>\n      <td>[This, church, choir, sings, to, the, masses, ...</td>\n      <td>[The, church, is, filled, with, song, .]</td>\n      <td>[this, church, choir, sing, to, the, masse, as...</td>\n      <td>[the, church, be, fill, with, song, .]</td>\n      <td>entailment</td>\n      <td>[-1.0000000150474662e+30, 2.79181170463562, 2....</td>\n      <td>[-1.0000000150474662e+30, 7.628961086273193, -...</td>\n      <td>[False, False, True, True, True, True, True, F...</td>\n      <td>[False, False, False, True, True, True, False]</td>\n    </tr>\n    <tr>\n      <th>2677109430.jpg#1r1c</th>\n      <td>[This, church, choir, sings, to, the, masses, ...</td>\n      <td>[A, choir, singing, at, a, baseball, game, .]</td>\n      <td>[this, church, choir, sing, to, the, masse, as...</td>\n      <td>[a, choir, singing, at, a, baseball, game, .]</td>\n      <td>contradiction</td>\n      <td>[-1.0000000150474662e+30, 2.5598974227905273, ...</td>\n      <td>[-1.0000000150474662e+30, 6.388305187225342, 6...</td>\n      <td>[False, False, False, False, False, False, Tru...</td>\n      <td>[False, False, True, False, False, True, True,...</td>\n    </tr>\n    <tr>\n      <th>6160193920.jpg#4r1n</th>\n      <td>[A, woman, with, a, green, headscarf, ,, blue,...</td>\n      <td>[The, woman, is, young, .]</td>\n      <td>[a, woman, with, a, green, headscarf, ,, blue,...</td>\n      <td>[the, woman, be, young, .]</td>\n      <td>neutral</td>\n      <td>[-1.0000000150474662e+30, 2.597653388977051, -...</td>\n      <td>[-1.0000000150474662e+30, 5.648240089416504, -...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n      <td>[False, False, False, True, False]</td>\n    </tr>\n    <tr>\n      <th>6160193920.jpg#4r1e</th>\n      <td>[A, woman, with, a, green, headscarf, ,, blue,...</td>\n      <td>[The, woman, is, very, happy, .]</td>\n      <td>[a, woman, with, a, green, headscarf, ,, blue,...</td>\n      <td>[the, woman, be, very, happy, .]</td>\n      <td>entailment</td>\n      <td>[-1.0000000150474662e+30, 2.784580707550049, -...</td>\n      <td>[-1.0000000150474662e+30, 5.648240089416504, -...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n      <td>[False, False, False, False, True, False]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################\n",
    "# LOAD HEURISTIC AND ANNOTATION MAPS\n",
    "#####################################\n",
    "df = dm.test_set.data\n",
    "df = df[['id', 'tokens.form.premise', 'tokens.form.hypothesis', 'tokens.norm.premise', 'tokens.norm.hypothesis', 'label', 'heuristic.premise', 'heuristic.hypothesis', 'rationale.premise', 'rationale.hypothesis']].copy()\n",
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:35.954568Z",
     "start_time": "2023-10-10T13:24:35.840293Z"
    }
   },
   "id": "5d78621b27526826"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Normalize heuristic scores\n",
    "df['heuristic.premise'] = df['heuristic.premise'].apply(lambda x: torch.tensor(x).exp())\n",
    "df['heuristic.hypothesis'] = df['heuristic.hypothesis'].apply(lambda x: torch.tensor(x).exp())\n",
    "\n",
    "df['heuristic.premise'] = df['heuristic.premise'].apply(lambda x: x / x.max())\n",
    "df['heuristic.hypothesis'] = df['heuristic.hypothesis'].apply(lambda x: x / x.max())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:36.329504Z",
     "start_time": "2023-10-10T13:24:36.003405Z"
    }
   },
   "id": "1d8be1f77c0b4795"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_prediction = pd.read_json(LOG_PATH + '/lstm_attention/esnli/run=0_lstm=1/predictions/inference.json')\n",
    "model_prediction.set_index('id', inplace=True)\n",
    "\n",
    "# Remove padding mask on attention\n",
    "model_prediction['a_hat.premise'] = model_prediction.apply(lambda x: [a for a, m in zip(x['a_hat.premise'], x['padding_mask.premise']) if not m], axis=1)\n",
    "model_prediction['a_hat.hypothesis'] = model_prediction.apply(lambda x: [a for a, m in zip(x['a_hat.hypothesis'], x['padding_mask.hypothesis']) if not m], axis=1)\n",
    "model_prediction.drop(columns=['padding_mask.premise', 'padding_mask.hypothesis'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:38.349489Z",
     "start_time": "2023-10-10T13:24:37.182483Z"
    }
   },
   "id": "74672bb50bf36633"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df = df.join(model_prediction[['y_hat', 'a_hat.premise', 'a_hat.hypothesis']])\n",
    "df = df[df['y_hat'] == df['label']]\n",
    "df = df[df['label'] != 'neutral']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:39.906551Z",
     "start_time": "2023-10-10T13:24:39.758709Z"
    }
   },
   "id": "535ca3ed463d8347"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalize attention scores\n",
    "from modules.utils import rescale\n",
    "df['a_hat.premise'] = df['a_hat.premise'].apply(lambda x: rescale(x).tolist())\n",
    "df['a_hat.hypothesis'] = df['a_hat.hypothesis'].apply(lambda x: rescale(x).tolist())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cddb5ba657432ea8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "df['a_true'] = df.apply(lambda x: [0.] + x['rationale.premise'] + [0.] + x['rationale.hypothesis'], axis=1)\n",
    "df['a_hat'] = df.apply(lambda x: [0.] + x['a_hat.premise'] + [0.] + x['a_hat.hypothesis'], axis=1)\n",
    "df['a_heu'] = df.apply(lambda x: [0.] + x['heuristic.premise'].tolist() + [0.] + x['heuristic.hypothesis'].tolist(), axis=1)\n",
    "df['tokens.form'] = df.apply(lambda x: ['<b>Premise: </b>'] + x['tokens.form.premise'] + ['<br/><b>Hypothesis: </b>'] + x['tokens.form.hypothesis'], axis=1)\n",
    "df['tokens.norm'] = df.apply(lambda x: ['<b>Premise: </b>'] + x['tokens.norm.premise'] + ['<br/><b>Hypothesis: </b>'] + x['tokens.norm.hypothesis'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T14:15:38.788087Z",
     "start_time": "2023-10-10T14:15:38.428887Z"
    }
   },
   "id": "8a9e7da6c8bfcf71"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10-2023 16:15:40 | \u001B[34m    INFO\u001B[0m \u001B[1m \u001B[4m 1845255670.py:<cell line: 8>:8 \u001B[0m \u001B[34mSave qualitative results at /home/dunguyen/RUNS/qualitative_heuristic_esnli\u001B[0m\n",
      "10-10-2023 16:15:40 | \u001B[34m    INFO\u001B[0m \u001B[1m \u001B[4m 1845255670.py:<cell line: 9>:10 \u001B[0m \u001B[34mRemoving existing folder /home/dunguyen/RUNS/qualitative_heuristic_esnli\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5582 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18c0dfa561a4485f945cbc5a8bb89b8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from modules.utils import highlight\n",
    "import shutil\n",
    "\n",
    "# Remove the previous existing folder\n",
    "PROJECT = 'qualitative_heuristic_esnli'\n",
    "html_dir = path.join(ROOT, PROJECT)\n",
    "log.info(f'Save qualitative results at {html_dir}')\n",
    "if os.path.exists(html_dir) and os.path.isdir(html_dir):\n",
    "    log.info(f'Removing existing folder {html_dir}')\n",
    "    shutil.rmtree(html_dir)\n",
    "\n",
    "# Generate each comparison into a file:\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    \n",
    "    # ignore if label is 0\n",
    "    if row['label'] == 'neutral': continue\n",
    "    \n",
    "    html = \"\"\"\n",
    "    <html>\n",
    "    <head><style>\n",
    "    table, th, td {\n",
    "      border:solid black;\n",
    "      border-collapse: collapse;\n",
    "      padding: 0px 5px 0px 5px;\n",
    "    }</style></head>\n",
    "    <body>\n",
    "    \"\"\"\n",
    "    html += '<table style=\"font-size:120%;\" cellspacing=0>'\n",
    "    html += f'<caption>Dataset: e-SNLI - Instance ID: {idx}</caption>'\n",
    "    html += f'<tr><th style=\"width:100px;\">Explainer</th> <th style=\"width:500px;\">Explanation</th> <th style=\"width:100px;\">Label</th></tr>'\n",
    "    \n",
    "    # Annotation map\n",
    "    map_viz = highlight(row['tokens.form'], row['a_true'], normalize_weight=False)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Annotation Map</td><td>{map_viz}</td><td rowspan=\"3\" style=\"text-align:center\"> {row[\"label\"]} </td></tr>'\n",
    "    \n",
    "    # Attention map\n",
    "    map_viz = highlight(row['tokens.norm'], row['a_hat'], normalize_weight=False)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Attention Map</td><td>{map_viz}</td></tr>'\n",
    "    \n",
    "    # Heuristic map\n",
    "    map_viz = highlight(row['tokens.form'], row['a_heu'], normalize_weight=True)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Heuristic Map</td><td>{map_viz}</td></tr>'\n",
    "    \n",
    "    # End\n",
    "    html += '</table>'\n",
    "    html += '</body></html>'\n",
    "\n",
    "    fpath_html = path.join(html_dir, f'{idx}.html')\n",
    "    os.makedirs(html_dir, exist_ok=True)\n",
    "    with open(fpath_html, 'w') as f:\n",
    "        f.write(html)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T14:15:47.421665Z",
     "start_time": "2023-10-10T14:15:40.400394Z"
    }
   },
   "id": "c7cfd6cf85424f96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f2098fadb329a5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
