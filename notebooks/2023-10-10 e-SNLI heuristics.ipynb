{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e16826685c6df3",
   "metadata": {},
   "source": [
    "# e-SNLI Heuristic Qualitative Result\n",
    "\n",
    "In this notebook, we show the qualitative of heuristic attention maps on e-SNLI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea506cc1c1867fe6",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8135f73-f3f9-4d54-b888-ad08edf3cb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:27.021909Z",
     "start_time": "2023-10-10T13:17:26.905022Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "sys.path.append(\"./../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be72d7a281b26a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:33.999371Z",
     "start_time": "2023-10-10T13:17:29.037444Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from modules.logger import init_logging\n",
    "from modules.logger import log\n",
    "\n",
    "init_logging(color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f350fd13-a37b-41e2-9514-9a0c0e84e0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:34.263435Z",
     "start_time": "2023-10-10T13:17:34.014736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 10 15:17:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   18C    P8     8W / 250W |      1MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1ab664bf18052",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8d5563976b6d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:34.288922Z",
     "start_time": "2023-10-10T13:17:34.271055Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10-2023 15:17:34 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m 2147724394.py:<cell line: 5>:5 \u001b[0m \u001b[34mCurrent node: grele-5.nancy.grid5000.fr\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# Define root folder based on current node (local or server)\n",
    "node = platform.node()\n",
    "log.info(f'Current node: {node}')\n",
    "if node == 'MAC-C02D80HRMD6':\n",
    "    ROOT = '/Users/dunguyen/Developer/server_backup/historic/2023-06-05'\n",
    "else:\n",
    "    ROOT = '/home/dunguyen/RUNS'\n",
    "    \n",
    "# model path\n",
    "LOG_PATH = path.join(ROOT, 'logs')\n",
    "DATA_CACHE = path.join(ROOT, 'dataset')\n",
    "MODEL_CACHE = path.join(ROOT, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5518758e75af1d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:17:54.800341Z",
     "start_time": "2023-10-10T13:17:34.293405Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-10-2023 15:17:53 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m esnli_module.py:prepare_data:103 \u001b[0m \u001b[34mLoaded vocab at /home/dunguyen/RUNS/dataset/esnli/vocab.pt\u001b[0m\n",
      "10-10-2023 15:17:53 | \u001b[34m    INFO\u001b[0m \u001b[1m \u001b[4m esnli_module.py:prepare_data:105 \u001b[0m \u001b[34mVocab size: 26578\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from data_module.esnli_module import ESNLIDM\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "###############\n",
    "# PREPARE DATA\n",
    "###############\n",
    "dm = ESNLIDM(cache_path=DATA_CACHE, batch_size=16, num_workers=16, shuffle=False)\n",
    "dm.prepare_data()\n",
    "dm.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d78621b27526826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:35.954568Z",
     "start_time": "2023-10-10T13:24:35.840293Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens.form.premise</th>\n",
       "      <th>tokens.form.hypothesis</th>\n",
       "      <th>tokens.norm.premise</th>\n",
       "      <th>tokens.norm.hypothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>heuristic.premise</th>\n",
       "      <th>heuristic.hypothesis</th>\n",
       "      <th>rationale.premise</th>\n",
       "      <th>rationale.hypothesis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2677109430.jpg#1r1n</th>\n",
       "      <td>[This, church, choir, sings, to, the, masses, ...</td>\n",
       "      <td>[The, church, has, cracks, in, the, ceiling, .]</td>\n",
       "      <td>[this, church, choir, sing, to, the, masse, as...</td>\n",
       "      <td>[the, church, have, crack, in, the, ceiling, .]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-1.0000000150474662e+30, 3.064525842666626, 1...</td>\n",
       "      <td>[-1.0000000150474662e+30, 7.628961086273193, -...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, True, True, True, True, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677109430.jpg#1r1e</th>\n",
       "      <td>[This, church, choir, sings, to, the, masses, ...</td>\n",
       "      <td>[The, church, is, filled, with, song, .]</td>\n",
       "      <td>[this, church, choir, sing, to, the, masse, as...</td>\n",
       "      <td>[the, church, be, fill, with, song, .]</td>\n",
       "      <td>entailment</td>\n",
       "      <td>[-1.0000000150474662e+30, 2.79181170463562, 2....</td>\n",
       "      <td>[-1.0000000150474662e+30, 7.628961086273193, -...</td>\n",
       "      <td>[False, False, True, True, True, True, True, F...</td>\n",
       "      <td>[False, False, False, True, True, True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677109430.jpg#1r1c</th>\n",
       "      <td>[This, church, choir, sings, to, the, masses, ...</td>\n",
       "      <td>[A, choir, singing, at, a, baseball, game, .]</td>\n",
       "      <td>[this, church, choir, sing, to, the, masse, as...</td>\n",
       "      <td>[a, choir, singing, at, a, baseball, game, .]</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>[-1.0000000150474662e+30, 2.5598974227905273, ...</td>\n",
       "      <td>[-1.0000000150474662e+30, 6.388305187225342, 6...</td>\n",
       "      <td>[False, False, False, False, False, False, Tru...</td>\n",
       "      <td>[False, False, True, False, False, True, True,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160193920.jpg#4r1n</th>\n",
       "      <td>[A, woman, with, a, green, headscarf, ,, blue,...</td>\n",
       "      <td>[The, woman, is, young, .]</td>\n",
       "      <td>[a, woman, with, a, green, headscarf, ,, blue,...</td>\n",
       "      <td>[the, woman, be, young, .]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-1.0000000150474662e+30, 2.597653388977051, -...</td>\n",
       "      <td>[-1.0000000150474662e+30, 5.648240089416504, -...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160193920.jpg#4r1e</th>\n",
       "      <td>[A, woman, with, a, green, headscarf, ,, blue,...</td>\n",
       "      <td>[The, woman, is, very, happy, .]</td>\n",
       "      <td>[a, woman, with, a, green, headscarf, ,, blue,...</td>\n",
       "      <td>[the, woman, be, very, happy, .]</td>\n",
       "      <td>entailment</td>\n",
       "      <td>[-1.0000000150474662e+30, 2.784580707550049, -...</td>\n",
       "      <td>[-1.0000000150474662e+30, 5.648240089416504, -...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[False, False, False, False, True, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens.form.premise  \\\n",
       "id                                                                       \n",
       "2677109430.jpg#1r1n  [This, church, choir, sings, to, the, masses, ...   \n",
       "2677109430.jpg#1r1e  [This, church, choir, sings, to, the, masses, ...   \n",
       "2677109430.jpg#1r1c  [This, church, choir, sings, to, the, masses, ...   \n",
       "6160193920.jpg#4r1n  [A, woman, with, a, green, headscarf, ,, blue,...   \n",
       "6160193920.jpg#4r1e  [A, woman, with, a, green, headscarf, ,, blue,...   \n",
       "\n",
       "                                              tokens.form.hypothesis  \\\n",
       "id                                                                     \n",
       "2677109430.jpg#1r1n  [The, church, has, cracks, in, the, ceiling, .]   \n",
       "2677109430.jpg#1r1e         [The, church, is, filled, with, song, .]   \n",
       "2677109430.jpg#1r1c    [A, choir, singing, at, a, baseball, game, .]   \n",
       "6160193920.jpg#4r1n                       [The, woman, is, young, .]   \n",
       "6160193920.jpg#4r1e                 [The, woman, is, very, happy, .]   \n",
       "\n",
       "                                                   tokens.norm.premise  \\\n",
       "id                                                                       \n",
       "2677109430.jpg#1r1n  [this, church, choir, sing, to, the, masse, as...   \n",
       "2677109430.jpg#1r1e  [this, church, choir, sing, to, the, masse, as...   \n",
       "2677109430.jpg#1r1c  [this, church, choir, sing, to, the, masse, as...   \n",
       "6160193920.jpg#4r1n  [a, woman, with, a, green, headscarf, ,, blue,...   \n",
       "6160193920.jpg#4r1e  [a, woman, with, a, green, headscarf, ,, blue,...   \n",
       "\n",
       "                                              tokens.norm.hypothesis  \\\n",
       "id                                                                     \n",
       "2677109430.jpg#1r1n  [the, church, have, crack, in, the, ceiling, .]   \n",
       "2677109430.jpg#1r1e           [the, church, be, fill, with, song, .]   \n",
       "2677109430.jpg#1r1c    [a, choir, singing, at, a, baseball, game, .]   \n",
       "6160193920.jpg#4r1n                       [the, woman, be, young, .]   \n",
       "6160193920.jpg#4r1e                 [the, woman, be, very, happy, .]   \n",
       "\n",
       "                             label  \\\n",
       "id                                   \n",
       "2677109430.jpg#1r1n        neutral   \n",
       "2677109430.jpg#1r1e     entailment   \n",
       "2677109430.jpg#1r1c  contradiction   \n",
       "6160193920.jpg#4r1n        neutral   \n",
       "6160193920.jpg#4r1e     entailment   \n",
       "\n",
       "                                                     heuristic.premise  \\\n",
       "id                                                                       \n",
       "2677109430.jpg#1r1n  [-1.0000000150474662e+30, 3.064525842666626, 1...   \n",
       "2677109430.jpg#1r1e  [-1.0000000150474662e+30, 2.79181170463562, 2....   \n",
       "2677109430.jpg#1r1c  [-1.0000000150474662e+30, 2.5598974227905273, ...   \n",
       "6160193920.jpg#4r1n  [-1.0000000150474662e+30, 2.597653388977051, -...   \n",
       "6160193920.jpg#4r1e  [-1.0000000150474662e+30, 2.784580707550049, -...   \n",
       "\n",
       "                                                  heuristic.hypothesis  \\\n",
       "id                                                                       \n",
       "2677109430.jpg#1r1n  [-1.0000000150474662e+30, 7.628961086273193, -...   \n",
       "2677109430.jpg#1r1e  [-1.0000000150474662e+30, 7.628961086273193, -...   \n",
       "2677109430.jpg#1r1c  [-1.0000000150474662e+30, 6.388305187225342, 6...   \n",
       "6160193920.jpg#4r1n  [-1.0000000150474662e+30, 5.648240089416504, -...   \n",
       "6160193920.jpg#4r1e  [-1.0000000150474662e+30, 5.648240089416504, -...   \n",
       "\n",
       "                                                     rationale.premise  \\\n",
       "id                                                                       \n",
       "2677109430.jpg#1r1n  [False, False, False, False, False, False, Fal...   \n",
       "2677109430.jpg#1r1e  [False, False, True, True, True, True, True, F...   \n",
       "2677109430.jpg#1r1c  [False, False, False, False, False, False, Tru...   \n",
       "6160193920.jpg#4r1n  [False, False, False, False, False, False, Fal...   \n",
       "6160193920.jpg#4r1e  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                                  rationale.hypothesis  \n",
       "id                                                                      \n",
       "2677109430.jpg#1r1n  [False, False, False, True, True, True, True, ...  \n",
       "2677109430.jpg#1r1e     [False, False, False, True, True, True, False]  \n",
       "2677109430.jpg#1r1c  [False, False, True, False, False, True, True,...  \n",
       "6160193920.jpg#4r1n                 [False, False, False, True, False]  \n",
       "6160193920.jpg#4r1e          [False, False, False, False, True, False]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################\n",
    "# LOAD HEURISTIC AND ANNOTATION MAPS\n",
    "#####################################\n",
    "df = dm.test_set.data\n",
    "df = df[['id', 'tokens.form.premise', 'tokens.form.hypothesis', 'tokens.norm.premise', 'tokens.norm.hypothesis', 'label', 'heuristic.premise', 'heuristic.hypothesis', 'rationale.premise', 'rationale.hypothesis']].copy()\n",
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d8be1f77c0b4795",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:36.329504Z",
     "start_time": "2023-10-10T13:24:36.003405Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize heuristic scores\n",
    "df['heuristic.premise'] = df['heuristic.premise'].apply(lambda x: torch.tensor(x).exp())\n",
    "df['heuristic.hypothesis'] = df['heuristic.hypothesis'].apply(lambda x: torch.tensor(x).exp())\n",
    "\n",
    "df['heuristic.premise'] = df['heuristic.premise'].apply(lambda x: x / x.max())\n",
    "df['heuristic.hypothesis'] = df['heuristic.hypothesis'].apply(lambda x: x / x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74672bb50bf36633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:38.349489Z",
     "start_time": "2023-10-10T13:24:37.182483Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_prediction = pd.read_json(LOG_PATH + '/lstm_attention/esnli/run=0_lstm=1/predictions/inference.json')\n",
    "model_prediction.set_index('id', inplace=True)\n",
    "\n",
    "# Remove padding mask on attention\n",
    "model_prediction['a_hat.premise'] = model_prediction.apply(lambda x: [a for a, m in zip(x['a_hat.premise'], x['padding_mask.premise']) if not m], axis=1)\n",
    "model_prediction['a_hat.hypothesis'] = model_prediction.apply(lambda x: [a for a, m in zip(x['a_hat.hypothesis'], x['padding_mask.hypothesis']) if not m], axis=1)\n",
    "model_prediction.drop(columns=['padding_mask.premise', 'padding_mask.hypothesis'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "535ca3ed463d8347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T13:24:39.906551Z",
     "start_time": "2023-10-10T13:24:39.758709Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.join(model_prediction[['y_hat', 'a_hat.premise', 'a_hat.hypothesis']])\n",
    "df = df[df['y_hat'] == df['label']]\n",
    "df = df[df['label'] != 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb5ba657432ea8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Normalize attention scores\n",
    "from modules.utils import rescale\n",
    "df['a_hat.premise'] = df['a_hat.premise'].apply(lambda x: rescale(x).tolist())\n",
    "df['a_hat.hypothesis'] = df['a_hat.hypothesis'].apply(lambda x: rescale(x).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a9e7da6c8bfcf71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T14:15:38.788087Z",
     "start_time": "2023-10-10T14:15:38.428887Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['a_true'] = df.apply(lambda x: [0.] + x['rationale.premise'] + [0.] + x['rationale.hypothesis'], axis=1)\n",
    "df['a_hat'] = df.apply(lambda x: [0.] + x['a_hat.premise'] + [0.] + x['a_hat.hypothesis'], axis=1)\n",
    "df['a_heu'] = df.apply(lambda x: [0.] + x['heuristic.premise'].tolist() + [0.] + x['heuristic.hypothesis'].tolist(), axis=1)\n",
    "df['tokens.form'] = df.apply(lambda x: ['<b>Premise: </b>'] + x['tokens.form.premise'] + ['<br/><b>Hypothesis: </b>'] + x['tokens.form.hypothesis'], axis=1)\n",
    "df['tokens.norm'] = df.apply(lambda x: ['<b>Premise: </b>'] + x['tokens.norm.premise'] + ['<br/><b>Hypothesis: </b>'] + x['tokens.norm.hypothesis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfd6cf85424f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T14:15:47.421665Z",
     "start_time": "2023-10-10T14:15:40.400394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m highlight\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Remove the previous existing folder\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from modules.utils import highlight\n",
    "import shutil\n",
    "\n",
    "# Remove the previous existing folder\n",
    "PROJECT = 'qualitative_heuristic_esnli'\n",
    "html_dir = path.join(ROOT, PROJECT)\n",
    "log.info(f'Save qualitative results at {html_dir}')\n",
    "if os.path.exists(html_dir) and os.path.isdir(html_dir):\n",
    "    log.info(f'Removing existing folder {html_dir}')\n",
    "    shutil.rmtree(html_dir)\n",
    "\n",
    "# Generate each comparison into a file:\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    \n",
    "    # ignore if label is 0\n",
    "    if row['label'] == 'neutral': continue\n",
    "    \n",
    "    html = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    <link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css\" integrity=\"sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N\" crossorigin=\"anonymous\">\n",
    "    <style>\n",
    "    table, th, td {\n",
    "      border:solid black;\n",
    "      border-collapse: collapse;\n",
    "      padding: 0px 5px 0px 5px;\n",
    "    }\n",
    "    </style></head>\n",
    "    <body>\n",
    "    \"\"\"\n",
    "    html += '<table style=\"font-size:120%;\" cellspacing=0>'\n",
    "    html += f'<caption>Dataset: e-SNLI - Instance ID: {idx}</caption>'\n",
    "    html += f'<tr><th style=\"width:100px;\">Explainer</th> <th style=\"width:500px;\">Explanation</th> <th style=\"width:100px;\">Label</th></tr>'\n",
    "    \n",
    "    # Annotation map\n",
    "    map_viz = highlight(row['tokens.form'], row['a_true'], normalize_weight=False)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Annotation Map</td><td>{map_viz}</td><td rowspan=\"3\" style=\"text-align:center\"> {row[\"label\"]} </td></tr>'\n",
    "    \n",
    "    # Attention map\n",
    "    map_viz = highlight(row['tokens.norm'], row['a_hat'], normalize_weight=False)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Attention Map</td><td>{map_viz}</td></tr>'\n",
    "    \n",
    "    # Heuristic map\n",
    "    map_viz = highlight(row['tokens.form'], row['a_heu'], normalize_weight=True)\n",
    "    html += f'<tr><td style=\"text-align:right;\"> Heuristic Map</td><td>{map_viz}</td></tr>'\n",
    "    \n",
    "    # End\n",
    "    html += '</table>'\n",
    "    html += '</body></html>'\n",
    "\n",
    "    fpath_html = path.join(html_dir, f'{idx}.html')\n",
    "    os.makedirs(html_dir, exist_ok=True)\n",
    "    with open(fpath_html, 'w') as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2098fadb329a5a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
