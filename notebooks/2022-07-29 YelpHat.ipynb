{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42291469-df9d-43bc-8e04-550994f2f37b",
   "metadata": {},
   "source": [
    "# Study on Yelp-Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7496c4-0dd9-4d9c-9d39-fce827df3bee",
   "metadata": {},
   "source": [
    "Paper: https://davis.wpi.edu/dsrg/PROJECTS/YELPHAT/2020_ACL_Human_vs_Machine-2.pdf\n",
    "\n",
    "Summary:\n",
    "* __Do annotators carefully choose relevant words?__ Yes, as the collecting time and number of chosen words increase accross the sentence length.\n",
    "\n",
    "Sigles:\n",
    "* __HAM__ (Human Attention Map): what annotators denote\n",
    "* __CAM__ (Consensus Attention Map): bitwise __AND__ operation of the HAMs\n",
    "* __SAM__ (Super Attention Map): bitwise __OR__ operation of the HAMs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e5a77f3-37ef-489d-bbb7-73be05cfc3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../src\")\n",
    "\n",
    "cache_path = path.join(os.getcwd(), '..', '.cache')\n",
    "\n",
    "DATASET_NAME='yelp-hat'\n",
    "\n",
    "dataset_path = path.join(cache_path, 'dataset', DATASET_NAME)\n",
    "\n",
    "tmp_path = path.join('.cache', '2022-07-29')\n",
    "os.makedirs(tmp_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b21b898-c66b-4f5a-8705-e2929c2d8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset zip\n",
    "URL='https://github.com/cansusen/Human-Attention-for-Text-Classification/archive/205c1552bc7be7ec48623d79d85d4c6fbfe62362.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02a562-b02d-4bec-aee5-1951162e0789",
   "metadata": {},
   "source": [
    "Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c006c64-6808-42d4-9ae0-394cc633df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import shutil\n",
    "\n",
    "zip_path = download_from_url(URL, root=dataset_path, path=path.join(dataset_path, f'{DATASET_NAME}.zip'))\n",
    "files = extract_archive(from_path=zip_path, to_path=dataset_path)\n",
    "\n",
    "for f in files:\n",
    "    if f.endswith('.csv'):\n",
    "        shutil.copy2(f, dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e15a9b-8e9b-45cf-bde9-81cd12eabafa",
   "metadata": {},
   "source": [
    "A quoi ressemble la dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57ef225d-0bbb-4172-8037-55416133d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Very slow. Never been in the drive at any othe...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span class=\"active\"&gt;Very&lt;/span&gt; &lt;span class=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Very slow. Never been in the drive at any othe...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Very&lt;/span&gt; &lt;span class=\"active\"&gt;slow.&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>I went here to get a snack before I went on th...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;went&lt;/span&gt; &lt;span&gt;here&lt;/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>I went here to get a snack before I went on th...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;went&lt;/span&gt; &lt;span&gt;here&lt;/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Always&lt;/span&gt; &lt;span&gt;packed&lt;/span&gt; &lt;span&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Always&lt;/span&gt; &lt;span&gt;packed&lt;/span&gt; &lt;span&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span class=\"active\"&gt;Always&lt;/span&gt; &lt;span class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.label                                         Input.text  \\\n",
       "0              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "1              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "2              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "3              0  Very slow. Never been in the drive at any othe...   \n",
       "4              0  Very slow. Never been in the drive at any othe...   \n",
       "..           ...                                                ...   \n",
       "895            0  I went here to get a snack before I went on th...   \n",
       "896            0  I went here to get a snack before I went on th...   \n",
       "897            0  Always packed for lunch.  Probably because Pit...   \n",
       "898            0  Always packed for lunch.  Probably because Pit...   \n",
       "899            0  Always packed for lunch.  Probably because Pit...   \n",
       "\n",
       "    Answer.Q1Answer                                 Answer.html_output  \n",
       "0               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "1               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "2               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "3                no  <span class=\"active\">Very</span> <span class=\"...  \n",
       "4                no  <span>Very</span> <span class=\"active\">slow.</...  \n",
       "..              ...                                                ...  \n",
       "895              no  <span>I</span> <span>went</span> <span>here</s...  \n",
       "896              no  <span>I</span> <span>went</span> <span>here</s...  \n",
       "897              no  <span>Always</span> <span>packed</span> <span>...  \n",
       "898              no  <span>Always</span> <span>packed</span> <span>...  \n",
       "899              no  <span class=\"active\">Always</span> <span class...  \n",
       "\n",
       "[900 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path.join(dataset_path, 'ham_part1(50words).csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14f7a0ed-c9fa-424e-9473-db6c85dce7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words highlighted in this review: 6\n",
      "Original annotation: <span>Out</span> <span>in</span> <span>Twinsburg</span> <span>for</span> <span>work</span> <span>and</span> <span>wasn't</span> <span>expecting</span> <span>to</span> <span>find</span> <span>a</span> <span>well</span> <span>reviewed</span> <span>sushi</span> <span>restaurant</span> <span>but</span> <span class=\"active\">glad</span> <span>I</span> <span>did.</span> <span>It</span> <span>was</span> <span>quite</span> <span>busy</span> <span>for</span> <span>a</span> <span>Monday</span> <span>and</span> <span>the</span> <span>poor</span> <span>waitress</span> <span>was</span> <span>slammed</span> <span>but</span> <span>the</span> <span>sushi</span> <span>chef</span> <span>stepped</span> <span>in</span> <span>to</span> <span>help</span> <span>and</span> <span>was</span> <span class=\"active\">very</span> <span class=\"active\">friendly.</span> <span>The</span> <span class=\"active\">presentation</span> <span>and</span> <span class=\"active\">flavors</span> <span>were</span> <span class=\"active\">great.</span> <span></span>\n",
      "Binarized attention map: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def generate_binary_human_attention_vector(html, num_words_in_review, max_words):\n",
    "    # Function provided by the dataset :\n",
    "    # https://github.com/cansusen/Human-Attention-for-Text-Classification/blob/master/generate_ham/sample_generate.ipynb\n",
    "\n",
    "    p = re.compile('<span(.*?)/span>')\n",
    "    all_span_items = p.findall(html)\n",
    "\n",
    "    if html == '{}':\n",
    "        print('Empty human annotation - This should never print')\n",
    "        return [0] * max_words\n",
    "\n",
    "    if len(all_span_items) == num_words_in_review + 1:\n",
    "        if (all_span_items[num_words_in_review] == '><') or (all_span_items[num_words_in_review] == ' data-vivaldi-spatnav-clickable=\"1\"><'):\n",
    "\n",
    "            binarized_human_attention = [0] * max_words\n",
    "            for i in range(0, len(all_span_items) - 1):\n",
    "                if 'class=\"active\"' in all_span_items[i]:\n",
    "                    binarized_human_attention[i] = 1\n",
    "\n",
    "        else:\n",
    "            print('This should never print.')\n",
    "    else:\n",
    "        print('This should never print.')\n",
    "\n",
    "    return binarized_human_attention\n",
    "\n",
    "MAX_WORDS = 100\n",
    "i = 0\n",
    "html = df['Answer.html_output'][i]\n",
    "num_highlighted = html.count('class=\"active\"')\n",
    "num_words_in_review = len(df['Input.text'][i].split())\n",
    "\n",
    "binarized_human_attention = generate_binary_human_attention_vector(html, num_words_in_review, MAX_WORDS)\n",
    "\n",
    "\n",
    "print(\"Number of words highlighted in this review:\",num_highlighted)\n",
    "print(\"Original annotation:\", html)\n",
    "print(\"Binarized attention map:\",binarized_human_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfc5ee17-0c54-4cdd-a0b1-93fccaffe5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, False, True, False, True]\n",
      "Check ham_part7.csv\n",
      "2096\n",
      "Check ham_part5.csv\n",
      "2999\n",
      "Check ham_part8(200words).csv\n",
      "543\n",
      "Check ham_part6(100words).csv\n",
      "1314\n",
      "Check ham_part4.csv\n",
      "3000\n",
      "Check ham_part3.csv\n",
      "3000\n",
      "Check ham_part1(50words).csv\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "def tokenize(html):\n",
    "    p = re.compile(r'<span[^>]*>(.+?)</span>')\n",
    "    return p.findall(html)\n",
    "\n",
    "def human_attention(html):\n",
    "\n",
    "    p = re.compile('<span(.*?)/span>')\n",
    "    all_span_items = p.findall(html)\n",
    "    if all_span_items[-1] == '><': all_span_items = all_span_items[:-1]\n",
    "\n",
    "    return ['class=\"active\"' in span_item for span_item in all_span_items]\n",
    "\n",
    "v_hat = human_attention(html)\n",
    "print(v_hat)\n",
    "\n",
    "# Check if we tokenize html, can our function \"human_attention\" reproduce the exact same length\n",
    "\n",
    "for fpath in os.listdir(dataset_path):\n",
    "    \n",
    "    if fpath.endswith('.csv'):\n",
    "        print('Check',fpath)\n",
    "        df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "        print(len(df['Answer.html_output']))\n",
    "        for html in df['Answer.html_output']:\n",
    "            tokens = tokenize(html)\n",
    "            v_hat = human_attention(html)\n",
    "            if len(tokens) != len(v_hat):\n",
    "                print(len(tokens), len(v_hat))\n",
    "                print(' '.tokens)\n",
    "                display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294fbb9-118e-4076-a792-9bfd59f1415c",
   "metadata": {},
   "source": [
    "Proceed dataset step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2299c93e-1bd5-4b00-9c67-15344a47201f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Raw dataset</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The food quality and portion size was awesome....</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;The&lt;/span&gt; &lt;span class=\"active\"&gt;food&lt;/sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The food quality and portion size was awesome....</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;The&lt;/span&gt; &lt;span&gt;food&lt;/span&gt; &lt;span class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The food quality and portion size was awesome....</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;The&lt;/span&gt; &lt;span&gt;food&lt;/span&gt; &lt;span&gt;quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Found these guys at taste of calgary and had t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Found&lt;/span&gt; &lt;span&gt;these&lt;/span&gt; &lt;span&gt;gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Found these guys at taste of calgary and had t...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Found&lt;/span&gt; &lt;span&gt;these&lt;/span&gt; &lt;span&gt;gu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.label                                         Input.text  \\\n",
       "0            1  The food quality and portion size was awesome....   \n",
       "1            1  The food quality and portion size was awesome....   \n",
       "2            1  The food quality and portion size was awesome....   \n",
       "3            1  Found these guys at taste of calgary and had t...   \n",
       "4            1  Found these guys at taste of calgary and had t...   \n",
       "\n",
       "  Answer.Q1Answer                                 Answer.html_output  \n",
       "0             yes  <span>The</span> <span class=\"active\">food</sp...  \n",
       "1             yes  <span>The</span> <span>food</span> <span class...  \n",
       "2             yes  <span>The</span> <span>food</span> <span>quali...  \n",
       "3             yes  <span>Found</span> <span>these</span> <span>gu...  \n",
       "4             yes  <span>Found</span> <span>these</span> <span>gu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m display(HTML(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<h3>Raw dataset</h3>\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m display(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m----> 6\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m3\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.html_output\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.Q1Answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m      7\u001b[0m dfs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mloc[idx::\u001b[38;5;241m3\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.html_output\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.Q1Answer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.html_output\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation_html_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.Q1Answer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman_label_\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;28mstr\u001b[39m(idx)) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m) ]\n\u001b[1;32m      8\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.label\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(dataset_path, 'ham_part3.csv'))\n",
    "display(HTML('<h3>Raw dataset</h3>'))\n",
    "display(df.head())\n",
    "\n",
    "\n",
    "dfs = [df.loc[0::3, df.columns != 'Answer.html_output' and df.columns != 'Answer.Q1Answer'].reset_index(drop=True)]\n",
    "dfs += [df.loc[idx::3, ['Answer.html_output','Answer.Q1Answer']].reset_index(drop=True).rename(columns={'Answer.html_output':'annotation_html_', 'Answer.Q1Answer': 'human_label_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text'})\n",
    "clean_df = clean_df[['text', 'annotation_html_0', 'annotation_html_1', 'annotation_html_2', 'label', 'human_label']]\n",
    "display(HTML('<h3>Clean up dataset</h3>'))\n",
    "display(clean_df.head())\n",
    "\n",
    "from data.yelp_hat.utils import yelp_hat_ham, yelp_hat_token\n",
    "clean_df['text_tokens'] = clean_df['annotation_html_0'].apply(yelp_hat_token)\n",
    "for idx in range(3):\n",
    "    clean_df[f'annotation_map_{idx}'] = clean_df[f'annotation_html_{idx}'].apply(yelp_hat_ham)\n",
    "display(HTML('<h3>Binarize annotation</h3>'))\n",
    "display(clean_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68cd16-6e28-45fd-b86a-6cba7f3819f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> By reconcatenating for spacy and re tokenize, do we obtain the coherent length?\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fca69a6-c3f6-4d57-afa9-07eef4f35481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f90aa7f19143869455890a833cf080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_part5.csv : Same tokens between text and ham > True\n",
      "ham_part8(200words).csv : Same tokens between text and ham > True\n",
      "ham_part6(100words).csv : Same tokens between text and ham > True\n",
      "ham_part4.csv : Same tokens between text and ham > True\n",
      "ham_part3.csv : Same tokens between text and ham > True\n",
      "ham_part1(50words).csv : Same tokens between text and ham > True\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "def tokenize_ham(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = [str(tag.string) for tag in soup.find_all('span') if tag.string is not None]\n",
    "    tokens = [str(tk.text) for doc in nlp.pipe(tags) for tk in doc]\n",
    "    return tokens\n",
    "\n",
    "files = [fpath for fpath in os.listdir(dataset_path) if fpath.endswith('.csv') and 'part7' not in fpath]\n",
    "\n",
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'ham_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "\n",
    "    clean_df['ham_tokens'] = clean_df['ham_html_0'].apply(tokenize_ham)\n",
    "    clean_df['count_ham_tokens'] = clean_df['ham_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    clean_df['count_text_tokens'] = clean_df['text_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    is_every_row_ok = (clean_df['count_text_tokens'] == clean_df['count_ham_tokens']).all()\n",
    "    print(fpath, ': Same tokens between text and ham >', is_every_row_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d68d5-ab3f-40fd-9260-02610908f91c",
   "metadata": {},
   "source": [
    "###### Split tokens in human attention maps by spacy, verify if `len(token) == len(annotation)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7efc1689-a576-427d-a481-e67541fb0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>Out</span> <span>in</span> <span>Twinsburg</span> <span>for</span> <span>work</span> <span>and</span> <span>wasn't</span> <span>expecting</span> <span>to</span> <span>find</span> <span>a</span> <span>well</span> <span>reviewed</span> <span>sushi</span> <span>restaurant</span> <span>but</span> <span class=\"active\">glad</span> <span>I</span> <span>did.</span> <span>It</span> <span>was</span> <span>quite</span> <span>busy</span> <span>for</span> <span>a</span> <span>Monday</span> <span>and</span> <span>the</span> <span>poor</span> <span>waitress</span> <span>was</span> <span>slammed</span> <span>but</span> <span>the</span> <span>sushi</span> <span>chef</span> <span>stepped</span> <span>in</span> <span>to</span> <span>help</span> <span>and</span> <span>was</span> <span class=\"active\">very</span> <span class=\"active\">friendly.</span> <span>The</span> <span class=\"active\">presentation</span> <span>and</span> <span class=\"active\">flavors</span> <span>were</span> <span class=\"active\">great.</span> <span></span>\n",
      "['Out', 'in', 'Twinsburg', 'for', 'work', 'and', 'was', \"n't\", 'expecting', 'to', 'find', 'a', 'well', 'reviewed', 'sushi', 'restaurant', 'but', 'glad', 'I', 'did', '.', 'It', 'was', 'quite', 'busy', 'for', 'a', 'Monday', 'and', 'the', 'poor', 'waitress', 'was', 'slammed', 'but', 'the', 'sushi', 'chef', 'stepped', 'in', 'to', 'help', 'and', 'was', 'very', 'friendly', '.', 'The', 'presentation', 'and', 'flavors', 'were', 'great', '.']\n"
     ]
    }
   ],
   "source": [
    "def binarize_ham(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = [tag for tag in soup.find_all('span') if tag.string is not None]\n",
    "    \n",
    "    tag_annot = [int('active' in t.get('class', [])) for t in tags]\n",
    "    tag_str = [str(t.string) for t in tags]\n",
    "    \n",
    "    ham = []\n",
    "    \n",
    "    for annot, splitted_tokens in zip(tag_annot, nlp.pipe(tag_str)):\n",
    "        annotation = [annot * int(not tk.is_punct) for tk in splitted_tokens]\n",
    "        ham += annotation\n",
    "    \n",
    "    return ham\n",
    "\n",
    "html = clean_df['ham_html_0']\n",
    "print(html[0])\n",
    "print(tokenize_ham(html[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a068205-9890-40c3-892e-16fd77d2c554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c014157d55da45ceb842f0c161b60b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ham_html_0', 'ham_html_1', 'ham_html_2'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m dfs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [df\u001b[38;5;241m.\u001b[39mloc[idx::\u001b[38;5;241m3\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.html_output\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.html_output\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotation_html_\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39madd_suffix(\u001b[38;5;28mstr\u001b[39m(idx)) \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m) ]\n\u001b[1;32m      9\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.label\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer.Q1Answer\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman_label\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m---> 10\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mham_html_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mham_html_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mham_html_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhuman_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham_html_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(binarize_ham)\n\u001b[1;32m     13\u001b[0m clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount_ham_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mham_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;28mlen\u001b[39m(row))\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ham_html_0', 'ham_html_1', 'ham_html_2'] not in index\""
     ]
    }
   ],
   "source": [
    "files = [fpath for fpath in os.listdir(dataset_path) if fpath.endswith('.csv') and 'part7' not in fpath]\n",
    "\n",
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'annotation_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "\n",
    "    clean_df['ham_tokens'] = clean_df['ham_html_0'].apply(binarize_ham)\n",
    "    clean_df['count_ham_tokens'] = clean_df['ham_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    clean_df['count_text_tokens'] = clean_df['text_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    is_every_row_ok = (clean_df['count_text_tokens'] == clean_df['count_ham_tokens']).all()\n",
    "    print(fpath, ': Same tokens between text and ham >', is_every_row_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac68ca6-bc03-40c7-bcd3-a8f378a78dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f37284a6-44d4-4c46-a765-2ee421f48cfd",
   "metadata": {},
   "source": [
    "## Check sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76b9d553-01e7-49a1-8b7f-1ed61696d345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de46c389e4134cae9b3aa9c6d25ae253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part5.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.694</td>\n",
       "      <td>7.983865</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%   max\n",
       "label        1000.0   0.516  0.499994   0.0   0.0   1.0   1.0   1.0\n",
       "text_length  1000.0  71.694  7.983865  55.0  66.0  71.0  78.0  97.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part8(200words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>0.501318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>181.0</td>\n",
       "      <td>230.071823</td>\n",
       "      <td>8.317340</td>\n",
       "      <td>210.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean       std    min    25%    50%    75%    max\n",
       "label        181.0    0.508287  0.501318    0.0    0.0    1.0    1.0    1.0\n",
       "text_length  181.0  230.071823  8.317340  210.0  224.0  230.0  235.0  252.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part6(100words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>438.0</td>\n",
       "      <td>0.513699</td>\n",
       "      <td>0.500384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>438.0</td>\n",
       "      <td>115.276256</td>\n",
       "      <td>5.565827</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean       std    min    25%    50%    75%    max\n",
       "label        438.0    0.513699  0.500384    0.0    0.0    1.0    1.0    1.0\n",
       "text_length  438.0  115.276256  5.565827  101.0  112.0  114.0  118.0  144.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part4.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.500201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.604</td>\n",
       "      <td>7.837641</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%    max\n",
       "label        1000.0   0.507  0.500201   0.0   0.0   1.0   1.0    1.0\n",
       "text_length  1000.0  71.604  7.837641  55.0  65.0  71.0  78.0  101.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part3.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.500241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.958</td>\n",
       "      <td>8.178944</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%    max\n",
       "label        1000.0   0.497  0.500241   0.0   0.0   0.0   1.0    1.0\n",
       "text_length  1000.0  71.958  8.178944  53.0  65.0  72.0  78.0  107.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part1(50words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.500557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>300.0</td>\n",
       "      <td>58.006667</td>\n",
       "      <td>3.009454</td>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean       std   min   25%   50%   75%   max\n",
       "label        300.0   0.483333  0.500557   0.0   0.0   0.0   1.0   1.0\n",
       "text_length  300.0  58.006667  3.009454  50.0  56.0  57.0  60.0  72.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "    display(HTML(f'<h3>{fpath}</h3>'))\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'ham_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    \n",
    "    clean_df['text_length'] = clean_df.text_tokens.str.len()\n",
    "    display(clean_df.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886978c-4171-4c53-bba3-0d91c9b7c577",
   "metadata": {},
   "source": [
    "### Handle case part7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57fe67ac-33e5-49ac-82f5-e9a03b104ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_html_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;$18.95&lt;/span&gt; &lt;span&gt;per&lt;/span&gt; &lt;span&gt;per...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;$18.95&lt;/span&gt; &lt;span&gt;per&lt;/span&gt; &lt;span&gt;per...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>0</td>\n",
       "      <td>Zero stars. Booked my brithday here. The waite...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Zero&lt;/span&gt; &lt;span&gt;stars.&lt;/span&gt; &lt;span&gt;Bo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2092</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoup has a large variety of soups on a daily r...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Zoup&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;a&lt;/sp...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoup has a large variety of soups on a daily r...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Zoup&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;a&lt;/sp...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoup has a large variety of soups on a daily r...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Zoup&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;a&lt;/sp...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoup has a large variety of soups on a daily r...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Zoup&lt;/span&gt; &lt;span&gt;has&lt;/span&gt; &lt;span&gt;a&lt;/sp...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2096 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Input.label                                         Input.text  \\\n",
       "0               0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "1               0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "2               0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "3               0  $18.95 per person....Was really hungry for lun...   \n",
       "4               0  $18.95 per person....Was really hungry for lun...   \n",
       "...           ...                                                ...   \n",
       "2091            0  Zero stars. Booked my brithday here. The waite...   \n",
       "2092            1  Zoup has a large variety of soups on a daily r...   \n",
       "2093            1  Zoup has a large variety of soups on a daily r...   \n",
       "2094            1  Zoup has a large variety of soups on a daily r...   \n",
       "2095            1  Zoup has a large variety of soups on a daily r...   \n",
       "\n",
       "     Answer.Q1Answer                                 Answer.html_output  \\\n",
       "0                 no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "1                 no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "2                 no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "3                 no  <span>$18.95</span> <span>per</span> <span>per...   \n",
       "4                 no  <span>$18.95</span> <span>per</span> <span>per...   \n",
       "...              ...                                                ...   \n",
       "2091              no  <span>Zero</span> <span>stars.</span> <span>Bo...   \n",
       "2092             yes  <span>Zoup</span> <span>has</span> <span>a</sp...   \n",
       "2093             yes  <span>Zoup</span> <span>has</span> <span>a</sp...   \n",
       "2094             yes  <span>Zoup</span> <span>has</span> <span>a</sp...   \n",
       "2095             yes  <span>Zoup</span> <span>has</span> <span>a</sp...   \n",
       "\n",
       "                                              ham_html_  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2091  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2092  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2093  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "2094  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "2095  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "\n",
       "[2096 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(dataset_path, 'ham_part7.csv'))\n",
    "df['ham_html_'] = df[f'Answer.html_output'].apply(yelp_hat_ham)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb5f50b6-3ee0-4b31-b8a9-036f8799e47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. Happy hour pricing is only available in the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 Minute wait per dish. Never coming here aga...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd time eating here, We drive 35 miles from H...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>if you are a vegetarian, do not go here. Don't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>the Jucy lucy is the only good thing about thi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>this place is filthy the mens room stinks of u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>very good ramen in a strip mall in vegas. the ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>went for lunch once and tried it again for din...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 index  size\n",
       "0    $18.95 per person....Was really hungry for lun...     3\n",
       "1    *knocks on door*\\n*walks into restaurant*\\n*go...     3\n",
       "2    1. Happy hour pricing is only available in the...     3\n",
       "3    20 Minute wait per dish. Never coming here aga...     3\n",
       "4    2nd time eating here, We drive 35 miles from H...     3\n",
       "..                                                 ...   ...\n",
       "620  if you are a vegetarian, do not go here. Don't...     2\n",
       "621  the Jucy lucy is the only good thing about thi...     4\n",
       "622  this place is filthy the mens room stinks of u...     4\n",
       "623  very good ramen in a strip mall in vegas. the ...     3\n",
       "624  went for lunch once and tried it again for din...     2\n",
       "\n",
       "[625 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df.groupby(df['Input.text'].tolist(),as_index=False).size()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30df6df6-fee8-4bf7-b4c9-c3457f9a2319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7de9074fde4bde9051ad717c6e77e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_html_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>Cold coffee, cold donut, flies EVERYWHERE, bis...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span class=\"active\"&gt;Cold&lt;/span&gt; &lt;span class=\"...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>Cold coffee, cold donut, flies EVERYWHERE, bis...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Cold&lt;/span&gt; &lt;span&gt;coffee,&lt;/span&gt; &lt;span&gt;c...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.label                                         Input.text  \\\n",
       "197            0  Cold coffee, cold donut, flies EVERYWHERE, bis...   \n",
       "198            0  Cold coffee, cold donut, flies EVERYWHERE, bis...   \n",
       "\n",
       "    Answer.Q1Answer                                 Answer.html_output  \\\n",
       "197              no  <span class=\"active\">Cold</span> <span class=\"...   \n",
       "198              no  <span>Cold</span> <span>coffee,</span> <span>c...   \n",
       "\n",
       "                                             ham_html_  \n",
       "197  [1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ...  \n",
       "198  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_html_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>Compared to others in the area, Scramble beats...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Compared&lt;/span&gt; &lt;span&gt;to&lt;/span&gt; &lt;span&gt;ot...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>Compared to others in the area, Scramble beats...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Compared&lt;/span&gt; &lt;span&gt;to&lt;/span&gt; &lt;span&gt;ot...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.label                                         Input.text  \\\n",
       "199            1  Compared to others in the area, Scramble beats...   \n",
       "200            1  Compared to others in the area, Scramble beats...   \n",
       "\n",
       "    Answer.Q1Answer                                 Answer.html_output  \\\n",
       "199             yes  <span>Compared</span> <span>to</span> <span>ot...   \n",
       "200             yes  <span>Compared</span> <span>to</span> <span>ot...   \n",
       "\n",
       "                                             ham_html_  \n",
       "199  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "200  [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_html_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0</td>\n",
       "      <td>DON'T waste your Time Money or Abuse your Tumm...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;DON'T&lt;/span&gt; &lt;span class=\"active\"&gt;waste&lt;...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0</td>\n",
       "      <td>DON'T waste your Time Money or Abuse your Tumm...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;DON'T&lt;/span&gt; &lt;span&gt;waste&lt;/span&gt; &lt;span&gt;yo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.label                                         Input.text  \\\n",
       "261            0  DON'T waste your Time Money or Abuse your Tumm...   \n",
       "262            0  DON'T waste your Time Money or Abuse your Tumm...   \n",
       "\n",
       "    Answer.Q1Answer                                 Answer.html_output  \\\n",
       "261              no  <span>DON'T</span> <span class=\"active\">waste<...   \n",
       "262              no  <span>DON'T</span> <span>waste</span> <span>yo...   \n",
       "\n",
       "                                             ham_html_  \n",
       "261  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "262  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dupli_2 = duplicates[duplicates['size'] < 3]\n",
    "\n",
    "for d in tqdm(dupli_2['index'][:3]):\n",
    "    display(df.loc[df['Input.text'] == d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae090f9e-75d9-4599-9bcf-08d4def24657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 53,  54,  56,  57,  61,  65,  69,  71,  76,  78,\n",
       "            ...\n",
       "            574, 584, 592, 595, 597, 605, 616, 618, 620, 624],\n",
       "           dtype='int64', length=130)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupli_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba9e4fd8-537b-42da-a66e-fae35867b187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all text that has only 2 reviews:\n",
    "df2 = df[~df['Input.text'].isin(dupli_2['index'])]\n",
    "\n",
    "# Verify if no more 2-row duplicate exist\n",
    "duplicates_2 = df2.groupby(df2['Input.text'].tolist(),as_index=False).size()\n",
    "duplicates_2['size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03380e7-0f3b-4a7a-82bc-4c8f3872cca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946576c9-a26b-42a9-a246-b4ea32ae0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3207f-047b-4908-94b1-1540866acbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a3d51-09a9-411d-a64d-9d33ae795694",
   "metadata": {},
   "outputs": [],
   "source": [
    "dupli_2 = duplicates[duplicates['size'] < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d53ba-fbb4-4377-899d-d261ed004160",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['text', 'label', 'ham_html_0', 'ham_html_1', ]\n",
    "data_dict = {'text': list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e71c7021-6c92-4a89-b682-c2c4e5e4ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate of 2 : 130\n",
      "Duplicate of 3 : 144\n",
      "Duplicate of 4 : 351\n"
     ]
    }
   ],
   "source": [
    "for dup_rows in [2, 3, 4]:\n",
    "    print('Duplicate of', dup_rows, ':', sum(duplicates['size'] == dup_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c4b11ed-ea88-401e-af89-e5f68c57af42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8      A measly amount of rice and beans for 10 bucks...\n",
       "9      A violently red coloured Pad Thai. It tasted l...\n",
       "10     Above average scallop dinner, however surprise...\n",
       "11     Above- average food with mediocre-below averag...\n",
       "12     Absolute GARBAGE!  The waiter bragged how they...\n",
       "                             ...                        \n",
       "613    Zero stars. Booked my brithday here. The waite...\n",
       "614    Zoup has a large variety of soups on a daily r...\n",
       "615    an excellent place for lunch, the food is grea...\n",
       "621    the Jucy lucy is the only good thing about thi...\n",
       "622    this place is filthy the mens room stinks of u...\n",
       "Name: index, Length: 351, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates[duplicates['size'] == 4]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e34721fd-71f0-4bf2-971a-387e37d499f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/74qzbgts2pjdbwt397c_q5dr00m9p0/T/ipykernel_16760/3391962994.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  text_4 = df[duplicates['size'] == 4]\n"
     ]
    },
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text_4 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mduplicates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m text_4\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3500\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/frame.py:3549\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3545\u001b[0m     )\n\u001b[1;32m   3547\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[1;32m   3548\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m-> 3549\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3550\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexing.py:2383\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2381\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(result\u001b[38;5;241m.\u001b[39m_values)\n\u001b[1;32m   2382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m-> 2383\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2384\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2385\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2386\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2387\u001b[0m         )\n\u001b[1;32m   2388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(key):\n\u001b[1;32m   2390\u001b[0m     \u001b[38;5;66;03m# key might be object-dtype bool, check_array_indexer needs bool array\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "text_4 = df[duplicates['size'] == 4]\n",
    "text_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28105a9f-09f0-46fb-9a88-a6638648773e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
