{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42291469-df9d-43bc-8e04-550994f2f37b",
   "metadata": {},
   "source": [
    "# Study on Yelp-Hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7496c4-0dd9-4d9c-9d39-fce827df3bee",
   "metadata": {},
   "source": [
    "Paper: https://davis.wpi.edu/dsrg/PROJECTS/YELPHAT/2020_ACL_Human_vs_Machine-2.pdf\n",
    "\n",
    "Summary:\n",
    "* __Do annotators carefully choose relevant words?__ Yes, as the collecting time and number of chosen words increase accross the sentence length.\n",
    "\n",
    "Sigles:\n",
    "* __HAM__ (Human Attention Map): what annotators denote\n",
    "* __CAM__ (Consensus Attention Map): bitwise __AND__ operation of the HAMs\n",
    "* __SAM__ (Super Attention Map): bitwise __OR__ operation of the HAMs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5a77f3-37ef-489d-bbb7-73be05cfc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./../src\")\n",
    "\n",
    "cache_path = path.join(os.getcwd(), '..', '.cache')\n",
    "\n",
    "DATASET_NAME='yelp-hat'\n",
    "\n",
    "dataset_path = path.join(cache_path, 'dataset', DATASET_NAME)\n",
    "\n",
    "tmp_path = path.join('.cache', '2022-07-29')\n",
    "os.makedirs(tmp_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02a562-b02d-4bec-aee5-1951162e0789",
   "metadata": {},
   "source": [
    "Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c006c64-6808-42d4-9ae0-394cc633df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import shutil\n",
    "\n",
    "# Download dataset zip\n",
    "URL='https://github.com/cansusen/Human-Attention-for-Text-Classification/archive/205c1552bc7be7ec48623d79d85d4c6fbfe62362.zip'\n",
    "\n",
    "zip_path = download_from_url(URL, root=dataset_path, path=path.join(dataset_path, f'{DATASET_NAME}.zip'))\n",
    "extracted_path = path.join(dataset_path, 'caching')\n",
    "files = extract_archive(from_path=zip_path, to_path=extracted_path)\n",
    "files = [f for f in files if f.endswith('.csv')]\n",
    "\n",
    "for f in files: shutil.copy2(f, extracted_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e15a9b-8e9b-45cf-bde9-81cd12eabafa",
   "metadata": {},
   "source": [
    "A quoi ressemble la dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ef225d-0bbb-4172-8037-55416133d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Out in Twinsburg for work and wasn't expecting...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Out&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; &lt;span&gt;Twinsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Very slow. Never been in the drive at any othe...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span class=\"active\"&gt;Very&lt;/span&gt; &lt;span class=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Very slow. Never been in the drive at any othe...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Very&lt;/span&gt; &lt;span class=\"active\"&gt;slow.&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>I went here to get a snack before I went on th...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;went&lt;/span&gt; &lt;span&gt;here&lt;/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>I went here to get a snack before I went on th...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;went&lt;/span&gt; &lt;span&gt;here&lt;/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Always&lt;/span&gt; &lt;span&gt;packed&lt;/span&gt; &lt;span&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;Always&lt;/span&gt; &lt;span&gt;packed&lt;/span&gt; &lt;span&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0</td>\n",
       "      <td>Always packed for lunch.  Probably because Pit...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span class=\"active\"&gt;Always&lt;/span&gt; &lt;span class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input.label                                         Input.text  \\\n",
       "0              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "1              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "2              1  Out in Twinsburg for work and wasn't expecting...   \n",
       "3              0  Very slow. Never been in the drive at any othe...   \n",
       "4              0  Very slow. Never been in the drive at any othe...   \n",
       "..           ...                                                ...   \n",
       "895            0  I went here to get a snack before I went on th...   \n",
       "896            0  I went here to get a snack before I went on th...   \n",
       "897            0  Always packed for lunch.  Probably because Pit...   \n",
       "898            0  Always packed for lunch.  Probably because Pit...   \n",
       "899            0  Always packed for lunch.  Probably because Pit...   \n",
       "\n",
       "    Answer.Q1Answer                                 Answer.html_output  \n",
       "0               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "1               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "2               yes  <span>Out</span> <span>in</span> <span>Twinsbu...  \n",
       "3                no  <span class=\"active\">Very</span> <span class=\"...  \n",
       "4                no  <span>Very</span> <span class=\"active\">slow.</...  \n",
       "..              ...                                                ...  \n",
       "895              no  <span>I</span> <span>went</span> <span>here</s...  \n",
       "896              no  <span>I</span> <span>went</span> <span>here</s...  \n",
       "897              no  <span>Always</span> <span>packed</span> <span>...  \n",
       "898              no  <span>Always</span> <span>packed</span> <span>...  \n",
       "899              no  <span class=\"active\">Always</span> <span class...  \n",
       "\n",
       "[900 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path.join(extracted_path, 'ham_part1(50words).csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f7a0ed-c9fa-424e-9473-db6c85dce7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words highlighted in this review: 6\n",
      "Original annotation: <span>Out</span> <span>in</span> <span>Twinsburg</span> <span>for</span> <span>work</span> <span>and</span> <span>wasn't</span> <span>expecting</span> <span>to</span> <span>find</span> <span>a</span> <span>well</span> <span>reviewed</span> <span>sushi</span> <span>restaurant</span> <span>but</span> <span class=\"active\">glad</span> <span>I</span> <span>did.</span> <span>It</span> <span>was</span> <span>quite</span> <span>busy</span> <span>for</span> <span>a</span> <span>Monday</span> <span>and</span> <span>the</span> <span>poor</span> <span>waitress</span> <span>was</span> <span>slammed</span> <span>but</span> <span>the</span> <span>sushi</span> <span>chef</span> <span>stepped</span> <span>in</span> <span>to</span> <span>help</span> <span>and</span> <span>was</span> <span class=\"active\">very</span> <span class=\"active\">friendly.</span> <span>The</span> <span class=\"active\">presentation</span> <span>and</span> <span class=\"active\">flavors</span> <span>were</span> <span class=\"active\">great.</span> <span></span>\n",
      "Binarized attention map: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def generate_binary_human_attention_vector(html, num_words_in_review, max_words):\n",
    "    # Function provided by the dataset :\n",
    "    # https://github.com/cansusen/Human-Attention-for-Text-Classification/blob/master/generate_ham/sample_generate.ipynb\n",
    "\n",
    "    p = re.compile('<span(.*?)/span>')\n",
    "    all_span_items = p.findall(html)\n",
    "\n",
    "    if html == '{}':\n",
    "        print('Empty human annotation - This should never print')\n",
    "        return [0] * max_words\n",
    "\n",
    "    if len(all_span_items) == num_words_in_review + 1:\n",
    "        if (all_span_items[num_words_in_review] == '><') or (all_span_items[num_words_in_review] == ' data-vivaldi-spatnav-clickable=\"1\"><'):\n",
    "\n",
    "            binarized_human_attention = [0] * max_words\n",
    "            for i in range(0, len(all_span_items) - 1):\n",
    "                if 'class=\"active\"' in all_span_items[i]:\n",
    "                    binarized_human_attention[i] = 1\n",
    "\n",
    "        else:\n",
    "            print('This should never print.')\n",
    "    else:\n",
    "        print('This should never print.')\n",
    "\n",
    "    return binarized_human_attention\n",
    "\n",
    "MAX_WORDS = 100\n",
    "i = 0\n",
    "html = df['Answer.html_output'][i]\n",
    "num_highlighted = html.count('class=\"active\"')\n",
    "num_words_in_review = len(df['Input.text'][i].split())\n",
    "\n",
    "binarized_human_attention = generate_binary_human_attention_vector(html, num_words_in_review, MAX_WORDS)\n",
    "\n",
    "\n",
    "print(\"Number of words highlighted in this review:\",num_highlighted)\n",
    "print(\"Original annotation:\", html)\n",
    "print(\"Binarized attention map:\",binarized_human_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dfc5ee17-0c54-4cdd-a0b1-93fccaffe5f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'html' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [137]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_span_items[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m><\u001b[39m\u001b[38;5;124m'\u001b[39m: all_span_items \u001b[38;5;241m=\u001b[39m all_span_items[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m span_item \u001b[38;5;28;01mfor\u001b[39;00m span_item \u001b[38;5;129;01min\u001b[39;00m all_span_items]\n\u001b[0;32m---> 13\u001b[0m v_hat \u001b[38;5;241m=\u001b[39m human_attention(\u001b[43mhtml\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(v_hat)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Check if we tokenize html, can our function \"human_attention\" reproduce the exact same length\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'html' is not defined"
     ]
    }
   ],
   "source": [
    "def tokenize(html):\n",
    "    p = re.compile(r'<span[^>]*>(.+?)</span>')\n",
    "    return p.findall(html)\n",
    "\n",
    "def human_attention(html):\n",
    "\n",
    "    p = re.compile('<span(.*?)/span>')\n",
    "    all_span_items = p.findall(html)\n",
    "    if all_span_items[-1] == '><': all_span_items = all_span_items[:-1]\n",
    "\n",
    "    return ['class=\"active\"' in span_item for span_item in all_span_items]\n",
    "\n",
    "v_hat = human_attention(html)\n",
    "print(v_hat)\n",
    "\n",
    "# Check if we tokenize html, can our function \"human_attention\" reproduce the exact same length\n",
    "for fpath in os.listdir(dataset_path):\n",
    "    \n",
    "    if fpath.endswith('.csv'):\n",
    "        print('Check',fpath)\n",
    "        df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "        print(len(df['Answer.html_output']))\n",
    "        for html in df['Answer.html_output']:\n",
    "            tokens = tokenize(html)\n",
    "            v_hat = human_attention(html)\n",
    "            if len(tokens) != len(v_hat):\n",
    "                print(len(tokens), len(v_hat))\n",
    "                print(' '.tokens)\n",
    "                display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294fbb9-118e-4076-a792-9bfd59f1415c",
   "metadata": {},
   "source": [
    "Proceed dataset step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d7502c20-2195-4bf3-b8a6-2997d002e9c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Raw dataset</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;don't&lt;/span&gt; &lt;span&gt;think&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span class=\"active\"&gt;don't&lt;/spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;don't&lt;/span&gt; &lt;span&gt;think&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Ate&lt;/span&gt; &lt;span&gt;here&lt;/span&gt; &lt;span&gt;two&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Ate&lt;/span&gt; &lt;span&gt;here&lt;/span&gt; &lt;span&gt;two&lt;/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.label                                         Input.text  \\\n",
       "0            0  I don't think so. \\n\\nThis \"buffet\" is probabl...   \n",
       "1            0  I don't think so. \\n\\nThis \"buffet\" is probabl...   \n",
       "2            0  I don't think so. \\n\\nThis \"buffet\" is probabl...   \n",
       "3            1  Ate here two times now and food has been excel...   \n",
       "4            1  Ate here two times now and food has been excel...   \n",
       "\n",
       "  Answer.Q1Answer                                 Answer.html_output  \n",
       "0              no  <span>I</span> <span>don't</span> <span>think<...  \n",
       "1              no  <span>I</span> <span class=\"active\">don't</spa...  \n",
       "2              no  <span>I</span> <span>don't</span> <span>think<...  \n",
       "3             yes  <span>Ate</span> <span>here</span> <span>two</...  \n",
       "4             yes  <span>Ate</span> <span>here</span> <span>two</...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Preprocess text and human attention</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>human_label_</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;don't&lt;/span&gt; &lt;span&gt;think&lt;...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[I, do, n't, think, so, ., This, \", buffet, \",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span class=\"active\"&gt;don't&lt;/spa...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[I, do, n't, think, so, ., This, \", buffet, \",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;I&lt;/span&gt; &lt;span&gt;don't&lt;/span&gt; &lt;span&gt;think&lt;...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[I, do, n't, think, so, ., This, \", buffet, \",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Ate&lt;/span&gt; &lt;span&gt;here&lt;/span&gt; &lt;span&gt;two&lt;/...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Ate, here, two, times, now, and, food, has, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>yes</td>\n",
       "      <td>&lt;span&gt;Ate&lt;/span&gt; &lt;span&gt;here&lt;/span&gt; &lt;span&gt;two&lt;/...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Ate, here, two, times, now, and, food, has, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text human_label_  \\\n",
       "0      0  I don't think so. \\n\\nThis \"buffet\" is probabl...           no   \n",
       "1      0  I don't think so. \\n\\nThis \"buffet\" is probabl...           no   \n",
       "2      0  I don't think so. \\n\\nThis \"buffet\" is probabl...           no   \n",
       "3      1  Ate here two times now and food has been excel...          yes   \n",
       "4      1  Ate here two times now and food has been excel...          yes   \n",
       "\n",
       "                                  Answer.html_output  \\\n",
       "0  <span>I</span> <span>don't</span> <span>think<...   \n",
       "1  <span>I</span> <span class=\"active\">don't</spa...   \n",
       "2  <span>I</span> <span>don't</span> <span>think<...   \n",
       "3  <span>Ate</span> <span>here</span> <span>two</...   \n",
       "4  <span>Ate</span> <span>here</span> <span>two</...   \n",
       "\n",
       "                                                ham_  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         text_tokens  \n",
       "0  [I, do, n't, think, so, ., This, \", buffet, \",...  \n",
       "1  [I, do, n't, think, so, ., This, \", buffet, \",...  \n",
       "2  [I, do, n't, think, so, ., This, \", buffet, \",...  \n",
       "3  [Ate, here, two, times, now, and, food, has, b...  \n",
       "4  [Ate, here, two, times, now, and, food, has, b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>ham_0</th>\n",
       "      <th>human_label_0</th>\n",
       "      <th>ham_1</th>\n",
       "      <th>human_label_1</th>\n",
       "      <th>ham_2</th>\n",
       "      <th>human_label_2</th>\n",
       "      <th>cam</th>\n",
       "      <th>sam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, do, n't, think, so, ., This, \", buffet, \",...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ate, here, two, times, now, and, food, has, b...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great food and great atmosphere. The one thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, food, and, great, atmosphere, ., The, ...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obsessed. Atmosphere is a great combo of class...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Obsessed, ., Atmosphere, is, a, great, combo,...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I spend a lot of time trying as many burger jo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, spend, a, lot, of, time, trying, as, many,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I don't think so. \\n\\nThis \"buffet\" is probabl...      0   \n",
       "1  Ate here two times now and food has been excel...      1   \n",
       "2  Great food and great atmosphere. The one thing...      1   \n",
       "3  Obsessed. Atmosphere is a great combo of class...      1   \n",
       "4  I spend a lot of time trying as many burger jo...      1   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [I, do, n't, think, so, ., This, \", buffet, \",...   \n",
       "1  [Ate, here, two, times, now, and, food, has, b...   \n",
       "2  [Great, food, and, great, atmosphere, ., The, ...   \n",
       "3  [Obsessed, ., Atmosphere, is, a, great, combo,...   \n",
       "4  [I, spend, a, lot, of, time, trying, as, many,...   \n",
       "\n",
       "                                               ham_0 human_label_0  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "3  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                               ham_1 human_label_1  \\\n",
       "0  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...           yes   \n",
       "3  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                               ham_2 human_label_2  \\\n",
       "0  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...           yes   \n",
       "3  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                                 cam  \\\n",
       "0  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...   \n",
       "3  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 sam  \\\n",
       "0  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...   \n",
       "3  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 ham  \n",
       "0  [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...  \n",
       "3  [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.yelp_hat.utils import yelp_hat_ham, yelp_hat_token\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "df = pd.read_csv(path.join(extracted_path, 'ham_part5.csv'))\n",
    "display(HTML('<h3>Raw dataset</h3>'))\n",
    "display(df.head())\n",
    "\n",
    "dupli_2 = duplicates[duplicates['size'] == 2]  # finds dupli_2\n",
    "df = df[~df['Input.text'].isin(dupli_2['index'])]\n",
    "\n",
    "df['ham_'] = df[f'Answer.html_output'].apply(lambda x: yelp_hat_ham(x, nlp)).apply(lambda x: np.array(x))\n",
    "df['text_tokens'] = df['Answer.html_output'].apply(lambda x: yelp_hat_token(x, nlp))\n",
    "df = df.rename(columns={'Answer.Q1Answer': 'human_label_', 'Input.text': 'text', 'Input.label': 'label'})\n",
    "\n",
    "display(HTML('<h3>Preprocess text and human attention</h3>'))\n",
    "display(df.head())\n",
    "\n",
    "dfs = [df.loc[0::3, ['text', 'label', 'text_tokens']].reset_index(drop=True)]\n",
    "for idx in range(3):\n",
    "    _data = df.loc[idx::3, ['ham_', 'human_label_']]\n",
    "    _data = _data.reset_index(drop=True).add_suffix(str(idx))\n",
    "    dfs += [_data]\n",
    "    \n",
    "df = pd.concat(dfs, axis=1)\n",
    "\n",
    "def cam(row):\n",
    "    return np.logical_and(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def sam(row):\n",
    "    return np.logical_or(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def ham(row):\n",
    "    return ((row['ham_0'] + row['ham_1'] + row['ham_2'])/3 >= 0.5).astype(int)\n",
    "\n",
    "df['cam'] = df.apply(cam,axis=1)\n",
    "df['sam'] = df.apply(sam,axis=1)\n",
    "df['ham'] = df.apply(ham,axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f60eca72-76f0-44a1-b9ba-2ae981593576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path.join(extracted_path, 'ham_part5.csv'))\n",
    "duplicates = df.groupby(df['Input.text'].tolist(),as_index=False).size()\n",
    "display(duplicates['size'].unique())\n",
    "for dup_rows in [2, 3]:\n",
    "    print('Duplicate of', dup_rows, ':', sum(duplicate['size'] == dup_rows))\n",
    "    \n",
    "dupli_2 = duplicates[duplicates['size'] == 2]  # finds dupli_2\n",
    "df = df[~df['Input.text'].isin(dupli_2['index'])]\n",
    "duplicate = df.groupby(df['Input.text'].tolist(),as_index=False).size()\n",
    "display(duplicate['size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "52565e89-3f93-4e02-a032-5a62f40875a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "#Incoherent length: 999\n"
     ]
    }
   ],
   "source": [
    "df['coherent_ham_01'] = df['ham_0'].str.len() == df['ham_1'].str.len()\n",
    "df['coherent_ham_12'] = df['ham_1'].str.len() == df['ham_2'].str.len()\n",
    "print(df['coherent_ham_01'].all())\n",
    "print(df['coherent_ham_12'].all())\n",
    "print('#Incoherent length:', df['coherent_ham_12'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a3afc25-fec6-4967-a7cb-2140c2846b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part1(50words).csv\n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part3.csv\n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part4.csv\n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part5.csv\n",
      "operands could not be broadcast together with shapes (55,) (55,) (71,) \n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part6(100words).csv\n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part7.csv\n",
      "operands could not be broadcast together with shapes (72,) (52,) (52,) \n",
      "/Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/Human-Attention-for-Text-Classification-205c1552bc7be7ec48623d79d85d4c6fbfe62362/raw_data/ham_part8(200words).csv\n"
     ]
    }
   ],
   "source": [
    "def cam(row):\n",
    "    return np.logical_and(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def sam(row):\n",
    "    return np.logical_or(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def ham(row):\n",
    "    return ((row['ham_0'] + row['ham_1'] + row['ham_2'])/3 >= 0.5).astype(int)\n",
    "\n",
    "for f in files:\n",
    "    print(f)\n",
    "    df = pd.read_csv(f)\n",
    "    df['ham_'] = df[f'Answer.html_output'].apply(yelp_hat_ham).apply(lambda x: np.array(x))\n",
    "    df['text_tokens'] = df['Answer.html_output'].apply(yelp_hat_token)\n",
    "    df = df.rename(columns={'Answer.Q1Answer': 'human_label_', 'Input.text': 'text', 'Input.label': 'label'})\n",
    "    dfs = [df.loc[0::3, ['text', 'label', 'text_tokens']].reset_index(drop=True)]\n",
    "    for idx in range(3):\n",
    "        _data = df.loc[idx::3, ['ham_', 'human_label_']]\n",
    "        _data = _data.reset_index(drop=True).add_suffix(str(idx))\n",
    "        dfs += [_data]\n",
    "\n",
    "    df = pd.concat(dfs, axis=1)\n",
    "\n",
    "    try:\n",
    "        df['cam'] = df.apply(cam,axis=1)\n",
    "        df['sam'] = df.apply(sam,axis=1)\n",
    "        df['ham'] = df.apply(ham,axis=1)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b29102c3-1beb-49d3-b44a-7b67a5ab59c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>ham_0</th>\n",
       "      <th>human_label_0</th>\n",
       "      <th>ham_1</th>\n",
       "      <th>human_label_1</th>\n",
       "      <th>ham_2</th>\n",
       "      <th>human_label_2</th>\n",
       "      <th>cam</th>\n",
       "      <th>sam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't think so. \\n\\nThis \"buffet\" is probabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, don't, think, so., This, \"buffet\", is, pro...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ate here two times now and food has been excel...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ate, here, two, times, now, and, food, has, b...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great food and great atmosphere. The one thing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, food, and, great, atmosphere., The, on...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obsessed. Atmosphere is a great combo of class...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Obsessed., Atmosphere, is, a, great, combo, o...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I spend a lot of time trying as many burger jo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, spend, a, lot, of, time, trying, as, many,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I don't think so. \\n\\nThis \"buffet\" is probabl...      0   \n",
       "1  Ate here two times now and food has been excel...      1   \n",
       "2  Great food and great atmosphere. The one thing...      1   \n",
       "3  Obsessed. Atmosphere is a great combo of class...      1   \n",
       "4  I spend a lot of time trying as many burger jo...      1   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  [I, don't, think, so., This, \"buffet\", is, pro...   \n",
       "1  [Ate, here, two, times, now, and, food, has, b...   \n",
       "2  [Great, food, and, great, atmosphere., The, on...   \n",
       "3  [Obsessed., Atmosphere, is, a, great, combo, o...   \n",
       "4  [I, spend, a, lot, of, time, trying, as, many,...   \n",
       "\n",
       "                                               ham_0 human_label_0  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "3  [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                               ham_1 human_label_1  \\\n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...           yes   \n",
       "3  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                               ham_2 human_label_2  \\\n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...            no   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...           yes   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...           yes   \n",
       "3  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...           yes   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           yes   \n",
       "\n",
       "                                                 cam  \\\n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "3  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 sam  \\\n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "3  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 ham  \n",
       "0  [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, ...  \n",
       "3  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cam(row):\n",
    "    return np.logical_and(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def sam(row):\n",
    "    return np.logical_or(row['ham_0'],row['ham_1'],row['ham_2'])\n",
    "\n",
    "def ham(row):\n",
    "    return ((row['ham_0'] + row['ham_1'] + row['ham_2'])/3 >= 0.5).astype(int)\n",
    "\n",
    "df['cam'] = df.apply(cam,axis=1)\n",
    "df['sam'] = df.apply(sam,axis=1)\n",
    "df['ham'] = df.apply(ham,axis=1)\n",
    "df.head()\n",
    "# sam = df.apply(lambda x: np.logical_and(np.array(x['ham_0']), np.array(x['ham_1']), np.array(x['ham_2'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68cd16-6e28-45fd-b86a-6cba7f3819f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> By reconcatenating for spacy and re tokenize, do we obtain the coherent length?\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8fca69a6-c3f6-4d57-afa9-07eef4f35481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463d6d78fa344beebf821c878c32b9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham_part5.csv : Same tokens between text and ham > True\n",
      "ham_part8(200words).csv : Same tokens between text and ham > True\n",
      "ham_part6(100words).csv : Same tokens between text and ham > True\n",
      "ham_part4.csv : Same tokens between text and ham > True\n",
      "ham_part3.csv : Same tokens between text and ham > True\n",
      "ham_part1(50words).csv : Same tokens between text and ham > True\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "def tokenize_ham(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = [str(tag.string) for tag in soup.find_all('span') if tag.string is not None]\n",
    "    tokens = [str(tk.text) for doc in nlp.pipe(tags) for tk in doc]\n",
    "    return tokens\n",
    "\n",
    "files = [fpath for fpath in os.listdir(extracted_path) if fpath.endswith('.csv') and 'part7' not in fpath]\n",
    "\n",
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(extracted_path, fpath))\n",
    "\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'ham_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "\n",
    "    clean_df['ham_tokens'] = clean_df['ham_html_0'].apply(tokenize_ham)\n",
    "    clean_df['count_ham_tokens'] = clean_df['ham_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    clean_df['count_text_tokens'] = clean_df['text_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    is_every_row_ok = (clean_df['count_text_tokens'] == clean_df['count_ham_tokens']).all()\n",
    "    print(fpath, ': Same tokens between text and ham >', is_every_row_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d68d5-ab3f-40fd-9260-02610908f91c",
   "metadata": {},
   "source": [
    "###### Split tokens in human attention maps by spacy, verify if `len(token) == len(annotation)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc1689-a576-427d-a481-e67541fb0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_ham(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tags = [tag for tag in soup.find_all('span') if tag.string is not None]\n",
    "    \n",
    "    tag_annot = [int('active' in t.get('class', [])) for t in tags]\n",
    "    tag_str = [str(t.string) for t in tags]\n",
    "    \n",
    "    ham = []\n",
    "    \n",
    "    for annot, splitted_tokens in zip(tag_annot, nlp.pipe(tag_str)):\n",
    "        annotation = [annot * int(not tk.is_punct) for tk in splitted_tokens]\n",
    "        ham += annotation\n",
    "    \n",
    "    return ham\n",
    "\n",
    "html = clean_df['ham_html_0']\n",
    "print(html[0])\n",
    "print(tokenize_ham(html[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a068205-9890-40c3-892e-16fd77d2c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [fpath for fpath in os.listdir(dataset_path) if fpath.endswith('.csv') and 'part7' not in fpath]\n",
    "\n",
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'annotation_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "\n",
    "    clean_df['ham_tokens'] = clean_df['ham_html_0'].apply(binarize_ham)\n",
    "    clean_df['count_ham_tokens'] = clean_df['ham_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    clean_df['count_text_tokens'] = clean_df['text_tokens'].apply(lambda row: len(row))\n",
    "\n",
    "    is_every_row_ok = (clean_df['count_text_tokens'] == clean_df['count_ham_tokens']).all()\n",
    "    print(fpath, ': Same tokens between text and ham >', is_every_row_ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37284a6-44d4-4c46-a765-2ee421f48cfd",
   "metadata": {},
   "source": [
    "## Check sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76b9d553-01e7-49a1-8b7f-1ed61696d345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a18de6908874463b30b42b5825df838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part5.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.694</td>\n",
       "      <td>7.983865</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%   max\n",
       "label        1000.0   0.516  0.499994   0.0   0.0   1.0   1.0   1.0\n",
       "text_length  1000.0  71.694  7.983865  55.0  66.0  71.0  78.0  97.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part8(200words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>181.0</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>0.501318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>181.0</td>\n",
       "      <td>230.071823</td>\n",
       "      <td>8.317340</td>\n",
       "      <td>210.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean       std    min    25%    50%    75%    max\n",
       "label        181.0    0.508287  0.501318    0.0    0.0    1.0    1.0    1.0\n",
       "text_length  181.0  230.071823  8.317340  210.0  224.0  230.0  235.0  252.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part6(100words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>438.0</td>\n",
       "      <td>0.513699</td>\n",
       "      <td>0.500384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>438.0</td>\n",
       "      <td>115.276256</td>\n",
       "      <td>5.565827</td>\n",
       "      <td>101.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean       std    min    25%    50%    75%    max\n",
       "label        438.0    0.513699  0.500384    0.0    0.0    1.0    1.0    1.0\n",
       "text_length  438.0  115.276256  5.565827  101.0  112.0  114.0  118.0  144.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part4.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.500201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.604</td>\n",
       "      <td>7.837641</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%    max\n",
       "label        1000.0   0.507  0.500201   0.0   0.0   1.0   1.0    1.0\n",
       "text_length  1000.0  71.604  7.837641  55.0  65.0  71.0  78.0  101.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part3.csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.500241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>71.958</td>\n",
       "      <td>8.178944</td>\n",
       "      <td>53.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count    mean       std   min   25%   50%   75%    max\n",
       "label        1000.0   0.497  0.500241   0.0   0.0   0.0   1.0    1.0\n",
       "text_length  1000.0  71.958  8.178944  53.0  65.0  72.0  78.0  107.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>ham_part1(50words).csv</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.500557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>300.0</td>\n",
       "      <td>58.006667</td>\n",
       "      <td>3.009454</td>\n",
       "      <td>50.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count       mean       std   min   25%   50%   75%   max\n",
       "label        300.0   0.483333  0.500557   0.0   0.0   0.0   1.0   1.0\n",
       "text_length  300.0  58.006667  3.009454  50.0  56.0  57.0  60.0  72.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fpath in tqdm(files, total=len(files)):\n",
    "        \n",
    "    df = pd.read_csv(path.join(dataset_path, fpath))\n",
    "    display(HTML(f'<h3>{fpath}</h3>'))\n",
    "    dfs = [df.loc[0::3, df.columns != 'Answer.html_output'].reset_index(drop=True)]\n",
    "    dfs += [df.loc[idx::3, ['Answer.html_output']].reset_index(drop=True).rename(columns={'Answer.html_output':'ham_html_'}).add_suffix(str(idx)) for idx in range(3) ]\n",
    "    clean_df = pd.concat(dfs,axis=1).rename(columns={'Input.label': 'label', 'Input.text': 'text', 'Answer.Q1Answer':'human_label'})\n",
    "    clean_df = clean_df[['text', 'ham_html_0', 'ham_html_1', 'ham_html_2', 'label', 'human_label']]\n",
    "    clean_df['text_tokens'] = [[tk.text for tk in doc if not tk.is_space] for doc in nlp.pipe(clean_df['text'].tolist())]\n",
    "    \n",
    "    clean_df['text_length'] = clean_df.text_tokens.str.len()\n",
    "    display(clean_df.describe().transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886978c-4171-4c53-bba3-0d91c9b7c577",
   "metadata": {},
   "source": [
    "### Handle case part7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "57fe67ac-33e5-49ac-82f5-e9a03b104ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Part 7</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input.label</th>\n",
       "      <th>Input.text</th>\n",
       "      <th>Answer.Q1Answer</th>\n",
       "      <th>Answer.html_output</th>\n",
       "      <th>ham_html_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;*knocks&lt;/span&gt; &lt;span&gt;on&lt;/span&gt; &lt;span&gt;doo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;$18.95&lt;/span&gt; &lt;span&gt;per&lt;/span&gt; &lt;span&gt;per...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>no</td>\n",
       "      <td>&lt;span&gt;$18.95&lt;/span&gt; &lt;span&gt;per&lt;/span&gt; &lt;span&gt;per...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input.label                                         Input.text  \\\n",
       "0            0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "1            0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "2            0  *knocks on door*\\n*walks into restaurant*\\n*go...   \n",
       "3            0  $18.95 per person....Was really hungry for lun...   \n",
       "4            0  $18.95 per person....Was really hungry for lun...   \n",
       "\n",
       "  Answer.Q1Answer                                 Answer.html_output  \\\n",
       "0              no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "1              no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "2              no  <span>*knocks</span> <span>on</span> <span>doo...   \n",
       "3              no  <span>$18.95</span> <span>per</span> <span>per...   \n",
       "4              no  <span>$18.95</span> <span>per</span> <span>per...   \n",
       "\n",
       "                                           ham_html_  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Duplication du part 7</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$18.95 per person....Was really hungry for lun...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*knocks on door*\\n*walks into restaurant*\\n*go...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. Happy hour pricing is only available in the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20 Minute wait per dish. Never coming here aga...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd time eating here, We drive 35 miles from H...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               index  size\n",
       "0  $18.95 per person....Was really hungry for lun...     3\n",
       "1  *knocks on door*\\n*walks into restaurant*\\n*go...     3\n",
       "2  1. Happy hour pricing is only available in the...     3\n",
       "3  20 Minute wait per dish. Never coming here aga...     3\n",
       "4  2nd time eating here, We drive 35 miles from H...     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(extracted_path, 'ham_part7.csv'))\n",
    "df['ham_html_'] = df[f'Answer.html_output'].apply(lambda x: yelp_hat_ham(x, nlp))\n",
    "display(HTML('<h3>Part 7</h3>'))\n",
    "display(df.head())\n",
    "\n",
    "duplicates = df.groupby(df['Input.text'].tolist(),as_index=False).size()\n",
    "display(HTML('<h3>Duplication du part 7</h3>'))\n",
    "display(duplicates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "30df6df6-fee8-4bf7-b4c9-c3457f9a2319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e2d7f2ae014c968c2f85b8e688d456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Input.text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input.text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [149]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dupli_2 \u001b[38;5;241m=\u001b[39m duplicates[duplicates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tqdm(dupli_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m3\u001b[39m]):\n\u001b[0;32m----> 4\u001b[0m     display(df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput.text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m d])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dup_rows \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuplicate of\u001b[39m\u001b[38;5;124m'\u001b[39m, dup_rows, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28msum\u001b[39m(duplicates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m dup_rows))\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input.text'"
     ]
    }
   ],
   "source": [
    "dupli_2 = duplicates[duplicates['size'] < 3]\n",
    "\n",
    "for d in tqdm(dupli_2['index'][:3]):\n",
    "    display(df.loc[df['Input.text'] == d])\n",
    "    \n",
    "for dup_rows in [2, 3, 4]:\n",
    "    print('Duplicate of', dup_rows, ':', sum(duplicates['size'] == dup_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ba9e4fd8-537b-42da-a66e-fae35867b187",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Input.text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input.text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop all text that has only 2 reviews:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df2 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput.text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misin(dupli_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Verify if no more 2-row duplicate exist\u001b[39;00m\n\u001b[1;32m      5\u001b[0m duplicates_2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mgroupby(df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/venv/eps/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Input.text'"
     ]
    }
   ],
   "source": [
    "# Drop all text that has only 2 reviews:\n",
    "df2 = df[~df['Input.text'].isin(dupli_2['index'])]\n",
    "\n",
    "# Verify if no more 2-row duplicate exist\n",
    "duplicates_2 = df2.groupby(df2['Input.text'].tolist(),as_index=False).size()\n",
    "display(duplicates_2['size'].unique())\n",
    "print('>> Expected not to have \"2\" after drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ae7d706-10f3-46b4-8c6e-b052380ff033",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'duplicates_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [151]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mduplicates_2\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;241m==\u001b[39m [\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'duplicates_2' is not defined"
     ]
    }
   ],
   "source": [
    "duplicates_2['size'].unique() == [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a3d87d0-ac1d-48a7-9061-5948a329b868",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop 4th annotation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df3 \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.text\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check if no more duplicate of 4:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m duplicates_3 \u001b[38;5;241m=\u001b[39m df3\u001b[38;5;241m.\u001b[39mgroupby(df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput.text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop 4th annotation\n",
    "df3 = df2.groupby('Input.text').head(3).reset_index(drop=True)\n",
    "\n",
    "# Check if no more duplicate of 4:\n",
    "duplicates_3 = df3.groupby(df3['Input.text'].tolist(),as_index=False).size()\n",
    "display(duplicates_3['size'].unique())\n",
    "\n",
    "print('Check correctly remove number of duplicate of 4', len(df3) + len(text_4) == len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28105a9f-09f0-46fb-9a88-a6638648773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9639f395-954c-443f-9a89-a81c30516b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_3['size'].unique()[0] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8937c06-84db-443f-9e13-a37bcf249a12",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a6a9214-a9f4-4c00-bbe1-c26563f15a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drop 12 samples because HAMs are not compatibles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part5.csv\n",
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part8(200words).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drop 2 samples because HAMs are not compatibles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part6(100words).csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drop 1 samples because HAMs are not compatibles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part4.csv\n",
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part3.csv\n",
      "Reformat /Users/dunguyen/Projects/explanation_on_pair_sequences_task/notebooks/../.cache/dataset/yelp-hat/caching/ham_part1(50words).csv\n"
     ]
    }
   ],
   "source": [
    "from data import YelpHat\n",
    "\n",
    "yelp_hat = YelpHat(root=path.join(cache_path, 'dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b5f5bd5-a08a-4827-bcce-776e0100fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3482"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yelp_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c59a0dd-3d8a-48dc-9b76-005837d59f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "N_train = int(len(yelp_hat) * 0.7)\n",
    "N_val = len(yelp_hat) - N_train\n",
    "trainset, valset = random_split(yelp_hat, [N_train, N_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8e42054-3397-4772-9df3-c1efb8e947d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2437"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdf6bf-1528-4eef-88d6-92f2c7be728a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
